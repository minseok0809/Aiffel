# -*- coding: utf-8 -*-
"""[E_01]Classification_Sklearn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/178ex220Kc4CZAMVa4W9lUgafdlksbOtg

##Iris의 세 가지 품종, 분류해볼 수 있겠어요?

데이터셋
<br/>load_digits : 손글씨 분류
<br/>load_wine : 와인 분류
<br/>load_breast_cancer : 유방암 여부 진단

개발 환경
<br/>데이터 정보
<br/>데이터 탐색
<br/>데이터 분리

모델 학습
<br/>Decision Tree
<br/>Random Forest
<br/>SVC
<br/>SGD Classifier
<br/>Logistic Regression

모델 평가
<br/>결론
<br/>참고문헌

#개발 환경
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd                                   
import numpy as np    
import matplotlib.pyplot as plt  
# %matplotlib inline     
import warnings
warnings.filterwarnings(action='ignore')

"""pandas는 데이터를 구조화된 형식으로 가공 및 분석할 수 있도록 자료구조를 제공하는 패키지이다.

matplotlib은 데이터를 시각화한다.

numpy는 수치 행렬을 계산한다.
"""

import sklearn
from sklearn.model_selection import train_test_split  
from sklearn.metrics import classification_report     
from sklearn.metrics import confusion_matrix 
from sklearn.metrics import plot_confusion_matrix 
from sklearn.metrics import accuracy_score            
from sklearn.tree import DecisionTreeClassifier       
from sklearn.ensemble import RandomForestClassifier  
from sklearn import svm                              
from sklearn.linear_model import SGDClassifier       
from sklearn.linear_model import LogisticRegression

"""sklearn.model_selection은 데이터를 훈련 데이터와 시험 데이터로 분리한다.

sklearn.metrics은 분류 결과값을 class별로 출력하고 오차행렬을 시각화한다.
<br/>또한 정확도를 측정한다.

sklearn은 Decision Tree, Random Forest, Support Vector Classifier(SVC), SGD Clssifier, Logistic Regression을 한다.
"""

from google.colab import drive
drive.mount('/content/drive')

pip freeze > '/content/drive/MyDrive/lms/library_version.txt'

library_name = ['pandas=', 'numpy=', 'matplotlib=', 'sklearn=']
library_version = []
count = 0

import sys
print(sys.version)
print()

with open('/content/drive/MyDrive/lms/library_version.txt', 'r') as f:
    lines = f.read().splitlines() 

for i in range(len(lines)):
  for line in lines[i:i+1]:
    for library in library_name:
      if library in line:
        library_version.append(line)
        count += 1
        print(line, end = '    ')
        if count % 3 == 0:
          print()

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

"""Google Colab에서 할당된 GPU를 확인한다.
<br/>고용량 메모리 VM에 액세스한다.

#load_digits : 손글씨 분류

##데이터 정보

[sklearn.datasets.load_digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits)

##데이터 탐색
"""

from sklearn.datasets import load_digits             
digits = load_digits()

plt.gray()
matfig = plt.figure(figsize=(2,2))
ax = plt.matshow(digits.images[0], fignum=matfig.number)
plt.show()

"""손글씨 데이터 행렬을 시각화 도구 matplotlip을 이용해 나타낼 수 있다. """

dir(digits)

digits.keys()

"""데이터셋 digits에는 data, target, frame, feature_names, target_names, images, DESCR까지
<br/>총 7개의 정보가 담겨져있다.
"""

digits_data = digits.data
print(digits_data.shape)

"""총 1797개의 데이터가 각각 64개의 정보를 담고 있다."""

digits_data[0]

"""0번 index에 위치한 데이터의 정보이다."""

digits_label = digits.target
print(digits_label.shape)
digits_label

"""digits 데이터의 타겟정보
<br/>타겟은 주어진 정답을 의미한다.
<br/>총 1797개의 데이터가 0부터 9까지 정수 한 자릿수로 구성됐다.
"""

digits.target_names

"""0부터 9까지 손글씨 이미지의 요소가 담겨있다."""

digits_feature = digits.feature_names
digits_feature

"""feature은 데이터의 속성으로 64개를 가지고 있다."""

print(digits['DESCR'])

"""인스턴스. 속성. 속성에 대한 정보. 결측치 개수. 데이터셋 제작자와 제작 날짜 등을 알아볼 수 있다."""

digits_df = pd.DataFrame(data=digits.data, columns=digits.feature_names)  
digits_df['label'] = digits.target                                       
digits_df

"""정답 데이터 label 컬럼을 추가했다.

##데이터 분리
"""

x_train, x_test, y_train, y_test = train_test_split(digits_data,  
                                                    digits_label,    
                                                    test_size=0.2,   
                                                    random_state=1)  

print('x_train 개수: ', len(x_train),', x_test 개수: ', len(x_test))

"""digits_data은 특징 데이터, digits_label은 정답 데이터로 구성하여
<br/>random state으로 데이터를 무작위로 정렬하고
<br/>전체의 20%를 시험 데이터로 사용한다.

##모델 학습

###Decision Tree
"""

decision_tree = DecisionTreeClassifier(random_state=15)   
decision_tree.fit(x_train, y_train)    
y_pred = decision_tree.predict(x_test)

y_pred

y_test

"""y_pred와 y_test의 결과를 비교해보니 비슷하게 나왔다"""

digits_decisiontree_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(digits_decisiontree_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(digits_decisiontree_confmat.shape[0]):
  for j in range(digits_decisiontree_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=digits_decisiontree_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Decision Tree 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(decision_tree, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.86
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.86
"""

digits_decisiontree_report = classification_report(y_test, y_pred, output_dict=True)
digits_decisiontree_report = pd.DataFrame(digits_decisiontree_report).transpose()   
digits_decisiontree_accuracy = digits_decisiontree_report['f1-score'][-3:-2][0]
print("accuracy : ", digits_decisiontree_accuracy)

"""Decision Tree 모델 성능 'accuracy'는 85.56%이다.
 <br/>Decision Tree 모델의 성능을 변수로 저장한다.

###Random Forest
"""

random_forest = RandomForestClassifier(random_state=32)       
random_forest.fit(x_train, y_train)                           
y_pred = random_forest.predict(x_test)

y_pred

y_test

"""정답지와 예측치를 비교한다."""

digits_random_forest_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(digits_random_forest_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(digits_random_forest_confmat.shape[0]):
  for j in range(digits_random_forest_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=digits_random_forest_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Random Forest 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(random_forest, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.97
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.97
"""

digits_randomforest_report = classification_report(y_test, y_pred, output_dict=True)
digits_randomforest_report = pd.DataFrame(digits_randomforest_report).transpose()  
digits_randomforest_accuracy = digits_randomforest_report['f1-score'][-3:-2][0]
print("accuracy : ", digits_randomforest_accuracy)

"""Randomforest 모델의 성능 'accuracy'는 98.61%이다.
<br/>Randomforest 모델의 성능을 변수로 저장한다.

###Support Vector Classifier(SVC)
"""

svc_model = svm.SVC()
svc_model.fit(x_train, y_train)
y_pred = svc_model.predict(x_test)

digits_svc_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(digits_svc_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(digits_svc_confmat.shape[0]):
  for j in range(digits_svc_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=digits_svc_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""SVC 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(svc_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.99
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.99
"""

digits_svc_report = classification_report(y_test, y_pred, output_dict=True)
digits_svc_report = pd.DataFrame(digits_svc_report).transpose()  
digits_svc_accuracy = digits_svc_report['f1-score'][-3:-2][0]
print("accuracy : ", digits_svc_accuracy)

"""SVC 모델의 성능 'accuracy'는 99.17%이다.
<br/>SVC 모델의 성능을 변수로 저장한다.

###SGD Classifier
"""

sgd_model = SGDClassifier()
sgd_model.fit(x_train, y_train)
y_pred = sgd_model.predict(x_test)

digits_sgd_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(digits_sgd_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(digits_sgd_confmat.shape[0]):
  for j in range(digits_sgd_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=digits_sgd_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""SGD 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(sgd_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.94
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.94
"""

digits_sgd_report = classification_report(y_test, y_pred, output_dict=True)
digits_sgd_report = pd.DataFrame(digits_sgd_report).transpose()  
digits_sgd_accuracy = digits_sgd_report['f1-score'][-3:-2][0]
print("accuracy : ", digits_sgd_accuracy)

"""SGD 모델의 성능 'accuracy'는 93.61%이다.
<br/>SGD 모델의 성능을 변수로 저장한다.

###Logistic Regression
"""

logistic_model = LogisticRegression()
logistic_model.fit(x_train, y_train)
y_pred = logistic_model.predict(x_test)

digits_logistic_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(digits_logistic_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(digits_logistic_confmat.shape[0]):
  for j in range(digits_logistic_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=digits_logistic_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Logistic Regression 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(logistic_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.97
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.97
"""

digits_logistic_report = classification_report(y_test, y_pred, output_dict=True)
digits_logistic_report = pd.DataFrame(digits_logistic_report).transpose()   
digits_logistic_accuracy = digits_logistic_report['f1-score'][-3:-2][0]  
print("accuracy : ", digits_logistic_accuracy)

"""Logistic Regression 모델의 성능 'accuracy'는 96.94%이다.
<br/>Logistic Regression 모델의 성능을 변수로 저장한다.

##모델 평가
"""

digits_model_comparison = [round(digits_decisiontree_accuracy, 4)
,round(digits_randomforest_accuracy, 4), round(digits_svc_accuracy, 4)
,round(digits_sgd_accuracy, 4), round(digits_logistic_accuracy, 4)]

digits_model_name = ['Decision Tree','Random Forest','SVC','SGD', 'Logistic']   


digits_df = pd.DataFrame({"Model": digits_model_name,
                  "Accuracy":digits_model_comparison})
digits_df_sorted= digits_df.sort_values('Accuracy',ascending=False)


plt.figure(figsize=(10, 5))                                                 
bar_width = 0.1                                                                 

plt.bar('Model', 'Accuracy',data=digits_df_sorted, color = 'blue')       


for i, v in enumerate(digits_model_name):
    plt.text(v, digits_model_comparison[i],digits_model_comparison[i],      
             fontsize = 9, 
             color='black',
             horizontalalignment='center',  
             verticalalignment='bottom')  

plt.ylim([0.7, 1])   

plt.title('Digits', fontsize=20)     
plt.xlabel('Model', fontsize=18)     
plt.ylabel('Accuracy', fontsize=18)  

plt.show()

"""SVC > Random Forest > Logistic > SGD > Decision Tree 순으로 성능이 높다.
<br/>따라서 digits 데이터셋에서는 SVC 모델 성능이 탁월하다.

#load_wine : 와인 분류

##데이터 정보

[sklearn.datasets.load_wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html?highlight=load_wine#sklearn.datasets.load_wine)

##데이터 탐색
"""

from sklearn.datasets import load_wine            
wine = load_wine()

dir(wine)

wine.keys()

"""데이터셋 wine에는 data, target, frame, feature_names, target_names, DESCR까지
<br/>총 6개의 정보가 담겨져있다.
"""

wine_data = wine.data
print(wine_data.shape)

"""총 178개의 데이터가 각각 13개의 정보를 담고 있다."""

wine_data[0]

"""0번 index에 위치한 데이터의 정보이다."""

wine_label = wine.target
print(wine_label.shape)
wine_label

"""wine 데이터의 타겟정보
<br/>타겟은 주어진 정답을 의미한다.
<br/>총 178개의 데이터가 0부터 2까지 정수 한 자릿수로 구성됐다.
"""

wine.target_names

"""'class_0', 'class_1', 'class_2'으로 wine의 요소가 담겨있다."""

wine_feature = wine.feature_names
wine_feature

"""feature은 데이터의 속성으로 13개를 가지고 있다."""

print(wine['DESCR'])

"""인스턴스. 속성. 속성에 대한 정보. 결측치 개수. 데이터셋 제작자와 제작 날짜 등을 알아볼 수 있다."""

wine_df = pd.DataFrame(data=wine.data, columns=wine.feature_names)  
wine_df['label'] = wine.target                                        
wine_df

"""정답 데이터 label 컬럼을 추가했다.

##데이터 분리
"""

x_train, x_test, y_train, y_test = train_test_split(wine_data,  
                                                    wine_label,    
                                                    test_size=0.2,   
                                                    random_state=1)  

print('x_train 개수: ', len(x_train),', x_test 개수: ', len(x_test))

"""digits_data은 특징 데이터, digits_label은 정답 데이터로 구성하여
<br/>random state으로 데이터를 무작위로 정렬하고
<br/>전체의 20%를 시험 데이터로 사용한다.

##모델 학습

###Decision Tree
"""

decision_tree = DecisionTreeClassifier(random_state=15)  
decision_tree.fit(x_train, y_train) 
y_pred = decision_tree.predict(x_test)

y_pred

y_test

"""y_pred와 y_test의 결과를 비교해보니 비슷하게 나왔다"""

wine_decisiontree_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(wine_decisiontree_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(wine_decisiontree_confmat.shape[0]):
  for j in range(wine_decisiontree_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=wine_decisiontree_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Decision Tree 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(decision_tree, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.95
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.94
"""

wine_decisiontree_report = classification_report(y_test, y_pred, output_dict=True)
wine_decisiontree_report = pd.DataFrame(wine_decisiontree_report).transpose()   
wine_decisiontree_accuracy = wine_decisiontree_report['f1-score'][-3:-2][0] 
print("accuracy : ", wine_decisiontree_accuracy)

"""Decision Tree 모델 성능 'accuracy'는 94.44%이다.
 <br/>Decision Tree 모델의 성능을 변수로 저장한다.

###Random Forest
"""

random_forest = RandomForestClassifier(random_state=32)       
random_forest.fit(x_train, y_train)                          
y_pred = random_forest.predict(x_test)

y_pred

y_test

wine_random_forest_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(wine_random_forest_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(wine_random_forest_confmat.shape[0]):
  for j in range(wine_random_forest_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=wine_random_forest_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Random Forest 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(random_forest, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화

Random Forest 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬
"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.97
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.97
"""

wine_randomforest_report = classification_report(y_test, y_pred, output_dict=True)
wine_randomforest_report = pd.DataFrame(wine_randomforest_report).transpose()   
wine_randomforest_accuracy = wine_randomforest_report['f1-score'][-3:-2][0]
print("accuracy : ", wine_randomforest_accuracy)

"""Randomforest 모델의 성능 'accuracy'는 97.22%이다.
<br/>Randomforest 모델의 성능을 변수로 저장한다.

###Support Vector Classifier(SVC)
"""

svc_model = svm.SVC()
svc_model.fit(x_train, y_train)
y_pred = svc_model.predict(x_test)

wine_svc_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(wine_svc_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(wine_svc_confmat.shape[0]):
  for j in range(wine_svc_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=wine_svc_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""SVC 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(svc_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.50
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.62
"""

wine_svc_report = classification_report(y_test, y_pred, output_dict=True)
wine_svc_report = pd.DataFrame(wine_svc_report).transpose()     
wine_svc_accuracy = wine_svc_report['f1-score'][-3:-2][0]
print("accuracy : ", wine_svc_accuracy)

"""SVC 모델의 성능 'accuracy'는 63.89%이다.
<br/>SVC 모델의 성능을 변수로 저장한다.

###SGD Classifier
"""

sgd_model = SGDClassifier()
sgd_model.fit(x_train, y_train)
y_pred = sgd_model.predict(x_test)

wine_sgd_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(wine_sgd_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(wine_sgd_confmat.shape[0]):
  for j in range(wine_sgd_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=wine_sgd_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""SGD 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(sgd_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.71
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.65
"""

wine_sgd_report = classification_report(y_test, y_pred, output_dict=True)
wine_sgd_report = pd.DataFrame(wine_sgd_report).transpose()    
wine_sgd_accuracy = wine_sgd_report['f1-score'][-3:-2][0]    
print("accuracy : ", wine_sgd_accuracy)

"""SGD 모델의 성능 'accuracy'는 66.67%이다.
<br/>SGD 모델의 성능을 변수로 저장한다.

###Logistic Regression
"""

logistic_model = LogisticRegression()
logistic_model.fit(x_train, y_train)
y_pred = logistic_model.predict(x_test)

wine_logistic_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(wine_logistic_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(wine_logistic_confmat.shape[0]):
  for j in range(wine_logistic_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=wine_logistic_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Logistic Regression 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(logistic_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.97
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.97
"""

wine_logistic_report = classification_report(y_test, y_pred, output_dict=True)
wine_logistic_report = pd.DataFrame(wine_logistic_report).transpose()     
wine_logistic_accuracy = wine_logistic_report['f1-score'][-3:-2][0]
print("accuracy : ", wine_logistic_accuracy)

"""Logistic Regression 모델의 성능 'accuracy'는 94.44%이다.
<br/>Logistic Regression 모델의 성능을 변수로 저장한다.

##모델 평가
"""

wine_model_comparison = [round(wine_decisiontree_accuracy, 4)
,round(wine_randomforest_accuracy, 4), round(wine_svc_accuracy, 4)
,round(wine_sgd_accuracy, 4), round(wine_logistic_accuracy, 4)]

wine_model_name = ['Decision Tree','Random Forest','SVC','SGD', 'Logistic']  

wine_df = pd.DataFrame({"Model": wine_model_name,
                  "Accuracy":wine_model_comparison})
wine_df_sorted= wine_df.sort_values('Accuracy',ascending=False)


plt.figure(figsize=(10, 5))                                                  
bar_width = 0.1                                                                

plt.bar('Model', 'Accuracy',data=wine_df_sorted, color = 'blue')        

for i, v in enumerate(wine_model_name):
    plt.text(v, wine_model_comparison[i],wine_model_comparison[i],      
             fontsize = 9, 
             color='black',
             horizontalalignment='center',  
             verticalalignment='bottom')    

plt.ylim([0.5, 1])    
plt.title('Wine', fontsize=20)     
plt.xlabel('Model', fontsize=18)     
plt.ylabel('Accuracy', fontsize=18)  
plt.show()

"""Random Forest > Decision Tree = Logistic  >  SGD > SVC 순으로 성능이 높다.
<br/>따라서 wine 데이터셋에서는 Random Forest 모델 성능이 탁월하다.

#load_breast_cancer : 유방암 여부 진단

##데이터 정보

[sklearn.datasets.load_breast_cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html?highlight=load_breast_cancer#sklearn.datasets.load_breast_cancer)

##**데이터 탐색**
"""

from sklearn.datasets import load_breast_cancer             
breast_cancer = load_breast_cancer()

dir(breast_cancer)

breast_cancer.keys()

"""데이터셋 breast_cancer에는 data, target, frame, feature_names, target_names, filename, data_module, DESCR까지
<br/>총 8개의 정보가 담겨져있다.
"""

breast_cancer_data = breast_cancer.data
print(breast_cancer_data.shape)

"""총 569개의 데이터가 각각 30개의 정보를 담고 있다."""

breast_cancer_data[0]

"""0번 index에 위치한 데이터의 정보이다."""

breast_cancer_label = breast_cancer.target
print(breast_cancer_label.shape)
breast_cancer_label

"""breast_cancer 데이터의 타겟정보
<br/>타겟은 주어진 정답을 의미한다.
<br/>총 569개의 데이터가 0과 1로 이진 분류됐다.
"""

breast_cancer.target_names

"""'malignant', 'benign'으로 breast_cancer의 요소가 담겨있다."""

breast_cancer_feature = breast_cancer.feature_names
breast_cancer_feature

"""feature은 데이터의 속성으로 30개를 가지고 있다."""

print(breast_cancer['DESCR'])

"""인스턴스. 속성. 속성에 대한 정보. 결측치 개수. 데이터셋 제작자와 제작 날짜 등을 알아볼 수 있다."""

breast_cancer_df = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)  
breast_cancer_df['label'] = breast_cancer.target                                       
breast_cancer_df

"""정답 데이터 label 컬럼을 추가했다.

##데이터 분리
"""

x_train, x_test, y_train, y_test = train_test_split(breast_cancer_data,  
                                                    breast_cancer_label,   
                                                    test_size=0.2,   
                                                    random_state=1)  

print('x_train 개수: ', len(x_train),', x_test 개수: ', len(x_test))

"""digits_data은 특징 데이터, digits_label은 정답 데이터로 구성하여
<br/>random state으로 데이터를 무작위로 정렬하고
<br/>전체의 20%를 시험 데이터로 사용한다.

##모델 학습

###Decision Tree
"""

decision_tree = DecisionTreeClassifier(random_state=15)   
decision_tree.fit(x_train, y_train)

y_pred = decision_tree.predict(x_test)                   
y_pred

y_test

"""y_pred와 y_test의 결과를 비교해보니 비슷하게 나왔다"""

breast_cancer_decisiontree_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(breast_cancer_decisiontree_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(breast_cancer_decisiontree_confmat.shape[0]):
  for j in range(breast_cancer_decisiontree_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=breast_cancer_decisiontree_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Decision Tree 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(decision_tree, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.95
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.94
"""

breast_cancer_decisiontree_report = classification_report(y_test, y_pred, output_dict=True)
breast_cancer_decisiontree_report = pd.DataFrame(breast_cancer_decisiontree_report).transpose()   
breast_cancer_decisiontree_accuracy = breast_cancer_decisiontree_report['f1-score'][-3:-2][0]    
print("accuracy : ", breast_cancer_decisiontree_accuracy)

"""Decision Tree 모델 성능 'accuracy'는 94.74%이다.
 <br/>Decision Tree 모델의 성능을 변수로 저장한다.

###Random Forest
"""

random_forest = RandomForestClassifier(random_state=32)       
random_forest.fit(x_train, y_train)                          
y_pred = random_forest.predict(x_test)

y_pred

y_test

breast_cancer_random_forest_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(breast_cancer_random_forest_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(breast_cancer_random_forest_confmat.shape[0]):
  for j in range(breast_cancer_random_forest_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=breast_cancer_random_forest_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Random Forest 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(random_forest, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.94
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.92
"""

breast_cancer_randomforest_report = classification_report(y_test, y_pred, output_dict=True)
breast_cancer_randomforest_report = pd.DataFrame(breast_cancer_randomforest_report).transpose()  
breast_cancer_randomforest_accuracy = breast_cancer_randomforest_report['f1-score'][-3:-2][0]    
print("accuracy : ", breast_cancer_randomforest_accuracy)

"""Randomforest 모델의 성능 'accuracy'는 95.61%이다.
<br/>Randomforest 모델의 성능을 변수로 저장한다.

###Support Vector Classifier(SVC)
"""

svc_model = svm.SVC()
svc_model.fit(x_train, y_train)
y_pred = svc_model.predict(x_test)

breast_cancer_svc_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(breast_cancer_svc_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(breast_cancer_svc_confmat.shape[0]):
  for j in range(breast_cancer_svc_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=breast_cancer_svc_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""SVC 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(svc_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.92
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.86
"""

breast_cancer_svc_report = classification_report(y_test, y_pred, output_dict=True)
breast_cancer_svc_report = pd.DataFrame(breast_cancer_svc_report).transpose()     
breast_cancer_svc_accuracy = breast_cancer_svc_report['f1-score'][-3:-2][0]   
print("accuracy : ", breast_cancer_svc_accuracy)

"""SVC 모델의 성능 'accuracy'는 90.35%이다.
<br/>SVC 모델의 성능을 변수로 저장한다.

###SGD Classifier
"""

sgd_model = SGDClassifier()
sgd_model.fit(x_train, y_train)
y_pred = sgd_model.predict(x_test)

wine_sgd_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(wine_sgd_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(wine_sgd_confmat.shape[0]):
  for j in range(wine_sgd_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=wine_sgd_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""SGD 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(sgd_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.90
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.82
"""

breast_cancer_sgd_report = classification_report(y_test, y_pred, output_dict=True)
breast_cancer_sgd_report = pd.DataFrame(breast_cancer_sgd_report).transpose()    
breast_cancer_sgd_accuracy = breast_cancer_sgd_report['f1-score'][-3:-2][0]
print("accuracy : ", breast_cancer_sgd_accuracy)

"""SGD 모델의 성능 'accuracy'는 74.56%이다.
<br/>SGD 모델의 성능을 변수로 저장한다.

###Logistic Regression
"""

logistic_model = LogisticRegression()
logistic_model.fit(x_train, y_train)
y_pred = logistic_model.predict(x_test)

wine_logistic_confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots(figsize=(2.5, 2.5))
ax.matshow(wine_logistic_confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(wine_logistic_confmat.shape[0]):
  for j in range(wine_logistic_confmat.shape[1]):
    ax.text(x=j, y=i,
            s=wine_logistic_confmat[i, j],
            va='center', ha='center')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()

"""Logistic Regression 학습 알고리즘의 성능을 행렬로 펼쳐 놓은 오차 행렬"""

plot_confusion_matrix(logistic_model, x_test, y_test, normalize='all')
plt.show()

"""normalize 매개변수를 사용하여 오차 행렬의 값을 정규화"""

print(classification_report(y_test, y_pred))

"""예측값을 기준으로 한 정답인 예측값의 비율(Precision) 평균 = 0.95
<br/>실제값을 기준으로 한 정답인 예측값의 비율(Recall) 평균 = 0.92
"""

breast_cancer_logistic_report = classification_report(y_test, y_pred, output_dict=True)
breast_cancer_logistic_report = pd.DataFrame(breast_cancer_logistic_report).transpose()     
breast_cancer_logistic_accuracy = breast_cancer_logistic_report['f1-score'][-3:-2][0]       
print("accuracy : ", breast_cancer_logistic_accuracy)

"""Logistic Regression 모델의 성능 'accuracy'는 94.74%이다.
<br/>Logistic Regression 모델의 성능을 변수로 저장한다.

##모델 평가
"""

breast_cancer_model_comparison = [round(breast_cancer_decisiontree_accuracy, 4)
,round(breast_cancer_randomforest_accuracy, 4), round(breast_cancer_svc_accuracy, 4)
,round(breast_cancer_sgd_accuracy, 4), round(breast_cancer_logistic_accuracy, 4)]


breast_cancer_model_name = ['Decision Tree','Random Forest','SVC','SGD', 'Logistic']  


breast_cancer_df = pd.DataFrame({"Model": breast_cancer_model_name,
                  "Accuracy":breast_cancer_model_comparison})
breast_cancer_df_sorted= breast_cancer_df.sort_values('Accuracy',ascending=False)


plt.figure(figsize=(10, 5))                                                  
bar_width = 0.1                                                                

plt.bar('Model', 'Accuracy',data=breast_cancer_df_sorted, color = 'blue')       


for i, v in enumerate(breast_cancer_model_name):
    plt.text(v, breast_cancer_model_comparison[i],breast_cancer_model_comparison[i],      
             fontsize = 9, 
             color='black',
             horizontalalignment='center',  
             verticalalignment='bottom')    

plt.ylim([0.7, 1])   
plt.title('Breast Cancer', fontsize=20)     
plt.xlabel('Model', fontsize=18)     
plt.ylabel('Accuracy', fontsize=18)  
plt.show()

"""Random Forest > Decision Tree = Logistic > SVC > SGD 순으로 성능이 높다.
<br/>따라서 breast_cancer 데이터셋에서는 Random Forest 모델 성능이 탁월하다.

#결론

digits
<br/>SVC > Random Forest > Logistic > SGD > Decision Tree 순으로 성능이 높다.

wine
<br/>Random Forest > Decision Tree = Logistic  >  SGD > SVC 순으로 성능이 높다.

breast_cancer
<br/>Random Forest > Decision Tree = Logistic > SVC > SGD 순으로 성능이 높다.

데이터에 따라 맞는 분석모델이 다르다.
<br/>최적화된 분석 모델의 선택 과정은 어떻게 되는 것일까?
<br/>코딩 이전에 모델을 선택하는 것일까?
<br/>아니면 코딩 이후에 모델을 선택하는 것일까?
<br/>분석자의 도메인 지식으로 알고 있는 데이터의 특성에 따라 분석모델을 선택하는 것일까?
<br/>연구자의 사전 지식을 배제하고 컴퓨터의 분석 결과 수치값만을 고려하여 수학적으로 분석모델을 선택하는 것일까?

#참고문헌

**LMS**
<br/>[jeina7](https://github.com/jeina7)

<br/>**단행본**
<br/>세바스찬 라시카, 바히드 미자리리, 『머신 러닝 교과서 with 파이썬, 사이킷런, 텐서플로』, 박해선 옮긴이, 길벗, 2021
<br/>[오차 행렬](https://thebook.io/080223/ch06/05/01-01/)

<br/>**공식 사이트**
<br/>Sklearn
<br/>[load_digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits)
<br/>[load_wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html?highlight=load_wine#sklearn.datasets.load_wine)
<br/>[load_breast_cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html?highlight=load_breast_cancer#sklearn.datasets.load_breast_cancer)

<br/>**웹사이트**
<br/>[Python matplotlib - 그래프에 값 표시 하기](https://pydole.tistory.com/entry/Python-matplotlib-%EA%B7%B8%EB%9E%98%ED%94%84%EC%97%90-%EA%B0%92-%ED%91%9C%EC%8B%9C-%ED%95%98%EA%B8%B0)
"""