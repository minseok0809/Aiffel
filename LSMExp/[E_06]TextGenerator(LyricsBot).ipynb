{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-06]TextGenerator(LyricsBot).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LSM EXP 06_Aiffel\n",
        "<br/>**6. 작사가 인공지능 만들기**"
      ],
      "metadata": {
        "id": "2uCcvItmOci-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "라이브러리\n",
        "<br/>데이터 정보\n",
        "<br/>데이터 탐색\n",
        "<br/>데이터 시각화\n",
        "<br/>데이터셋의 한계\n",
        "* 문장 토큰화\n",
        "* 데이터셋 노이즈\n",
        "* 전처리 이후의 문장 길이 빈도 분포\n",
        "\n",
        "데이터 전처리\n",
        "* 특수문자, 공백 제거\n",
        "* 문장 길이, 토큰 개수, 기호 제외\n",
        "\n",
        "train, val 데이터 분리\n",
        "<br/>학습 모델\n",
        "<br/>학습 모델 (하이퍼 파라미터 조정)\n",
        "<br/>평가 모델\n",
        "<br/>가사 생성\n",
        "<br/>결론\n",
        "* 하이퍼 파라미터 튜닝\n",
        "* 텍스트 데이터셋\n",
        "\n",
        "참고문헌"
      ],
      "metadata": {
        "id": "66AfZULXBZHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#라이브러리"
      ],
      "metadata": {
        "id": "v6TbNgiSOeb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import re \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "metadata": {
        "id": "gZvVy4njOouQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob**는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다.\n",
        "<br/>단, 조건에 정규식을 사용할 수 없으며 엑셀 등에서도 사용할 수 있는 '*'와 '?'같은 와일드카드만을 지원한다."
      ],
      "metadata": {
        "id": "0pEf5ZnoQviL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tensorflow**는 구글이 개발한 오픈소스 소프트웨어 딥러닝 및 머신러닝 라이브러리이다.\n",
        "<br/>수학 계산식과 데이터의 흐름을 노드와 엣지를 사용한 방향성 그래프, 데이터 플로우 그래프로 나타낸다."
      ],
      "metadata": {
        "id": "w-LFuuo9Oeiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**numpy**는 array 단위로 벡터와 행렬을 계산한다. 이 라이브러리를 사용하기 위해서는 선형대수학 지식이 필요하다."
      ],
      "metadata": {
        "id": "Acm1V6-fvfoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**os(Operating System)**는 운영체제에서 제공되는 여러 기능을 파이썬에서 수행한다. <br/>예를 들어, 파일 복사, 디렉터리 생성, 파일 목록을 구할 수 있다."
      ],
      "metadata": {
        "id": "ESWq3NcjvufN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**re(regex)**는 특정 문자 또는 문자열이 존재하는지나 어느 위치에 있는지와 같은 기능을 제공하는 정규표현식 라이브러리이다."
      ],
      "metadata": {
        "id": "8-_H8De9vfDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**matplotlib**은 다양한 데이터와 학습 모델을 시각화한다."
      ],
      "metadata": {
        "id": "UF9k9DtZIg4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **sklearn.model_selection**는 훈련 데이터, 테스트 데이터를 분리한다."
      ],
      "metadata": {
        "id": "92-N05wpz63c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 정보"
      ],
      "metadata": {
        "id": "Vy4iUr53Oeon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[song_lyrics](https://aiffelstaticprd.blob.core.windows.net/media/documents/song_lyrics.zip)"
      ],
      "metadata": {
        "id": "eZ3uOVAEOcnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "49명의 가수의 영어 노래 가사를 수집한 텍스트 파일 모음 데이터셋이다.\n",
        "<br/>가사 생성기(lyric Generator)를 만드는 데 사용된다."
      ],
      "metadata": {
        "id": "K-3GbtyGO-5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 탐색"
      ],
      "metadata": {
        "id": "0BleA9rSO6mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYEfeIDjXFFS",
        "outputId": "0358716b-e07b-4959-c2cb-019111f9f764"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file_path = '/content/drive/MyDrive/LMS/song_lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMHkEHYis4If",
        "outputId": "942dc0a1-ccac-461b-ce4b-bb1178bdc625"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['\"Don\\'t worry about a thing,', \"'Cause every little thing gonna be all right.\", 'Singin\\': \"Don\\'t worry about a thing,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 데이터셋은 187088 문장으로 구성되어 있다.\n"
      ],
      "metadata": {
        "id": "UKSDz4tbO6eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**주의사항**\n",
        "<br/>주소를 적을 때 txt_file_path = '.../*'의 끝에 별 *를 적어야 한다.\n",
        "<br/>별을 빠뜨리면 IsADirectoryError: [Errno 21]라는 에러가 발생한다."
      ],
      "metadata": {
        "id": "FWDUByl71Ls8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob.glob**는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다. <br/>특정 파일 경로 안에 있는 파일명을 불러왔다.\n"
      ],
      "metadata": {
        "id": "u3PBTdg2tg22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**splitlines**은 줄 단위로 문자열을 리스트로 변환한다.\n",
        "<br/>그런데 split(\"\\n')도 splitlines()와 동일한 결과값을 보여주기 때문에\n",
        "<br/>문자열을 리스트로 변경할 때는 대부분 split()을 사용한다.\n"
      ],
      "metadata": {
        "id": "c_2KKH6L8s-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extend**는 확장 함수로 다른 리스트를 연결한다.\n",
        "<br/>여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다."
      ],
      "metadata": {
        "id": "snfQJyag28pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extend**와 **append**, **insert(a,b)**는 다른 형태의 추가 함수이니 때에 따라 다르게 쓴다.\n",
        "<br/>**append**는 리스트의 끝에 x 값을 추가한다.\n",
        "<br/>**insert(a,b)**는 리스트의 a 위치에 b 값을 추가한다."
      ],
      "metadata": {
        "id": "84GhFnAM-BIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 시각화"
      ],
      "metadata": {
        "id": "CTdZ96tJVUom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**matplotlib**을 이용해 문장 길이의 빈도 분포를 시각화한다."
      ],
      "metadata": {
        "id": "STBljIZRY_tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in raw_corpus)\n",
        "print('최대 길이 : %d' % max_len)\n",
        "print('최소 길이 : %d' % min(len(l) for l in raw_corpus if len(l) >= 1))\n",
        "print('평균 길이 : %f' % (sum(map(len, raw_corpus))/len(raw_corpus)))\n",
        "plt.hist([len(s) for s in raw_corpus if len(s) >= 1], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "SDlRs-eBJJJD",
        "outputId": "4f896a00-90b6-4f3a-8afe-14b6e169b541"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 1465\n",
            "최소 길이 : 1\n",
            "평균 길이 : 34.977070\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1,000이 넘는 지나치게 긴 길이가 있는 문장이 존재한다.\n",
        "<br/>왜 그럴까?"
      ],
      "metadata": {
        "id": "nEKXuIo1TbBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "print를 이용해 직접 1,000이 넘는 문장을 출력해서 문제 원인을 확인한다."
      ],
      "metadata": {
        "id": "FN4K1gllVnlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in raw_corpus:\n",
        "  if len(i) >= 1000:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYfbGIyUJ4hq",
        "outputId": "34b616bd-71fb-41e0-9df6-a4c6b9a89f08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WRITERS RUSSELL BROWN, IRWIN LEVINE I'm comin' home, I've done my time Now I've got to know what is and isn't mine If you received my letter telling you I'd soon be free Then you'll know just what to do if you still want me If you still want me Just tie a yellow ribbon 'round the old oak tree It's been way too long, do you still want me? If I don't see a ribbon 'round the old oak tree I'll just stay on the bus, forget about us, put the blame on me If I don't see a yellow ribbon 'round the old oak tree Bus driver, please look for me 'Cause I couldn't bear to see what I might see I'm really still in prison and my love, he holds the key A simple yellow ribbon's all I need to set me free I wrote and told him please... Just tie a yellow ribbon 'round the old oak tree It's been way too long, do you still want me? If I don't see a ribbon 'round the old oak tree I'll just stay on the bus, forget about us, put the blame on me If I don't see a ribbon 'round the old oak tree Tie a yellow ribbon 'round that old oak tree I'm coming home Now the whole dang bus is cheerin' and I can't believe I see a hundred yellow ribbons tied 'round the old oak tree I'm comin' home, I'm glad you waited for me Tie a yellow ribbon 'round the old oak tree Tie a ribbon 'round the old oak tree Tie a ribbon 'round the old oak tree Tie a yellow ribbon if you still want me Tie a yellow ribbon 'round the old oak tree Tie a yellow ribbon 'round the old oak tree Here you come again\n",
            "Another one (Chorus) Standing on the mountain top, counting all this money, laughing at you haters, ain't nothing gonna save yeah. Yeah, Welcome Back, Another small Buy, we global , Feel my pain They can't deal witha nigga like me. Cus I keep it so hood, yeah I keep it so Street. The industry hate but they gotta see me. Turn your tvs on Bet all you see is me. Nah I ain't playing why you trying to blame me, Might as well hate the world instead of hating on me. Pussy ass nigga (And we taking over, One paper bag at a time) I need that clearence feed me more, come and think about it you need it more Uhh I am miami I do it for miami, 24 and 7 trays yeah nigga we born and raised. See this, Joe Crack we showed them. Damn right I'm so concieted. I know it made you sick, guess what it made me rich. Shout out to all my DJ's. Projects I know you feel me. Thank god for rubber bands. Phantoms on paper tags. This oens for all the fans. We the best. (Chorus) Standing on the mountain top, counting all this money, laughing at you haters, ain't nothing gonna save yeah. x2 I Introduce you to ace hood!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 자체의 문제이다.\n",
        "<br/>웹크롤링 당시 줄바꿈되지 않은 채 여러 문장이 하나의 문장으로 이어져 txt 파일에 담긴 것이다."
      ],
      "metadata": {
        "id": "s5Es1m2TTic-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터셋의 한계"
      ],
      "metadata": {
        "id": "Wb26WWs7wQpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##문장 토큰화"
      ],
      "metadata": {
        "id": "CwBMfaTHwcSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 토큰화를 하는 함수 **nltk.tokenize**의 **sent_tokenize**가 있으나\n",
        "<br/>마침표를 기준으로 문장을 나누기 때문에 길이가 1000이 넘는 문장을 구분할 수 없다.\n",
        "<br/>이 문장 안에는 마침표가 존재하지 않는다."
      ],
      "metadata": {
        "id": "qcA4ueaDvlbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> WRITERS RUSSELL BROWN, IRWIN LEVINE I'm comin' home, I've done my time Now I've got to know what is and isn't mine If you receive (생략)"
      ],
      "metadata": {
        "id": "wnwNEBLewLml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터셋 노이즈"
      ],
      "metadata": {
        "id": "YA_JKVN9zDYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entire_sentence_num = 0\n",
        "for i in raw_corpus:\n",
        "  entire_sentence_num += 1\n",
        "\n",
        "print('전체 문장 개수 : %d' % entire_sentence_num)\n",
        "\n",
        "fifteen_sentence_num = 0\n",
        "for i in raw_corpus:\n",
        "  if len(i) <= 14:\n",
        "    fifteen_sentence_num += 1\n",
        "\n",
        "print('문장 길이 15 미만의 문장 개수 : %d' % fifteen_sentence_num)\n",
        "\n",
        "num_difference = entire_sentence_num - fifteen_sentence_num\n",
        "print('문장 길이 15 기준 전처리 이후 제외되는 문장 개수 : %d' % num_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fie9vJGt0xxE",
        "outputId": "d7411efa-f747-48b3-a342-f310236d74df"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 문장 개수 : 187088\n",
            "토큰 15개 미만의 문장 개수 : 23268\n",
            "토큰 15개 기준 전처리 이후 제외되는 문장 개수 : 163820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리를 통해 지나치게 긴 문장을 제외한 상황을 가정한다."
      ],
      "metadata": {
        "id": "NPDPv6rBI3Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이 15를 기준으로 전처리 이후 제외된 문장의 개수는 23268개이다."
      ],
      "metadata": {
        "id": "sRWTx0AT2Jm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23000개가 넘는 문장의 데이터를 잃지만 전처리를 통해 정제된 데이터를 얻을 수 있다."
      ],
      "metadata": {
        "id": "6fyhWtBJo8il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_data_rate = round((23268 / 187088) * 100, 2)\n",
        "print('전처리로 제외된 데이터 비율 : %.2f ' % delete_data_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6AVPhtqC2x7",
        "outputId": "8a55c7db-9bb7-40f7-ea39-aefd5f9a2be8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리로 제외된 데이터 비율 : 12.44 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리로 전체 데이터의 12.44%가 제외된다."
      ],
      "metadata": {
        "id": "4CCb0UyjC0Cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "웹크롤링으로 가져온 데이터셋의 노이즈가 그만큼 많다는 것이다."
      ],
      "metadata": {
        "id": "hmyOf96kEhW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이가 15를 넘어가는 문장을 제외하는 방법이 아닌 대안이 있어야하지 않을까?\n"
      ],
      "metadata": {
        "id": "K7Z_VMRvEour"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "웹에 업로드되어있는 데이터 자체의 문제로 인해 문장의 끝에 마침표가 없어서 \n",
        "<br/>여러 문장이 합쳐져 '지나치게 긴 하나의 문장'이 된 노이즈를 \n",
        "<br/>여러 문장으로 분할하여 '하나의 문장'이라는 정제된 데이터로 변환시켜주는 \n",
        "<br/>전처리 기술이 개발되어야하지 않을까?"
      ],
      "metadata": {
        "id": "o3mg75Hpu02p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 전처리 기술이 발달이 되면 12.44%와 같은 데이터양의 축소를 하지 않고\n",
        "<br/>더 많은 웹크롤링 텍스트 데이터의 양을 확보할 수 있을 것이다."
      ],
      "metadata": {
        "id": "Of2xScvFFfiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##전처리 이후의 문장 길이 빈도 분포"
      ],
      "metadata": {
        "id": "EksJKbWBGfQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(i) for i in raw_corpus if len(i) <= 14])\n",
        "sum_len = sum([len(i) for i in raw_corpus if 1 <= len(i) <= 14])\n",
        "mean_len = sum_len / fifteen_sentence_num\n",
        "\n",
        "print('최대 길이 : %d' % max_len)\n",
        "print('최소 길이 : %d' % min(len(l) for l in raw_corpus))\n",
        "print('평균 길이 : %f' % mean_len)\n",
        "plt.hist([len(s) for s in raw_corpus if 1 <= len(s) <= 14], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "fnSz7KtNzAwL",
        "outputId": "eab0d58c-7359-4f6a-d63c-f95795846bde"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 14\n",
            "최소 길이 : 0\n",
            "평균 길이 : 5.154203\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 전처리"
      ],
      "metadata": {
        "id": "UKcT31lpO62T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##특수문자, 공백 제거"
      ],
      "metadata": {
        "id": "Z1SbwBLgUJ21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() \n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    return sentence\n",
        "\n",
        "\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl9Q46mhub91",
        "outputId": "050ada7e-de74-4b81-cc55-dd198b24dbcf"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lower.strip**은 소문자로 바꾸고, 양쪽 공백을 지운다.\n"
      ],
      "metadata": {
        "id": "UGdC7GMZBpj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sub**을 이용해 특수문자 양쪽에 공백을 넣는다.\n",
        "<br/>여러개의 공백은 하나의 공백으로 바꾼다.\n",
        "<br/>a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾼다."
      ],
      "metadata": {
        "id": "W74c0bm8ESvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**strip**은 다시 양쪽 공백을 지운다."
      ],
      "metadata": {
        "id": "Ys_1f9oKEWe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 시작에는 start, 끝에는 end를 추가한다."
      ],
      "metadata": {
        "id": "BA8Ik8aBEjgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##문장 길이, 토큰 개수, 기호 제외"
      ],
      "metadata": {
        "id": "wN27Y5Hp9h-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "corpus[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS28S5c4ud4W",
        "outputId": "ca08f656-6c1a-43aa-91c5-59db16779d54"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> don t worry about a thing , <end>',\n",
              " '<start> cause every little thing gonna be all right . <end>',\n",
              " '<start> singin don t worry about a thing , <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "corpus 리스트에 정제된 문장을 담는다."
      ],
      "metadata": {
        "id": "FogHifOIG-kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이가 0인 문장은 넘어간다."
      ],
      "metadata": {
        "id": "rYQf8VipHjkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막에 기호 :가 있는 문장은 리스트에 담지 않고 넘어간다."
      ],
      "metadata": {
        "id": "laby64YG9e0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    \n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "id": "hdTeXoduuhDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6d6c71-9ccd-422a-8d69-cf24cca9eaf1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2   37   15 ...    0    0    0]\n",
            " [   2   67  133 ...    0    0    0]\n",
            " [   2 1551   37 ...    0    0    0]\n",
            " ...\n",
            " [   2   45  900 ...    0    0    0]\n",
            " [   2   45   66 ...    0    0    0]\n",
            " [   2    8   83 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f375b898e10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer**는 내부 단어장의 크기를 12000로 갖는다.\n",
        "<br/>단어장에 포함되지 못한 단어는 'unk'로 저장한다. "
      ],
      "metadata": {
        "id": "RL4x_ig_qPh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "준비한 tokenizer를 이용해 corpus를 Tensor로 변환한다."
      ],
      "metadata": {
        "id": "bS8FHiQYqYRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**padding='post'**는 입력 데이터의 시퀀스 길이를 일정하게 맞춘다.\n",
        "<br/>만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다."
      ],
      "metadata": {
        "id": "mw3DuFohqZpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**maxlen=15**는 토큰의 개수가 15개 넘어가는 문장을 제외한다.\n",
        "<br/>지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거할 필요가 있다. "
      ],
      "metadata": {
        "id": "8MCwckVNBSzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:3, :10])"
      ],
      "metadata": {
        "id": "aVVdFqWAukXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0af0209-2535-43f1-b860-af94fef1f091"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2   37   15  717  113    9  181    4    3    0]\n",
            " [   2   67  133  117  181   96   27   24   84   20]\n",
            " [   2 1551   37   15  717  113    9  181    4    3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성된 텐서 데이터를 3번째 행, 10번째 열까지만 출력한다."
      ],
      "metadata": {
        "id": "GgwitDCA1FLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "id": "PBMjFzwNuk0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25eabdb7-e911-47de-f695-2a42e6525859"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " tokenizer에 구축된 단어 사전의 인덱스를 통해 단어 사전이 어떻게 구축되었는지 확인한다."
      ],
      "metadata": {
        "id": "5f-A7ha41Q-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_input = tensor[:, :-1]  \n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "id": "hMwm8YKbunbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83fd3c37-465e-4b2e-8907-a5482e392f3d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2  37  15 717 113   9 181   4   3   0   0   0   0   0]\n",
            "[ 37  15 717 113   9 181   4   3   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor에서 마지막 토큰을 잘라내서 소스 문장 **src_input**을 생성한다.\n"
      ],
      "metadata": {
        "id": "J0iu6JaG1hJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막 토큰은 end가 아니라 pad일 가능성이 높다."
      ],
      "metadata": {
        "id": "nW08LPLo1n07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor에서 start를 잘라내서 타겟 문장 **tgt_input**을 생성한다."
      ],
      "metadata": {
        "id": "5holoN2W1oxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train, val 데이터 분리"
      ],
      "metadata": {
        "id": "A9QkL92ktsrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
        "                                                    tgt_input,    \n",
        "                                                    test_size=0.2,   \n",
        "                                                    random_state=1)  \n",
        "\n",
        "print('enc_train 개수: ', len(enc_train),', enc_val 개수: ', len(enc_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIoKJQwU2DgM",
        "outputId": "c373ad68-c165-41fc-a8d2-ed89f07afb31"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc_train 개수:  140599 , enc_val 개수:  35150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sklearnn** 모듈의 **train_test_split**를 이용해 데이터셋 분리를 한다.\n",
        "<br/>소스 문장 **src_input**을 특징 데이터, 타겟 문장 **tgt_input**을 정답 데이터로 사용한다.\n",
        "<br/>전체의 20%를 평가 데이터로 사용한다.\n",
        "<br/>**random_state**는 데이터를 무작위로 정렬하여 분리한다."
      ],
      "metadata": {
        "id": "-aIbV7qe1928"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Source Train: ', enc_train.shape)\n",
        "print('Target Train: ', dec_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QQc_zIAKZz",
        "outputId": "6ba2e142-e18c-408d-9215-733107ba4fa7"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Train:  (140599, 14)\n",
            "Target Train:  (140599, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "LdxSEnrouBJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f75140-2153-479d-de99-d6886c3cb4ee"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WigPZz2O5ZCr",
        "outputId": "4e37c375-949a-4a07-9f18-2df350bbab31"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch size**는 한 번에 네트워크에 넘겨주는 데이터의 수이다.\n",
        "<br/>trade off로서 컴퓨터의 메모리 문제 때문에 분할해서 학습하는 것이다.\n",
        "\n",
        "<br/>140599 ≥ 140544 = 256 * 549\n",
        "<br/>train data num = batch size * step\n",
        "\n",
        "<br/>35150 = 256 * 137 ≥ 35072\n",
        "<br/>validation data num = batch size * step\n",
        "\n",
        "<br/>주의할 점은 epoch와 batch size는 다른 개념이다.\n",
        "<br/>epoch = batch size * step\n"
      ],
      "metadata": {
        "id": "ICTY6YIpaXNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**vocab size**는 tokenizer가 구축한 단어사전 내 7000개, 0 : pad를 포함하여 7001개를 포함한다."
      ],
      "metadata": {
        "id": "II-5WOeN4kqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학습 모델"
      ],
      "metadata": {
        "id": "XG9ld0Xvtzhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.keras.Model을 Subclassing하는 방식으로 만든다.\n",
        "<br/>Embedding 레이어 1개, LSTM 레이어 2개, Dense 레이어 1개로 구성된다"
      ],
      "metadata": {
        "id": "P3efBSKi5_Tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "EJWb3Pjhu0O9"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 모델 **model1**\n",
        "<br/>하이퍼 파라미터를 조정한 학습 모델 **model2**\n",
        "<br/>평가 모델 **model3**으로 설정한다."
      ],
      "metadata": {
        "id": "3tMryZ5u7nlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model1 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "nnDRgmqr7mNr"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding 레이어**는 이 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꾼다.\n",
        "<br/>워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현(representation)으로 사용된다."
      ],
      "metadata": {
        "id": "OEYdPyFl6WPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model1(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "018DgCW7vuZm",
        "outputId": "8431ca55-fdeb-4a68-8df7-9ec496f0f918"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 2.59152963e-04,  2.55710707e-04,  1.89954662e-04, ...,\n",
              "          1.86881778e-04, -3.89832217e-04,  8.52760568e-05],\n",
              "        [ 2.95058329e-04,  5.36240463e-04,  2.46459706e-04, ...,\n",
              "         -4.28641688e-05, -6.16939215e-04, -1.75927722e-04],\n",
              "        ...,\n",
              "        [-1.45345042e-03, -2.98856728e-04,  1.50849461e-03, ...,\n",
              "          7.21762364e-04, -1.26660115e-03, -1.49171310e-03],\n",
              "        [-1.55146315e-03, -2.77278188e-04,  1.66823075e-03, ...,\n",
              "          9.07679729e-04, -1.40510674e-03, -1.38349598e-03],\n",
              "        [-1.61832012e-03, -2.38572218e-04,  1.83011149e-03, ...,\n",
              "          1.09559565e-03, -1.55437400e-03, -1.24894211e-03]],\n",
              "\n",
              "       [[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 2.32708277e-04,  4.01601574e-05,  3.64393229e-04, ...,\n",
              "         -2.13495383e-04, -3.69870133e-04, -5.45612929e-05],\n",
              "        [ 2.43278890e-04,  1.26326908e-04,  5.56675135e-04, ...,\n",
              "         -3.99501441e-04, -2.66939693e-04, -2.72948062e-04],\n",
              "        ...,\n",
              "        [-6.36863231e-04, -1.90923020e-04,  8.16528685e-04, ...,\n",
              "         -2.82290293e-05, -1.09210494e-03, -1.30721179e-04],\n",
              "        [-8.81975458e-04, -2.56893865e-04,  9.38988349e-04, ...,\n",
              "          1.15956391e-04, -1.15888240e-03, -3.42365820e-04],\n",
              "        [-1.08783343e-03, -2.90647731e-04,  1.08899863e-03, ...,\n",
              "          2.74861988e-04, -1.23422930e-03, -4.92655265e-04]],\n",
              "\n",
              "       [[-1.14390205e-04,  1.74208748e-04, -8.42063819e-05, ...,\n",
              "         -9.88146057e-05, -9.47283479e-05,  1.18151191e-04],\n",
              "        [-7.33234847e-05,  1.59583476e-04, -2.05216813e-04, ...,\n",
              "         -2.12523111e-04, -1.79534705e-04,  8.40782668e-05],\n",
              "        [-9.64284845e-05,  1.76797723e-04, -1.29209526e-04, ...,\n",
              "         -2.01418748e-04,  1.65001082e-04,  2.88352021e-05],\n",
              "        ...,\n",
              "        [-4.30157597e-05, -1.03563815e-03, -4.01703117e-04, ...,\n",
              "         -5.92375291e-04,  7.68279599e-04, -1.42922904e-03],\n",
              "        [ 1.30405431e-04, -1.12099748e-03, -4.13678528e-04, ...,\n",
              "         -7.10174500e-04,  5.81918692e-04, -1.29671430e-03],\n",
              "        [ 1.96759909e-04, -1.26466295e-03, -2.09055055e-04, ...,\n",
              "         -8.03500938e-04,  5.52995305e-04, -1.34560058e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 4.45868733e-04, -6.34604839e-06,  2.11862905e-04, ...,\n",
              "          1.50921871e-04, -4.27435065e-04,  1.46675404e-04],\n",
              "        [ 6.05857524e-04,  1.09891131e-04,  2.92338693e-04, ...,\n",
              "         -1.00404061e-04, -5.06456359e-04,  5.34670835e-05],\n",
              "        ...,\n",
              "        [-1.53432484e-03, -1.04783452e-04,  1.02655916e-03, ...,\n",
              "          6.57497498e-04, -1.55247527e-03, -8.26029107e-04],\n",
              "        [-1.69357657e-03, -1.45272788e-04,  1.20541314e-03, ...,\n",
              "          8.02519149e-04, -1.68349501e-03, -8.24240560e-04],\n",
              "        [-1.80096889e-03, -1.63151693e-04,  1.39201817e-03, ...,\n",
              "          9.56979056e-04, -1.80491409e-03, -7.86648772e-04]],\n",
              "\n",
              "       [[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 2.75331025e-04, -2.25824682e-04,  1.10245774e-05, ...,\n",
              "         -1.69041305e-04, -1.96317691e-04, -1.80546704e-04],\n",
              "        [ 5.77269122e-04, -4.63959877e-04, -2.86856026e-04, ...,\n",
              "         -2.11278355e-04, -2.27828477e-05, -6.31923758e-05],\n",
              "        ...,\n",
              "        [ 1.23042986e-03, -7.04566541e-04, -7.71550054e-04, ...,\n",
              "         -8.81591332e-05, -1.02837417e-04,  1.06061553e-03],\n",
              "        [ 1.10328384e-03, -7.54650333e-04, -7.15148402e-04, ...,\n",
              "          1.31444895e-05, -7.53910645e-05,  1.09814468e-03],\n",
              "        [ 7.37035472e-04, -1.01889414e-03, -6.86899235e-04, ...,\n",
              "          1.09044267e-04, -1.19726596e-04,  1.10431400e-03]],\n",
              "\n",
              "       [[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 2.57891428e-04,  3.30581650e-04,  9.49058085e-05, ...,\n",
              "          5.49371616e-05, -1.98592199e-04,  1.84978242e-04],\n",
              "        [ 2.55690276e-04,  4.48251056e-04, -1.42255367e-05, ...,\n",
              "         -4.18134732e-05, -6.65543121e-05,  2.51268473e-04],\n",
              "        ...,\n",
              "        [ 8.47709482e-04, -5.05258038e-04, -1.34250836e-03, ...,\n",
              "          4.81680618e-04,  4.98065550e-04,  2.67217110e-04],\n",
              "        [ 7.34813046e-04, -4.15833958e-04, -1.25654042e-03, ...,\n",
              "          8.36043968e-04,  4.22425917e-04,  1.66335376e-04],\n",
              "        [ 6.41188642e-04, -2.30575213e-04, -1.14306109e-03, ...,\n",
              "          1.07000675e-03,  4.34918620e-04,  2.14115935e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋에서 데이터 한 배치만 불러온다.\n",
        "<br/>한 배치만 불러온 데이터를 모델에 넣는다."
      ],
      "metadata": {
        "id": "MZ9TZ7CV44W7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model의 input shape가 결정되면서 model.build()가 자동으로 호출된다.\n",
        "<br/>"
      ],
      "metadata": {
        "id": "6cRD5_NN6x7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "5gcqszZDu3T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58f230a-20a1-43f4-b23f-861e86c1bb38"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     multiple                  3072256   \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              multiple                  8392704   \n",
            "                                                                 \n",
            " dense_7 (Dense)             multiple                  12301025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model1.compile(loss=loss, optimizer=optimizer)\n",
        "model1.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "id": "OMdkMRFbu7KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9e8c33-4b16-456a-c9e4-201ca0daf8e1"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 85s 151ms/step - loss: 3.6903\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 85s 155ms/step - loss: 3.1976\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 87s 158ms/step - loss: 3.0198\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.8836\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.7654\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.6574\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.5567\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 85s 155ms/step - loss: 2.4606\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 87s 158ms/step - loss: 2.3701\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.2846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f375bad9410>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1**의 train loss는 2.2846이다."
      ],
      "metadata": {
        "id": "Yjf-mQkviLnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학습 모델 (하이퍼 파라미터 조정)"
      ],
      "metadata": {
        "id": "K9h4eV6w8jf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**에서 하이퍼 파라미터를 다음과 같이 조정한다.\n",
        "> embedding_size = 256 → 600\n",
        "<br/>hidden_size = 1024 → 2048\n"
      ],
      "metadata": {
        "id": "QOEvQmQcZsQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 600\n",
        "hidden_size = 2048\n",
        "model2 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "jo9Fpr7yMEqr"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model2(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO9qatX-MEtR",
        "outputId": "16109d0a-4272-4f3a-91b7-08eb0fbbb208"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 8.98761442e-04,  6.57740107e-04, -3.33451433e-04, ...,\n",
              "         -2.16741842e-04, -4.78792441e-04,  9.14298289e-04],\n",
              "        [ 1.41155138e-03,  9.28761670e-04, -5.09645382e-04, ...,\n",
              "         -4.61590738e-04, -7.08812498e-04,  1.24689669e-03],\n",
              "        ...,\n",
              "        [ 4.09965316e-04,  1.93638250e-03, -1.03193463e-03, ...,\n",
              "         -4.12586407e-04, -8.39014887e-04,  8.14105952e-05],\n",
              "        [ 4.07122425e-04,  1.88428944e-03, -8.22052360e-04, ...,\n",
              "         -6.74766547e-04, -1.82157048e-04,  8.29519413e-05],\n",
              "        [ 6.47721579e-04,  1.54634879e-03, -9.48799716e-04, ...,\n",
              "         -7.36404036e-04,  3.55802244e-04,  2.61138863e-04]],\n",
              "\n",
              "       [[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 4.74448723e-04,  5.00936818e-04, -4.71094507e-04, ...,\n",
              "         -1.83796496e-04, -4.41196287e-04,  7.38874485e-04],\n",
              "        [ 4.39904834e-04,  9.11371084e-04, -4.30403219e-04, ...,\n",
              "         -8.78286082e-05, -7.60912197e-04,  9.24833585e-04],\n",
              "        ...,\n",
              "        [ 1.05535868e-03, -3.51592596e-03, -2.23470270e-03, ...,\n",
              "          1.87906518e-03,  9.07104186e-05,  5.78694465e-03],\n",
              "        [ 1.12555467e-03, -4.18851804e-03, -2.54234346e-03, ...,\n",
              "          2.30042124e-03,  1.25255596e-04,  6.19129650e-03],\n",
              "        [ 1.18808181e-03, -4.79222462e-03, -2.83133937e-03, ...,\n",
              "          2.72215647e-03,  1.40567034e-04,  6.52117562e-03]],\n",
              "\n",
              "       [[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 6.49530673e-04,  3.53667361e-04, -4.17524629e-04, ...,\n",
              "          3.30587795e-06, -6.87774562e-04,  6.13192969e-04],\n",
              "        [ 5.30434016e-04,  3.33666481e-04, -6.56539225e-04, ...,\n",
              "         -1.68633531e-04, -7.51762651e-04,  6.23264757e-04],\n",
              "        ...,\n",
              "        [ 7.15827802e-04, -3.44489398e-03, -1.87212566e-03, ...,\n",
              "          1.06152100e-03,  2.54836887e-05,  5.29390294e-03],\n",
              "        [ 7.43111654e-04, -4.08046087e-03, -2.11683987e-03, ...,\n",
              "          1.53221563e-03,  7.42293851e-05,  5.78418933e-03],\n",
              "        [ 7.93604180e-04, -4.66150977e-03, -2.36169831e-03, ...,\n",
              "          2.01556832e-03,  1.04738428e-04,  6.20274711e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.19782846e-04,  1.20092973e-05,  2.00391747e-04, ...,\n",
              "         -4.28757412e-05,  3.34811542e-04, -2.37958357e-05],\n",
              "        [-3.14322562e-04,  2.64373048e-05, -2.20993272e-04, ...,\n",
              "         -2.28609861e-04,  4.28396132e-04,  1.84476492e-04],\n",
              "        [-8.17432126e-04,  2.11553241e-04, -3.88824352e-04, ...,\n",
              "         -5.52269397e-04,  3.56084871e-04,  4.92595835e-04],\n",
              "        ...,\n",
              "        [-5.50310477e-04, -7.62939279e-04, -8.40673922e-04, ...,\n",
              "          6.54875359e-04, -2.34088402e-05,  6.61819417e-04],\n",
              "        [-1.52402601e-04, -6.70581707e-04, -8.27453041e-04, ...,\n",
              "          9.52517381e-04, -3.52063100e-04,  9.55199066e-04],\n",
              "        [ 1.29883992e-04, -2.97559251e-04, -1.20047468e-03, ...,\n",
              "          1.15642615e-03, -5.10791899e-04,  1.02332688e-03]],\n",
              "\n",
              "       [[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 7.28467887e-04,  6.26336318e-04, -4.69070539e-04, ...,\n",
              "         -1.39354161e-04, -3.97730793e-04,  6.72027352e-04],\n",
              "        [ 1.10020372e-03,  8.09218385e-04, -7.09761283e-04, ...,\n",
              "         -3.11494427e-04, -3.81056307e-04,  9.04387794e-04],\n",
              "        ...,\n",
              "        [ 2.65442720e-03, -6.10842602e-04, -1.33034517e-03, ...,\n",
              "          4.69435152e-04,  1.47635781e-03, -1.21218420e-03],\n",
              "        [ 2.72247009e-03, -9.79051576e-04, -1.49642560e-03, ...,\n",
              "          4.92505089e-04,  1.73099514e-03, -6.43580395e-04],\n",
              "        [ 2.63959426e-03, -1.46284827e-03, -1.61004334e-03, ...,\n",
              "          5.21137321e-04,  1.82083866e-03,  1.51046974e-04]],\n",
              "\n",
              "       [[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 2.59071094e-04,  2.99780368e-04, -8.76280363e-04, ...,\n",
              "         -2.96698854e-04, -3.32444411e-04,  8.44902126e-04],\n",
              "        [ 2.44192415e-05,  2.09347039e-04, -8.61907611e-04, ...,\n",
              "         -8.69373558e-04, -1.06710315e-04,  1.07394985e-03],\n",
              "        ...,\n",
              "        [-1.38785821e-04,  4.92032792e-04, -4.16254188e-04, ...,\n",
              "          1.20814424e-03,  6.67011715e-04,  2.39049376e-04],\n",
              "        [ 1.37107112e-04,  4.60390293e-05, -3.79837467e-04, ...,\n",
              "          1.24522671e-03,  8.76089325e-04,  4.66161815e-04],\n",
              "        [ 3.33281059e-04, -5.66424220e-04, -3.71147151e-04, ...,\n",
              "          1.31225656e-03,  1.01095892e-03,  9.87590058e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TZJwHMbMEv0",
        "outputId": "7d7a3eec-9aff-4d73-ab0c-a55432452797"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    multiple                  7200600   \n",
            "                                                                 \n",
            " lstm_30 (LSTM)              multiple                  21700608  \n",
            "                                                                 \n",
            " lstm_31 (LSTM)              multiple                  33562624  \n",
            "                                                                 \n",
            " dense_15 (Dense)            multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,053,881\n",
            "Trainable params: 87,053,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model2.compile(loss=loss, optimizer=optimizer)\n",
        "model2.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM8qTaMVMEyb",
        "outputId": "1322ebbd-9346-4b01-f92f-32bf4bb51be0"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 247s 447ms/step - loss: 3.4829\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 250s 455ms/step - loss: 2.8911\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 250s 455ms/step - loss: 2.5695\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 251s 457ms/step - loss: 2.2626\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.9673\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 251s 457ms/step - loss: 1.6924\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.4513\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.2525\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.1037\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.0074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36d75cb490>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**의 train loss는 1.0074이다."
      ],
      "metadata": {
        "id": "_4fWdrvLiIRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#평가 모델"
      ],
      "metadata": {
        "id": "YvKJIe__JPf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 좋은 **model2**의 하이퍼 파라미터 값을 평가 모델 **model3**에 사용한다.\n",
        "> embedding_size = 600\n",
        "<br/>hidden_size = 2048\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ucL7-Sg_ZHfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 600\n",
        "hidden_size = 2048\n",
        "model3 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "9bVJmLmlJX5K"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in val_dataset.take(1): break\n",
        "\n",
        "model3(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TwG-IO0JYIb",
        "outputId": "f0871edb-7296-4848-d3ec-2b646fc83790"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-2.4457051e-05,  4.7833633e-05, -3.4179442e-04, ...,\n",
              "          5.9708761e-04, -4.0994101e-04, -4.7562204e-04],\n",
              "        [ 1.5796947e-04,  1.2700519e-04, -3.1310885e-04, ...,\n",
              "          6.8283046e-04, -6.1571982e-04, -4.6007056e-04],\n",
              "        ...,\n",
              "        [-3.7857862e-03,  3.4553516e-03,  1.9701649e-03, ...,\n",
              "         -2.2496835e-03, -1.9925165e-03,  1.0253132e-03],\n",
              "        [-4.2156843e-03,  3.6314451e-03,  2.3188677e-03, ...,\n",
              "         -2.4916297e-03, -2.3248915e-03,  1.1366366e-03],\n",
              "        [-4.5746313e-03,  3.7324128e-03,  2.6403668e-03, ...,\n",
              "         -2.7112467e-03, -2.6112793e-03,  1.2271563e-03]],\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [ 4.8940892e-05,  4.5891435e-04, -5.1036256e-04, ...,\n",
              "          1.1486997e-04, -4.8445768e-04, -1.4668293e-04],\n",
              "        [ 4.4289662e-04,  3.5861350e-04, -6.7317701e-04, ...,\n",
              "          2.4762345e-04, -6.1232672e-04, -2.7315447e-05],\n",
              "        ...,\n",
              "        [-1.6278720e-03,  1.7103950e-03, -6.7396596e-04, ...,\n",
              "         -1.4808499e-04, -5.5205228e-04,  1.6370657e-03],\n",
              "        [-2.3321689e-03,  2.3329102e-03, -2.7159051e-04, ...,\n",
              "         -6.4228685e-04, -9.2077453e-04,  1.6669659e-03],\n",
              "        [-2.9817123e-03,  2.8522420e-03,  1.7286559e-04, ...,\n",
              "         -1.1250721e-03, -1.2995520e-03,  1.6911686e-03]],\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-3.0423866e-05,  4.2704711e-04, -6.7621231e-04, ...,\n",
              "          4.5668779e-04, -6.0508354e-04, -3.9692200e-04],\n",
              "        [ 1.3579689e-04,  4.6076975e-04, -9.1894675e-04, ...,\n",
              "          7.8818639e-04, -5.8549899e-04, -3.7566750e-04],\n",
              "        ...,\n",
              "        [ 8.1318378e-04,  1.4214238e-04,  4.8835471e-04, ...,\n",
              "         -2.0406016e-03,  8.1044436e-04,  5.4760178e-04],\n",
              "        [ 6.1505729e-05,  7.7849405e-04,  7.4604136e-04, ...,\n",
              "         -2.2362438e-03,  3.4270209e-04,  5.4783403e-04],\n",
              "        [-7.7455456e-04,  1.4439797e-03,  1.0537397e-03, ...,\n",
              "         -2.3896936e-03, -2.2836278e-04,  5.7111547e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-1.9265137e-04,  2.6232676e-04, -5.2903302e-04, ...,\n",
              "          3.9922504e-04, -6.5128709e-04, -5.6115887e-04],\n",
              "        [ 1.7774626e-06,  3.5639518e-04, -2.8141792e-04, ...,\n",
              "          5.7327875e-04, -8.3245378e-04, -6.9629465e-04],\n",
              "        ...,\n",
              "        [-3.0292835e-04,  1.4473258e-03,  1.6275846e-03, ...,\n",
              "         -8.3042070e-04, -5.6442677e-04,  8.2774635e-04],\n",
              "        [-1.1020587e-03,  2.0773001e-03,  1.8500137e-03, ...,\n",
              "         -1.1077117e-03, -1.0680418e-03,  9.9420280e-04],\n",
              "        [-1.8689625e-03,  2.5867030e-03,  2.0839113e-03, ...,\n",
              "         -1.3911468e-03, -1.5341472e-03,  1.1277512e-03]],\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-6.5913750e-04,  4.8010572e-04, -3.9837731e-04, ...,\n",
              "         -4.8724833e-05, -5.9158873e-04, -5.0366682e-04],\n",
              "        [-1.0220436e-03,  6.4772385e-04, -5.6934642e-04, ...,\n",
              "         -3.1995838e-05, -7.7452511e-04, -5.4247899e-04],\n",
              "        ...,\n",
              "        [-1.7130361e-03,  3.8919444e-03,  7.0334063e-05, ...,\n",
              "         -1.2248190e-03, -2.0800582e-03,  9.2012779e-04],\n",
              "        [-2.3867749e-03,  4.1897655e-03,  5.3953694e-04, ...,\n",
              "         -1.5858688e-03, -2.3783285e-03,  1.0063566e-03],\n",
              "        [-2.9996880e-03,  4.3844716e-03,  1.0083948e-03, ...,\n",
              "         -1.9319097e-03, -2.6435489e-03,  1.0744849e-03]],\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-5.6657732e-06,  6.9164707e-05, -9.2346472e-04, ...,\n",
              "          1.6033540e-04, -6.3666230e-04, -2.9455899e-04],\n",
              "        [ 5.0041667e-04,  3.6841364e-05, -7.6878828e-04, ...,\n",
              "          1.8517859e-04, -9.5967739e-04, -1.6086880e-04],\n",
              "        ...,\n",
              "        [ 5.3490638e-03,  9.4843010e-04, -7.2585838e-04, ...,\n",
              "          6.4525047e-05, -1.8920521e-03, -1.1047156e-03],\n",
              "        [ 5.0143786e-03,  1.0924659e-03, -1.0076334e-03, ...,\n",
              "          1.4439578e-05, -1.5797762e-03, -1.1497888e-03],\n",
              "        [ 4.5381859e-03,  1.3128852e-03, -1.5185112e-03, ...,\n",
              "          1.9610777e-04, -1.2854844e-03, -9.7408344e-04]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPi_vBP5JYLK",
        "outputId": "a843d13d-0baf-4a9b-c13b-07b12db948cc"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    multiple                  7200600   \n",
            "                                                                 \n",
            " lstm_28 (LSTM)              multiple                  21700608  \n",
            "                                                                 \n",
            " lstm_29 (LSTM)              multiple                  33562624  \n",
            "                                                                 \n",
            " dense_14 (Dense)            multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,053,881\n",
            "Trainable params: 87,053,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model3.compile(loss=loss, optimizer=optimizer)\n",
        "model3.fit(val_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6UpWhuXJYOS",
        "outputId": "e4bee446-04e2-4b7b-d991-bcb2b6dbb388"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "137/137 [==============================] - 62s 436ms/step - loss: 4.1889\n",
            "Epoch 2/10\n",
            "137/137 [==============================] - 61s 447ms/step - loss: 3.4904\n",
            "Epoch 3/10\n",
            "137/137 [==============================] - 62s 452ms/step - loss: 3.2521\n",
            "Epoch 4/10\n",
            "137/137 [==============================] - 62s 456ms/step - loss: 3.0824\n",
            "Epoch 5/10\n",
            "137/137 [==============================] - 63s 458ms/step - loss: 2.9260\n",
            "Epoch 6/10\n",
            "137/137 [==============================] - 63s 457ms/step - loss: 2.7697\n",
            "Epoch 7/10\n",
            "137/137 [==============================] - 63s 456ms/step - loss: 2.6076\n",
            "Epoch 8/10\n",
            "137/137 [==============================] - 63s 456ms/step - loss: 2.4342\n",
            "Epoch 9/10\n",
            "137/137 [==============================] - 63s 457ms/step - loss: 2.2557\n",
            "Epoch 10/10\n",
            "137/137 [==============================] - 63s 457ms/step - loss: 2.0739\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36c815a8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model3**의 valadation loss는 2.0739이다."
      ],
      "metadata": {
        "id": "P9TYnQiJh1cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#가사 생성"
      ],
      "metadata": {
        "id": "oe43geLkKNu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "   \n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "iI2gJn_A8NZg"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.convert_to_tensor**는 테스트를 위해서 입력받은 init_sentence도 텐서로 변환한다."
      ],
      "metadata": {
        "id": "Jz3RINnn9J3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**while Loop**에서 단어를 하나씩 예측해 문장을 만든다.\n",
        "<br/>1) 입력받은 문장의 텐서를 입력한다.\n",
        "<br/>2) 예측된 값 중 가장 높은 확률인 word index를 뽑아낸다.\n",
        "<br/>3) 2에서 예측된 word index를 문장 뒤에 붙인다.\n",
        "<br/>4) 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마친다."
      ],
      "metadata": {
        "id": "Qbnc60dc9yj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer**를 이용해 word index를 단어로 하나씩 변환합니다 "
      ],
      "metadata": {
        "id": "DGxJTUaY96We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 좋은 학습 모델 **model2**를 사용해 가사를 생성한다."
      ],
      "metadata": {
        "id": "2HKRbru-kk27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> i love\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nV3xG_-IkZtC",
        "outputId": "004ec7f3-26e9-4ff0-e03c-8f956c2cf6bf"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love the way you lie <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2l23ETvyjBia",
        "outputId": "9923e150-bea7-4116-e96b-7f63f4d1098b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> good day sunshine , <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> morning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iSIzshmzjBYa",
        "outputId": "fb7a01fd-a918-41dc-cdde-b213ce76b1aa"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> morning glow is almost here <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> I gonna\")"
      ],
      "metadata": {
        "id": "Mu2jWUvOt7hV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6c5bb7d-7054-465e-ad1e-599aa5c5c39d"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i gonna make it work . i didn t brush my hair <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> where\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mW1aWEXcj49a",
        "outputId": "c61a845b-f741-4ce8-9d58-c70e82b304a0"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> where the eyelids go verse <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결론"
      ],
      "metadata": {
        "id": "sgq97imgO7Fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##하이퍼 파라미터 튜닝"
      ],
      "metadata": {
        "id": "6K0aAKGAqK_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**에서 하이퍼 파라미터를 다음과 같이 조정한다.\n",
        "> embedding_size = 256 → 600\n",
        "<br/>hidden_size = 1024 → 2048"
      ],
      "metadata": {
        "id": "YZf1hWeilkjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 좋은 **model2**의 하이퍼 파라미터 값을 평가 모델 **model3**에 사용한다.\n",
        "> embedding_size = 600\n",
        "<br/>hidden_size = 2048"
      ],
      "metadata": {
        "id": "IMmlvdoeO7MD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1**의 train loss는 2.2846이다.\n",
        "<br/>**model2**의 train loss는 1.0074이다.\n",
        "<br/>**model3**의 valadation loss는 2.0739이다."
      ],
      "metadata": {
        "id": "1NGKmBOWlJRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 조정으로 train loss는 감소했지만\n",
        "<br/>train loss와 valadation loss의 차이는 1.0665이다."
      ],
      "metadata": {
        "id": "1tc1g5Lyla2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding_size가 커지고 hidden_size가 깊어져서\n",
        "과적합이 발생한 것인가?\n",
        "<br/>하이퍼 파라미터 값이 크다고 성능이 좋아질거라는 보장은 없다."
      ],
      "metadata": {
        "id": "P5ndLwntl3Mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "또한 튜닝에 있어서 무슨 하이퍼 파라미터를 선택해야 하는가?\n",
        "<br/>embedding_size, hidden_size 튜닝은 무슨 시사점을 남기는가?"
      ],
      "metadata": {
        "id": "_hA_2XzgnHTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 튜닝 결과에 대한 분석 방법을 알고자 튜닝 관련 논문을 찾아보았다."
      ],
      "metadata": {
        "id": "sQunSVR6o9NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[RNN모델에서 하이퍼 파라미터 변화에 따른 정확도와 손실 성능, 분석융합정보논문지 v.11 no.7, 2021, pp.31 - 38, 김준용, 박구락](https://www.koreascience.or.kr/article/JAKO202123157143805.pdf)\n"
      ],
      "metadata": {
        "id": "h5thXMjSmDWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 논문에서는 LSTM의 unit, batch_size, embedding_size를 조정한다.\n"
      ],
      "metadata": {
        "id": "xWkxITBvmJqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "unit, batch_size, embedding_size 튜닝은 무슨 시사점을 남기는가?\n",
        "* embedding_size가 가장 영향력이 큰 하이퍼 파라미터였다.\n",
        "* Unit의 개수가 적을수록 batch_size가 클 수록 성능이 높아진다.\n",
        "* Embedding size이 커지면 성능이 높아졌다가 낮아진다."
      ],
      "metadata": {
        "id": "KyUqNY2CoS3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 하이퍼 파라미터 튜닝의 결과에 대해 분석할 수 있었던 이유는\n",
        "<br/>연구자가 하이퍼 파라미터 변화에 따른 Loss와 Accuracy의 추이를 표로 정리했기 때문이다."
      ],
      "metadata": {
        "id": "srELNMwPo6Ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 변화에 따른 학습 결과를 문서로 정리할 수 있는 알고리즘을 짜는 방법을 알고 싶다."
      ],
      "metadata": {
        "id": "tKRpUhjPmDcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 데이터셋"
      ],
      "metadata": {
        "id": "J6Ybgv9lqNDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 노이즈에 대한 사전지식을 갖추고 웹크롤링과 데이터 전처리를 진행해야한다.\n",
        "* 문장 부호가 작성되지 않았거나 띄어쓰기가 되지 않은 상황에서 토큰의 단위에 따라 어떻게 분리하는가?\n",
        "\n"
      ],
      "metadata": {
        "id": "q9MFa_3nqNGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#참고문헌"
      ],
      "metadata": {
        "id": "VVZkeI61zg37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "\n",
        "[text_generation_shakespeare_rnn.ipynb](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_shakespeare_rnn/text_generation_shakespeare_rnn.ipynb#scrollTo=bui0MyTjv1Mp)\n",
        "\n",
        "[OS 모듈](https://wikidocs.net/3141)\n",
        "\n",
        "[Python re 모듈 사용법](https://brownbears.tistory.com/506)\n",
        "\n",
        "[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "\n",
        "\n",
        "[Python 리스트(List)와 리스트 메소드(append, insert, remove, pop, extend)](https://velog.io/@falling_star3/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9D%98-%EB%A6%AC%EC%8A%A4%ED%8A%B8List%EC%99%80-%EA%B4%80%EB%A0%A8-%ED%95%A8%EC%88%98%EB%93%A4append-insert-remove-pop-extend)\n",
        "\n",
        "\n",
        "[파이썬 문자열을 리스트로 만들기 – split, splitlines](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=debolm74&logNo=221953881991)\n",
        "\n",
        "[PyTorch로 시작하는 딥 러닝 입문  / 01. 자연어 처리 전처리 이해하기](https://wikidocs.net/64517)\n",
        "\n",
        "[4. 텍스트 전처리(정규화)](https://blockchainstudy.tistory.com/58)\n",
        "\n",
        "[PYTHON / NLTK 텍스트 파일 문장 단위로 분해하기 (SENTENCE TOKENIZE)](https://cryptosalamander.tistory.com/140)\n",
        "\n",
        "[Python에서 문자열의 단어 계산](https://www.delftstack.com/ko/howto/python/python-count-words-in-string/)\n",
        "\n",
        "[15.Batch size & Batch Norm](https://nittaku.tistory.com/293)\n",
        "\n",
        "\n",
        "[RNN모델에서 하이퍼 파라미터 변화에 따른 정확도와 손실 성능, 분석융합정보논문지 v.11 no.7, 2021, pp.31 - 38, 김준용, 박구락](https://www.koreascience.or.kr/article/JAKO202123157143805.pdf)\n"
      ],
      "metadata": {
        "id": "ttZWzlIErLhb"
      }
    }
  ]
}