{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-06]TextGenerator(LyricsBot).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LSM EXP 06_Aiffel\n",
        "<br/>**6. 작사가 인공지능 만들기**"
      ],
      "metadata": {
        "id": "2uCcvItmOci-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "라이브러리\n",
        "<br/>데이터 정보\n",
        "<br/>데이터 탐색\n",
        "<br/>데이터 시각화\n",
        "<br/>데이터셋의 한계\n",
        "* 문장 토큰화\n",
        "* 데이터셋 노이즈\n",
        "* 전처리 이후의 문장 길이 빈도 분포\n",
        "\n",
        "데이터 전처리\n",
        "* 특수문자, 공백 제거\n",
        "* 문장 길이, 토큰 개수, 기호 제외\n",
        "\n",
        "train, val 데이터 분리\n",
        "<br/>학습 모델\n",
        "<br/>학습 모델 (하이퍼 파라미터 조정)\n",
        "<br/>평가 모델\n",
        "<br/>가사 생성\n",
        "<br/>결론\n",
        "* 하이퍼 파라미터 튜닝\n",
        "* 텍스트 데이터셋\n",
        "\n",
        "참고문헌"
      ],
      "metadata": {
        "id": "66AfZULXBZHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#라이브러리"
      ],
      "metadata": {
        "id": "v6TbNgiSOeb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import re \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "metadata": {
        "id": "gZvVy4njOouQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob**는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다.\n",
        "<br/>단, 조건에 정규식을 사용할 수 없으며 엑셀 등에서도 사용할 수 있는 '*'와 '?'같은 와일드카드만을 지원한다."
      ],
      "metadata": {
        "id": "0pEf5ZnoQviL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tensorflow**는 구글이 개발한 오픈소스 소프트웨어 딥러닝 및 머신러닝 라이브러리이다.\n",
        "<br/>수학 계산식과 데이터의 흐름을 노드와 엣지를 사용한 방향성 그래프, 데이터 플로우 그래프로 나타낸다."
      ],
      "metadata": {
        "id": "w-LFuuo9Oeiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**numpy**는 array 단위로 벡터와 행렬을 계산한다. 이 라이브러리를 사용하기 위해서는 선형대수학 지식이 필요하다."
      ],
      "metadata": {
        "id": "Acm1V6-fvfoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**os(Operating System)**는 운영체제에서 제공되는 여러 기능을 파이썬에서 수행한다. <br/>예를 들어, 파일 복사, 디렉터리 생성, 파일 목록을 구할 수 있다."
      ],
      "metadata": {
        "id": "ESWq3NcjvufN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**re(regex)**는 특정 문자 또는 문자열이 존재하는지나 어느 위치에 있는지와 같은 기능을 제공하는 정규표현식 라이브러리이다."
      ],
      "metadata": {
        "id": "8-_H8De9vfDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**matplotlib**은 다양한 데이터와 학습 모델을 시각화한다."
      ],
      "metadata": {
        "id": "UF9k9DtZIg4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **sklearn.model_selection**는 훈련 데이터, 테스트 데이터를 분리한다."
      ],
      "metadata": {
        "id": "92-N05wpz63c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 정보"
      ],
      "metadata": {
        "id": "Vy4iUr53Oeon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[song_lyrics](https://aiffelstaticprd.blob.core.windows.net/media/documents/song_lyrics.zip)"
      ],
      "metadata": {
        "id": "eZ3uOVAEOcnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "49명의 가수의 영어 노래 가사를 수집한 텍스트 파일 모음 데이터셋이다.\n",
        "<br/>가사 생성기(lyric Generator)를 만드는 데 사용된다."
      ],
      "metadata": {
        "id": "K-3GbtyGO-5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 탐색"
      ],
      "metadata": {
        "id": "0BleA9rSO6mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYEfeIDjXFFS",
        "outputId": "0358716b-e07b-4959-c2cb-019111f9f764"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file_path = '/content/drive/MyDrive/LMS/song_lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMHkEHYis4If",
        "outputId": "942dc0a1-ccac-461b-ce4b-bb1178bdc625"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['\"Don\\'t worry about a thing,', \"'Cause every little thing gonna be all right.\", 'Singin\\': \"Don\\'t worry about a thing,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 데이터셋은 187088 문장으로 구성되어 있다.\n"
      ],
      "metadata": {
        "id": "UKSDz4tbO6eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**주의사항**\n",
        "<br/>주소를 적을 때 txt_file_path = '.../*'의 끝에 별 *를 적어야 한다.\n",
        "<br/>별을 빠뜨리면 IsADirectoryError: [Errno 21]라는 에러가 발생한다."
      ],
      "metadata": {
        "id": "FWDUByl71Ls8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob.glob**는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다. <br/>특정 파일 경로 안에 있는 파일명을 불러왔다.\n"
      ],
      "metadata": {
        "id": "u3PBTdg2tg22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**splitlines**은 줄 단위로 문자열을 리스트로 변환한다.\n",
        "<br/>그런데 split(\"\\n')도 splitlines()와 동일한 결과값을 보여주기 때문에\n",
        "<br/>문자열을 리스트로 변경할 때는 대부분 split()을 사용한다.\n"
      ],
      "metadata": {
        "id": "c_2KKH6L8s-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extend**는 확장 함수로 다른 리스트를 연결한다.\n",
        "<br/>여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다."
      ],
      "metadata": {
        "id": "snfQJyag28pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extend**와 **append**, **insert(a,b)**는 다른 형태의 추가 함수이니 때에 따라 다르게 쓴다.\n",
        "<br/>**append**는 리스트의 끝에 x 값을 추가한다.\n",
        "<br/>**insert(a,b)**는 리스트의 a 위치에 b 값을 추가한다."
      ],
      "metadata": {
        "id": "84GhFnAM-BIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 시각화"
      ],
      "metadata": {
        "id": "CTdZ96tJVUom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**matplotlib**을 이용해 문장 길이의 빈도 분포를 시각화한다."
      ],
      "metadata": {
        "id": "STBljIZRY_tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in raw_corpus)\n",
        "print('최대 길이 : %d' % max_len)\n",
        "print('최소 길이 : %d' % min(len(l) for l in raw_corpus))\n",
        "print('평균 길이 : %f' % (sum(map(len, raw_corpus))/len(raw_corpus)))\n",
        "plt.hist([len(s) for s in raw_corpus], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "SDlRs-eBJJJD",
        "outputId": "caf0c5c0-46f4-4c4c-f0a6-d08f5446981a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 1465\n",
            "최소 길이 : 0\n",
            "평균 길이 : 34.977070\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1,000이 넘는 지나치게 긴 길이가 있는 문장이 존재한다.\n",
        "<br/>왜 그럴까?"
      ],
      "metadata": {
        "id": "nEKXuIo1TbBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "print를 이용해 직접 1,000이 넘는 문장을 출력해서 문제 원인을 확인한다."
      ],
      "metadata": {
        "id": "FN4K1gllVnlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in raw_corpus:\n",
        "  if len(i) >= 1000:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYfbGIyUJ4hq",
        "outputId": "34b616bd-71fb-41e0-9df6-a4c6b9a89f08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WRITERS RUSSELL BROWN, IRWIN LEVINE I'm comin' home, I've done my time Now I've got to know what is and isn't mine If you received my letter telling you I'd soon be free Then you'll know just what to do if you still want me If you still want me Just tie a yellow ribbon 'round the old oak tree It's been way too long, do you still want me? If I don't see a ribbon 'round the old oak tree I'll just stay on the bus, forget about us, put the blame on me If I don't see a yellow ribbon 'round the old oak tree Bus driver, please look for me 'Cause I couldn't bear to see what I might see I'm really still in prison and my love, he holds the key A simple yellow ribbon's all I need to set me free I wrote and told him please... Just tie a yellow ribbon 'round the old oak tree It's been way too long, do you still want me? If I don't see a ribbon 'round the old oak tree I'll just stay on the bus, forget about us, put the blame on me If I don't see a ribbon 'round the old oak tree Tie a yellow ribbon 'round that old oak tree I'm coming home Now the whole dang bus is cheerin' and I can't believe I see a hundred yellow ribbons tied 'round the old oak tree I'm comin' home, I'm glad you waited for me Tie a yellow ribbon 'round the old oak tree Tie a ribbon 'round the old oak tree Tie a ribbon 'round the old oak tree Tie a yellow ribbon if you still want me Tie a yellow ribbon 'round the old oak tree Tie a yellow ribbon 'round the old oak tree Here you come again\n",
            "Another one (Chorus) Standing on the mountain top, counting all this money, laughing at you haters, ain't nothing gonna save yeah. Yeah, Welcome Back, Another small Buy, we global , Feel my pain They can't deal witha nigga like me. Cus I keep it so hood, yeah I keep it so Street. The industry hate but they gotta see me. Turn your tvs on Bet all you see is me. Nah I ain't playing why you trying to blame me, Might as well hate the world instead of hating on me. Pussy ass nigga (And we taking over, One paper bag at a time) I need that clearence feed me more, come and think about it you need it more Uhh I am miami I do it for miami, 24 and 7 trays yeah nigga we born and raised. See this, Joe Crack we showed them. Damn right I'm so concieted. I know it made you sick, guess what it made me rich. Shout out to all my DJ's. Projects I know you feel me. Thank god for rubber bands. Phantoms on paper tags. This oens for all the fans. We the best. (Chorus) Standing on the mountain top, counting all this money, laughing at you haters, ain't nothing gonna save yeah. x2 I Introduce you to ace hood!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 자체의 문제이다.\n",
        "<br/>웹크롤링 당시 줄바꿈되지 않은 채 여러 문장이 하나의 문장으로 이어져 txt 파일에 담긴 것이다."
      ],
      "metadata": {
        "id": "s5Es1m2TTic-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터셋의 한계"
      ],
      "metadata": {
        "id": "Wb26WWs7wQpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##문장 토큰화"
      ],
      "metadata": {
        "id": "CwBMfaTHwcSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 토큰화를 하는 함수 **nltk.tokenize**의 **sent_tokenize**가 있으나\n",
        "<br/>마침표를 기준으로 문장을 나누기 때문에 길이가 1000이 넘는 문장을 구분할 수 없다.\n",
        "<br/>이 문장 안에는 마침표가 존재하지 않는다."
      ],
      "metadata": {
        "id": "qcA4ueaDvlbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> WRITERS RUSSELL BROWN, IRWIN LEVINE I'm comin' home, I've done my time Now I've got to know what is and isn't mine If you receive (생략)"
      ],
      "metadata": {
        "id": "wnwNEBLewLml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터셋 노이즈"
      ],
      "metadata": {
        "id": "YA_JKVN9zDYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entire_sentence_num = 0\n",
        "for i in raw_corpus:\n",
        "  entire_sentence_num += 1\n",
        "\n",
        "print('전체 문장 개수 : %d' % entire_sentence_num)\n",
        "\n",
        "fifteen_sentence_num = 0\n",
        "for i in raw_corpus:\n",
        "  if len(i) <= 14:\n",
        "    fifteen_sentence_num += 1\n",
        "\n",
        "print('토큰 15개 미만의 문장 개수 : %d' % fifteen_sentence_num)\n",
        "\n",
        "num_difference = entire_sentence_num - fifteen_sentence_num\n",
        "print('토큰 15개 기준 전처리 이후 제외되는 문장 개수 : %d' % num_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fie9vJGt0xxE",
        "outputId": "d7411efa-f747-48b3-a342-f310236d74df"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 문장 개수 : 187088\n",
            "토큰 15개 미만의 문장 개수 : 23268\n",
            "토큰 15개 기준 전처리 이후 제외되는 문장 개수 : 163820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리를 통해 지나치게 긴 문장을 제외한 상황을 가정한다."
      ],
      "metadata": {
        "id": "NPDPv6rBI3Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이 15를 기준으로 전처리 이후 제외된 문장의 개수는 23268개이다."
      ],
      "metadata": {
        "id": "sRWTx0AT2Jm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23000개가 넘는 문장의 데이터를 잃지만 전처리를 통해 정제된 데이터를 얻을 수 있다."
      ],
      "metadata": {
        "id": "6fyhWtBJo8il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_data_rate = round((23268 / 187088) * 100, 2)\n",
        "print('전처리로 제외된 데이터 비율 : %.2f ' % delete_data_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6AVPhtqC2x7",
        "outputId": "8a55c7db-9bb7-40f7-ea39-aefd5f9a2be8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리로 제외된 데이터 비율 : 12.44 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리로 전체 데이터의 12.44%가 제외된다."
      ],
      "metadata": {
        "id": "4CCb0UyjC0Cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "웹크롤링으로 가져온 데이터셋의 노이즈가 그만큼 많다는 것이다."
      ],
      "metadata": {
        "id": "hmyOf96kEhW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이가 15를 넘어가는 문장을 제외하는 방법이 아닌 대안이 있어야하지 않을까?\n"
      ],
      "metadata": {
        "id": "K7Z_VMRvEour"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "웹에 업로드되어있는 데이터 자체의 문제로 인해 문장의 끝에 마침표가 없어서 \n",
        "<br/>여러 문장이 합쳐져 '지나치게 긴 하나의 문장'이 된 노이즈를 \n",
        "<br/>여러 문장으로 분할하여 '하나의 문장'이라는 정제된 데이터로 변환시켜주는 \n",
        "<br/>전처리 기술이 개발되어야하지 않을까?"
      ],
      "metadata": {
        "id": "o3mg75Hpu02p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 전처리 기술이 발달이 되면 12.44%와 같은 데이터양의 축소를 하지 않고\n",
        "<br/>더 많은 웹크롤링 텍스트 데이터의 양을 확보할 수 있을 것이다."
      ],
      "metadata": {
        "id": "Of2xScvFFfiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##전처리 이후의 문장 길이 빈도 분포"
      ],
      "metadata": {
        "id": "EksJKbWBGfQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(i) for i in raw_corpus if len(i) <= 14])\n",
        "sum_len = sum([len(i) for i in raw_corpus if len(i) <= 14])\n",
        "mean_len = sum_len / fifteen_sentence_num\n",
        "\n",
        "print('최대 길이 : %d' % max_len)\n",
        "print('최소 길이 : %d' % min(len(l) for l in raw_corpus))\n",
        "print('평균 길이 : %f' % mean_len)\n",
        "plt.hist([len(s) for s in raw_corpus if len(s) <= 14], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "fnSz7KtNzAwL",
        "outputId": "92092d50-eaa1-4435-84cf-a6b61fc3112d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 14\n",
            "최소 길이 : 0\n",
            "평균 길이 : 5.154203\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j = 1\n",
        "for i in raw_corpus:\n",
        "  if len(i) == 108:\n",
        "    while j < 2:\n",
        "      print(i)\n",
        "      j += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdfFVTOB6g88",
        "outputId": "a0dfbf79-25bf-4ee7-ed12-3185c79e191b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who you are and where you stand in the struggle They go so very, so very, so very, so very, so very, so very\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 길이 15 미만의 문장 중에서 가장 길이가 긴 문장의 사례이다."
      ],
      "metadata": {
        "id": "tSORUyAR7eoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 길이 15 미만으로 전처리했어도\n",
        "<br/>여러 문장이 하나의 문장으로 합쳐진 사례가 등장한다.\n",
        "<br/>데이터셋과 전처리 기술력의 한계이다."
      ],
      "metadata": {
        "id": "TqC0L2ph0VVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 전처리"
      ],
      "metadata": {
        "id": "UKcT31lpO62T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##특수문자, 공백 제거"
      ],
      "metadata": {
        "id": "Z1SbwBLgUJ21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() \n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    return sentence\n",
        "\n",
        "\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl9Q46mhub91",
        "outputId": "050ada7e-de74-4b81-cc55-dd198b24dbcf"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lower.strip**은 소문자로 바꾸고, 양쪽 공백을 지운다.\n"
      ],
      "metadata": {
        "id": "UGdC7GMZBpj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sub**을 이용해 특수문자 양쪽에 공백을 넣는다.\n",
        "<br/>여러개의 공백은 하나의 공백으로 바꾼다.\n",
        "<br/>a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾼다."
      ],
      "metadata": {
        "id": "W74c0bm8ESvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**strip**은 다시 양쪽 공백을 지운다."
      ],
      "metadata": {
        "id": "Ys_1f9oKEWe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 시작에는 start, 끝에는 end를 추가한다."
      ],
      "metadata": {
        "id": "BA8Ik8aBEjgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##문장 길이, 토큰 개수, 기호 제외"
      ],
      "metadata": {
        "id": "wN27Y5Hp9h-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "corpus[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS28S5c4ud4W",
        "outputId": "ca08f656-6c1a-43aa-91c5-59db16779d54"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> don t worry about a thing , <end>',\n",
              " '<start> cause every little thing gonna be all right . <end>',\n",
              " '<start> singin don t worry about a thing , <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "corpus 리스트에 정제된 문장을 담는다."
      ],
      "metadata": {
        "id": "FogHifOIG-kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이가 0인 문장은 넘어간다."
      ],
      "metadata": {
        "id": "rYQf8VipHjkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막에 기호 :가 있는 문장은 리스트에 담지 않고 넘어간다."
      ],
      "metadata": {
        "id": "laby64YG9e0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    \n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "id": "hdTeXoduuhDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6d6c71-9ccd-422a-8d69-cf24cca9eaf1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2   37   15 ...    0    0    0]\n",
            " [   2   67  133 ...    0    0    0]\n",
            " [   2 1551   37 ...    0    0    0]\n",
            " ...\n",
            " [   2   45  900 ...    0    0    0]\n",
            " [   2   45   66 ...    0    0    0]\n",
            " [   2    8   83 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f375b898e10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer**는 내부 단어장의 크기를 12000로 갖는다.\n",
        "<br/>단어장에 포함되지 못한 단어는 'unk'로 저장한다. "
      ],
      "metadata": {
        "id": "RL4x_ig_qPh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "준비한 tokenizer를 이용해 corpus를 Tensor로 변환한다."
      ],
      "metadata": {
        "id": "bS8FHiQYqYRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**padding='post'**는 입력 데이터의 시퀀스 길이를 일정하게 맞춘다.\n",
        "<br/>만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다."
      ],
      "metadata": {
        "id": "mw3DuFohqZpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**maxlen=15**는 토큰의 개수가 15개 넘어가는 문장을 제외한다.\n",
        "<br/>지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거할 필요가 있다. "
      ],
      "metadata": {
        "id": "8MCwckVNBSzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:3, :10])"
      ],
      "metadata": {
        "id": "aVVdFqWAukXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0af0209-2535-43f1-b860-af94fef1f091"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2   37   15  717  113    9  181    4    3    0]\n",
            " [   2   67  133  117  181   96   27   24   84   20]\n",
            " [   2 1551   37   15  717  113    9  181    4    3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성된 텐서 데이터를 3번째 행, 10번째 열까지만 출력한다."
      ],
      "metadata": {
        "id": "GgwitDCA1FLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "id": "PBMjFzwNuk0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25eabdb7-e911-47de-f695-2a42e6525859"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " tokenizer에 구축된 단어 사전의 인덱스를 통해 단어 사전이 어떻게 구축되었는지 확인한다."
      ],
      "metadata": {
        "id": "5f-A7ha41Q-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_input = tensor[:, :-1]  \n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "id": "hMwm8YKbunbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83fd3c37-465e-4b2e-8907-a5482e392f3d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2  37  15 717 113   9 181   4   3   0   0   0   0   0]\n",
            "[ 37  15 717 113   9 181   4   3   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor에서 마지막 토큰을 잘라내서 소스 문장 **src_input**을 생성한다.\n"
      ],
      "metadata": {
        "id": "J0iu6JaG1hJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막 토큰은 end가 아니라 pad일 가능성이 높다."
      ],
      "metadata": {
        "id": "nW08LPLo1n07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor에서 start를 잘라내서 타겟 문장 **tgt_input**을 생성한다."
      ],
      "metadata": {
        "id": "5holoN2W1oxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train, val 데이터 분리"
      ],
      "metadata": {
        "id": "A9QkL92ktsrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
        "                                                    tgt_input,    \n",
        "                                                    test_size=0.2,   \n",
        "                                                    random_state=1)  \n",
        "\n",
        "print('enc_train 개수: ', len(enc_train),', enc_val 개수: ', len(enc_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIoKJQwU2DgM",
        "outputId": "c373ad68-c165-41fc-a8d2-ed89f07afb31"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc_train 개수:  140599 , enc_val 개수:  35150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sklearnn** 모듈의 **train_test_split**를 이용해 데이터셋 분리를 한다.\n",
        "<br/>소스 문장 **src_input**을 특징 데이터, 타겟 문장 **tgt_input**을 정답 데이터로 사용한다.\n",
        "<br/>전체의 20%를 평가 데이터로 사용한다.\n",
        "<br/>**random_state**는 데이터를 무작위로 정렬하여 분리한다."
      ],
      "metadata": {
        "id": "-aIbV7qe1928"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Source Train: ', enc_train.shape)\n",
        "print('Target Train: ', dec_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QQc_zIAKZz",
        "outputId": "6ba2e142-e18c-408d-9215-733107ba4fa7"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Train:  (140599, 14)\n",
            "Target Train:  (140599, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "LdxSEnrouBJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f75140-2153-479d-de99-d6886c3cb4ee"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WigPZz2O5ZCr",
        "outputId": "4e37c375-949a-4a07-9f18-2df350bbab31"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch size**는 한 번에 네트워크에 넘겨주는 데이터의 수이다.\n",
        "<br/>trade off로서 컴퓨터의 메모리 문제 때문에 분할해서 학습하는 것이다.\n",
        "\n",
        "<br/>140599 ≥ 140544 = 256 * 549\n",
        "<br/>train data num = batch size * step\n",
        "\n",
        "<br/>35150 = 256 * 137 ≥ 35072\n",
        "<br/>validation data num = batch size * step\n",
        "\n",
        "<br/>주의할 점은 epoch와 batch size는 다른 개념이다.\n",
        "<br/>epoch = batch size * step\n"
      ],
      "metadata": {
        "id": "ICTY6YIpaXNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**vocab size**는 tokenizer가 구축한 단어사전 내 7000개, 0 : pad를 포함하여 7001개를 포함한다."
      ],
      "metadata": {
        "id": "II-5WOeN4kqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학습 모델"
      ],
      "metadata": {
        "id": "XG9ld0Xvtzhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.keras.Model을 Subclassing하는 방식으로 만든다.\n",
        "<br/>Embedding 레이어 1개, LSTM 레이어 2개, Dense 레이어 1개로 구성된다"
      ],
      "metadata": {
        "id": "P3efBSKi5_Tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "EJWb3Pjhu0O9"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 모델 **model1**\n",
        "<br/>하이퍼 파라미터를 조정한 학습 모델 **model2**\n",
        "<br/>평가 모델 **model3**으로 설정한다."
      ],
      "metadata": {
        "id": "3tMryZ5u7nlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model1 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "nnDRgmqr7mNr"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding 레이어**는 이 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꾼다.\n",
        "<br/>워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현(representation)으로 사용된다."
      ],
      "metadata": {
        "id": "OEYdPyFl6WPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model1(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "018DgCW7vuZm",
        "outputId": "8431ca55-fdeb-4a68-8df7-9ec496f0f918"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 2.59152963e-04,  2.55710707e-04,  1.89954662e-04, ...,\n",
              "          1.86881778e-04, -3.89832217e-04,  8.52760568e-05],\n",
              "        [ 2.95058329e-04,  5.36240463e-04,  2.46459706e-04, ...,\n",
              "         -4.28641688e-05, -6.16939215e-04, -1.75927722e-04],\n",
              "        ...,\n",
              "        [-1.45345042e-03, -2.98856728e-04,  1.50849461e-03, ...,\n",
              "          7.21762364e-04, -1.26660115e-03, -1.49171310e-03],\n",
              "        [-1.55146315e-03, -2.77278188e-04,  1.66823075e-03, ...,\n",
              "          9.07679729e-04, -1.40510674e-03, -1.38349598e-03],\n",
              "        [-1.61832012e-03, -2.38572218e-04,  1.83011149e-03, ...,\n",
              "          1.09559565e-03, -1.55437400e-03, -1.24894211e-03]],\n",
              "\n",
              "       [[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 2.32708277e-04,  4.01601574e-05,  3.64393229e-04, ...,\n",
              "         -2.13495383e-04, -3.69870133e-04, -5.45612929e-05],\n",
              "        [ 2.43278890e-04,  1.26326908e-04,  5.56675135e-04, ...,\n",
              "         -3.99501441e-04, -2.66939693e-04, -2.72948062e-04],\n",
              "        ...,\n",
              "        [-6.36863231e-04, -1.90923020e-04,  8.16528685e-04, ...,\n",
              "         -2.82290293e-05, -1.09210494e-03, -1.30721179e-04],\n",
              "        [-8.81975458e-04, -2.56893865e-04,  9.38988349e-04, ...,\n",
              "          1.15956391e-04, -1.15888240e-03, -3.42365820e-04],\n",
              "        [-1.08783343e-03, -2.90647731e-04,  1.08899863e-03, ...,\n",
              "          2.74861988e-04, -1.23422930e-03, -4.92655265e-04]],\n",
              "\n",
              "       [[-1.14390205e-04,  1.74208748e-04, -8.42063819e-05, ...,\n",
              "         -9.88146057e-05, -9.47283479e-05,  1.18151191e-04],\n",
              "        [-7.33234847e-05,  1.59583476e-04, -2.05216813e-04, ...,\n",
              "         -2.12523111e-04, -1.79534705e-04,  8.40782668e-05],\n",
              "        [-9.64284845e-05,  1.76797723e-04, -1.29209526e-04, ...,\n",
              "         -2.01418748e-04,  1.65001082e-04,  2.88352021e-05],\n",
              "        ...,\n",
              "        [-4.30157597e-05, -1.03563815e-03, -4.01703117e-04, ...,\n",
              "         -5.92375291e-04,  7.68279599e-04, -1.42922904e-03],\n",
              "        [ 1.30405431e-04, -1.12099748e-03, -4.13678528e-04, ...,\n",
              "         -7.10174500e-04,  5.81918692e-04, -1.29671430e-03],\n",
              "        [ 1.96759909e-04, -1.26466295e-03, -2.09055055e-04, ...,\n",
              "         -8.03500938e-04,  5.52995305e-04, -1.34560058e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 4.45868733e-04, -6.34604839e-06,  2.11862905e-04, ...,\n",
              "          1.50921871e-04, -4.27435065e-04,  1.46675404e-04],\n",
              "        [ 6.05857524e-04,  1.09891131e-04,  2.92338693e-04, ...,\n",
              "         -1.00404061e-04, -5.06456359e-04,  5.34670835e-05],\n",
              "        ...,\n",
              "        [-1.53432484e-03, -1.04783452e-04,  1.02655916e-03, ...,\n",
              "          6.57497498e-04, -1.55247527e-03, -8.26029107e-04],\n",
              "        [-1.69357657e-03, -1.45272788e-04,  1.20541314e-03, ...,\n",
              "          8.02519149e-04, -1.68349501e-03, -8.24240560e-04],\n",
              "        [-1.80096889e-03, -1.63151693e-04,  1.39201817e-03, ...,\n",
              "          9.56979056e-04, -1.80491409e-03, -7.86648772e-04]],\n",
              "\n",
              "       [[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 2.75331025e-04, -2.25824682e-04,  1.10245774e-05, ...,\n",
              "         -1.69041305e-04, -1.96317691e-04, -1.80546704e-04],\n",
              "        [ 5.77269122e-04, -4.63959877e-04, -2.86856026e-04, ...,\n",
              "         -2.11278355e-04, -2.27828477e-05, -6.31923758e-05],\n",
              "        ...,\n",
              "        [ 1.23042986e-03, -7.04566541e-04, -7.71550054e-04, ...,\n",
              "         -8.81591332e-05, -1.02837417e-04,  1.06061553e-03],\n",
              "        [ 1.10328384e-03, -7.54650333e-04, -7.15148402e-04, ...,\n",
              "          1.31444895e-05, -7.53910645e-05,  1.09814468e-03],\n",
              "        [ 7.37035472e-04, -1.01889414e-03, -6.86899235e-04, ...,\n",
              "          1.09044267e-04, -1.19726596e-04,  1.10431400e-03]],\n",
              "\n",
              "       [[ 1.40947523e-04,  4.04085367e-05,  1.64556957e-04, ...,\n",
              "          6.11222204e-05, -2.46991811e-04,  4.76812893e-05],\n",
              "        [ 2.57891428e-04,  3.30581650e-04,  9.49058085e-05, ...,\n",
              "          5.49371616e-05, -1.98592199e-04,  1.84978242e-04],\n",
              "        [ 2.55690276e-04,  4.48251056e-04, -1.42255367e-05, ...,\n",
              "         -4.18134732e-05, -6.65543121e-05,  2.51268473e-04],\n",
              "        ...,\n",
              "        [ 8.47709482e-04, -5.05258038e-04, -1.34250836e-03, ...,\n",
              "          4.81680618e-04,  4.98065550e-04,  2.67217110e-04],\n",
              "        [ 7.34813046e-04, -4.15833958e-04, -1.25654042e-03, ...,\n",
              "          8.36043968e-04,  4.22425917e-04,  1.66335376e-04],\n",
              "        [ 6.41188642e-04, -2.30575213e-04, -1.14306109e-03, ...,\n",
              "          1.07000675e-03,  4.34918620e-04,  2.14115935e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋에서 데이터 한 배치만 불러온다.\n",
        "<br/>한 배치만 불러온 데이터를 모델에 넣는다."
      ],
      "metadata": {
        "id": "MZ9TZ7CV44W7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model의 input shape가 결정되면서 model.build()가 자동으로 호출된다.\n",
        "<br/>"
      ],
      "metadata": {
        "id": "6cRD5_NN6x7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "5gcqszZDu3T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58f230a-20a1-43f4-b23f-861e86c1bb38"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     multiple                  3072256   \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              multiple                  8392704   \n",
            "                                                                 \n",
            " dense_7 (Dense)             multiple                  12301025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model1.compile(loss=loss, optimizer=optimizer)\n",
        "model1.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "id": "OMdkMRFbu7KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9e8c33-4b16-456a-c9e4-201ca0daf8e1"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 85s 151ms/step - loss: 3.6903\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 85s 155ms/step - loss: 3.1976\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 87s 158ms/step - loss: 3.0198\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.8836\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.7654\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.6574\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.5567\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 85s 155ms/step - loss: 2.4606\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 87s 158ms/step - loss: 2.3701\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 88s 160ms/step - loss: 2.2846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f375bad9410>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1**의 train loss는 2.2846이다."
      ],
      "metadata": {
        "id": "Yjf-mQkviLnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학습 모델 (하이퍼 파라미터 조정)"
      ],
      "metadata": {
        "id": "K9h4eV6w8jf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**에서 하이퍼 파라미터를 다음과 같이 조정한다.\n",
        "> embedding_size = 256 → 600\n",
        "<br/>hidden_size = 1024 → 2048\n"
      ],
      "metadata": {
        "id": "QOEvQmQcZsQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 600\n",
        "hidden_size = 2048\n",
        "model2 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "jo9Fpr7yMEqr"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model2(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO9qatX-MEtR",
        "outputId": "16109d0a-4272-4f3a-91b7-08eb0fbbb208"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 8.98761442e-04,  6.57740107e-04, -3.33451433e-04, ...,\n",
              "         -2.16741842e-04, -4.78792441e-04,  9.14298289e-04],\n",
              "        [ 1.41155138e-03,  9.28761670e-04, -5.09645382e-04, ...,\n",
              "         -4.61590738e-04, -7.08812498e-04,  1.24689669e-03],\n",
              "        ...,\n",
              "        [ 4.09965316e-04,  1.93638250e-03, -1.03193463e-03, ...,\n",
              "         -4.12586407e-04, -8.39014887e-04,  8.14105952e-05],\n",
              "        [ 4.07122425e-04,  1.88428944e-03, -8.22052360e-04, ...,\n",
              "         -6.74766547e-04, -1.82157048e-04,  8.29519413e-05],\n",
              "        [ 6.47721579e-04,  1.54634879e-03, -9.48799716e-04, ...,\n",
              "         -7.36404036e-04,  3.55802244e-04,  2.61138863e-04]],\n",
              "\n",
              "       [[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 4.74448723e-04,  5.00936818e-04, -4.71094507e-04, ...,\n",
              "         -1.83796496e-04, -4.41196287e-04,  7.38874485e-04],\n",
              "        [ 4.39904834e-04,  9.11371084e-04, -4.30403219e-04, ...,\n",
              "         -8.78286082e-05, -7.60912197e-04,  9.24833585e-04],\n",
              "        ...,\n",
              "        [ 1.05535868e-03, -3.51592596e-03, -2.23470270e-03, ...,\n",
              "          1.87906518e-03,  9.07104186e-05,  5.78694465e-03],\n",
              "        [ 1.12555467e-03, -4.18851804e-03, -2.54234346e-03, ...,\n",
              "          2.30042124e-03,  1.25255596e-04,  6.19129650e-03],\n",
              "        [ 1.18808181e-03, -4.79222462e-03, -2.83133937e-03, ...,\n",
              "          2.72215647e-03,  1.40567034e-04,  6.52117562e-03]],\n",
              "\n",
              "       [[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 6.49530673e-04,  3.53667361e-04, -4.17524629e-04, ...,\n",
              "          3.30587795e-06, -6.87774562e-04,  6.13192969e-04],\n",
              "        [ 5.30434016e-04,  3.33666481e-04, -6.56539225e-04, ...,\n",
              "         -1.68633531e-04, -7.51762651e-04,  6.23264757e-04],\n",
              "        ...,\n",
              "        [ 7.15827802e-04, -3.44489398e-03, -1.87212566e-03, ...,\n",
              "          1.06152100e-03,  2.54836887e-05,  5.29390294e-03],\n",
              "        [ 7.43111654e-04, -4.08046087e-03, -2.11683987e-03, ...,\n",
              "          1.53221563e-03,  7.42293851e-05,  5.78418933e-03],\n",
              "        [ 7.93604180e-04, -4.66150977e-03, -2.36169831e-03, ...,\n",
              "          2.01556832e-03,  1.04738428e-04,  6.20274711e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.19782846e-04,  1.20092973e-05,  2.00391747e-04, ...,\n",
              "         -4.28757412e-05,  3.34811542e-04, -2.37958357e-05],\n",
              "        [-3.14322562e-04,  2.64373048e-05, -2.20993272e-04, ...,\n",
              "         -2.28609861e-04,  4.28396132e-04,  1.84476492e-04],\n",
              "        [-8.17432126e-04,  2.11553241e-04, -3.88824352e-04, ...,\n",
              "         -5.52269397e-04,  3.56084871e-04,  4.92595835e-04],\n",
              "        ...,\n",
              "        [-5.50310477e-04, -7.62939279e-04, -8.40673922e-04, ...,\n",
              "          6.54875359e-04, -2.34088402e-05,  6.61819417e-04],\n",
              "        [-1.52402601e-04, -6.70581707e-04, -8.27453041e-04, ...,\n",
              "          9.52517381e-04, -3.52063100e-04,  9.55199066e-04],\n",
              "        [ 1.29883992e-04, -2.97559251e-04, -1.20047468e-03, ...,\n",
              "          1.15642615e-03, -5.10791899e-04,  1.02332688e-03]],\n",
              "\n",
              "       [[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 7.28467887e-04,  6.26336318e-04, -4.69070539e-04, ...,\n",
              "         -1.39354161e-04, -3.97730793e-04,  6.72027352e-04],\n",
              "        [ 1.10020372e-03,  8.09218385e-04, -7.09761283e-04, ...,\n",
              "         -3.11494427e-04, -3.81056307e-04,  9.04387794e-04],\n",
              "        ...,\n",
              "        [ 2.65442720e-03, -6.10842602e-04, -1.33034517e-03, ...,\n",
              "          4.69435152e-04,  1.47635781e-03, -1.21218420e-03],\n",
              "        [ 2.72247009e-03, -9.79051576e-04, -1.49642560e-03, ...,\n",
              "          4.92505089e-04,  1.73099514e-03, -6.43580395e-04],\n",
              "        [ 2.63959426e-03, -1.46284827e-03, -1.61004334e-03, ...,\n",
              "          5.21137321e-04,  1.82083866e-03,  1.51046974e-04]],\n",
              "\n",
              "       [[ 3.39108024e-04,  1.62792086e-04, -2.44630064e-04, ...,\n",
              "         -6.35598408e-05, -1.29764143e-04,  4.72686865e-04],\n",
              "        [ 2.59071094e-04,  2.99780368e-04, -8.76280363e-04, ...,\n",
              "         -2.96698854e-04, -3.32444411e-04,  8.44902126e-04],\n",
              "        [ 2.44192415e-05,  2.09347039e-04, -8.61907611e-04, ...,\n",
              "         -8.69373558e-04, -1.06710315e-04,  1.07394985e-03],\n",
              "        ...,\n",
              "        [-1.38785821e-04,  4.92032792e-04, -4.16254188e-04, ...,\n",
              "          1.20814424e-03,  6.67011715e-04,  2.39049376e-04],\n",
              "        [ 1.37107112e-04,  4.60390293e-05, -3.79837467e-04, ...,\n",
              "          1.24522671e-03,  8.76089325e-04,  4.66161815e-04],\n",
              "        [ 3.33281059e-04, -5.66424220e-04, -3.71147151e-04, ...,\n",
              "          1.31225656e-03,  1.01095892e-03,  9.87590058e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TZJwHMbMEv0",
        "outputId": "7d7a3eec-9aff-4d73-ab0c-a55432452797"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    multiple                  7200600   \n",
            "                                                                 \n",
            " lstm_30 (LSTM)              multiple                  21700608  \n",
            "                                                                 \n",
            " lstm_31 (LSTM)              multiple                  33562624  \n",
            "                                                                 \n",
            " dense_15 (Dense)            multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,053,881\n",
            "Trainable params: 87,053,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model2.compile(loss=loss, optimizer=optimizer)\n",
        "model2.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM8qTaMVMEyb",
        "outputId": "1322ebbd-9346-4b01-f92f-32bf4bb51be0"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 247s 447ms/step - loss: 3.4829\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 250s 455ms/step - loss: 2.8911\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 250s 455ms/step - loss: 2.5695\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 251s 457ms/step - loss: 2.2626\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.9673\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 251s 457ms/step - loss: 1.6924\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.4513\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.2525\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.1037\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 251s 456ms/step - loss: 1.0074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36d75cb490>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**의 train loss는 1.0074이다."
      ],
      "metadata": {
        "id": "_4fWdrvLiIRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#평가 모델"
      ],
      "metadata": {
        "id": "YvKJIe__JPf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 좋은 **model2**의 하이퍼 파라미터 값을 평가 모델 **model3**에 사용한다.\n",
        "> embedding_size = 600\n",
        "<br/>hidden_size = 2048\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ucL7-Sg_ZHfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 600\n",
        "hidden_size = 2048\n",
        "model3 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "9bVJmLmlJX5K"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in val_dataset.take(1): break\n",
        "\n",
        "model3(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TwG-IO0JYIb",
        "outputId": "f0871edb-7296-4848-d3ec-2b646fc83790"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-2.4457051e-05,  4.7833633e-05, -3.4179442e-04, ...,\n",
              "          5.9708761e-04, -4.0994101e-04, -4.7562204e-04],\n",
              "        [ 1.5796947e-04,  1.2700519e-04, -3.1310885e-04, ...,\n",
              "          6.8283046e-04, -6.1571982e-04, -4.6007056e-04],\n",
              "        ...,\n",
              "        [-3.7857862e-03,  3.4553516e-03,  1.9701649e-03, ...,\n",
              "         -2.2496835e-03, -1.9925165e-03,  1.0253132e-03],\n",
              "        [-4.2156843e-03,  3.6314451e-03,  2.3188677e-03, ...,\n",
              "         -2.4916297e-03, -2.3248915e-03,  1.1366366e-03],\n",
              "        [-4.5746313e-03,  3.7324128e-03,  2.6403668e-03, ...,\n",
              "         -2.7112467e-03, -2.6112793e-03,  1.2271563e-03]],\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [ 4.8940892e-05,  4.5891435e-04, -5.1036256e-04, ...,\n",
              "          1.1486997e-04, -4.8445768e-04, -1.4668293e-04],\n",
              "        [ 4.4289662e-04,  3.5861350e-04, -6.7317701e-04, ...,\n",
              "          2.4762345e-04, -6.1232672e-04, -2.7315447e-05],\n",
              "        ...,\n",
              "        [-1.6278720e-03,  1.7103950e-03, -6.7396596e-04, ...,\n",
              "         -1.4808499e-04, -5.5205228e-04,  1.6370657e-03],\n",
              "        [-2.3321689e-03,  2.3329102e-03, -2.7159051e-04, ...,\n",
              "         -6.4228685e-04, -9.2077453e-04,  1.6669659e-03],\n",
              "        [-2.9817123e-03,  2.8522420e-03,  1.7286559e-04, ...,\n",
              "         -1.1250721e-03, -1.2995520e-03,  1.6911686e-03]],\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-3.0423866e-05,  4.2704711e-04, -6.7621231e-04, ...,\n",
              "          4.5668779e-04, -6.0508354e-04, -3.9692200e-04],\n",
              "        [ 1.3579689e-04,  4.6076975e-04, -9.1894675e-04, ...,\n",
              "          7.8818639e-04, -5.8549899e-04, -3.7566750e-04],\n",
              "        ...,\n",
              "        [ 8.1318378e-04,  1.4214238e-04,  4.8835471e-04, ...,\n",
              "         -2.0406016e-03,  8.1044436e-04,  5.4760178e-04],\n",
              "        [ 6.1505729e-05,  7.7849405e-04,  7.4604136e-04, ...,\n",
              "         -2.2362438e-03,  3.4270209e-04,  5.4783403e-04],\n",
              "        [-7.7455456e-04,  1.4439797e-03,  1.0537397e-03, ...,\n",
              "         -2.3896936e-03, -2.2836278e-04,  5.7111547e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-1.9265137e-04,  2.6232676e-04, -5.2903302e-04, ...,\n",
              "          3.9922504e-04, -6.5128709e-04, -5.6115887e-04],\n",
              "        [ 1.7774626e-06,  3.5639518e-04, -2.8141792e-04, ...,\n",
              "          5.7327875e-04, -8.3245378e-04, -6.9629465e-04],\n",
              "        ...,\n",
              "        [-3.0292835e-04,  1.4473258e-03,  1.6275846e-03, ...,\n",
              "         -8.3042070e-04, -5.6442677e-04,  8.2774635e-04],\n",
              "        [-1.1020587e-03,  2.0773001e-03,  1.8500137e-03, ...,\n",
              "         -1.1077117e-03, -1.0680418e-03,  9.9420280e-04],\n",
              "        [-1.8689625e-03,  2.5867030e-03,  2.0839113e-03, ...,\n",
              "         -1.3911468e-03, -1.5341472e-03,  1.1277512e-03]],\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-6.5913750e-04,  4.8010572e-04, -3.9837731e-04, ...,\n",
              "         -4.8724833e-05, -5.9158873e-04, -5.0366682e-04],\n",
              "        [-1.0220436e-03,  6.4772385e-04, -5.6934642e-04, ...,\n",
              "         -3.1995838e-05, -7.7452511e-04, -5.4247899e-04],\n",
              "        ...,\n",
              "        [-1.7130361e-03,  3.8919444e-03,  7.0334063e-05, ...,\n",
              "         -1.2248190e-03, -2.0800582e-03,  9.2012779e-04],\n",
              "        [-2.3867749e-03,  4.1897655e-03,  5.3953694e-04, ...,\n",
              "         -1.5858688e-03, -2.3783285e-03,  1.0063566e-03],\n",
              "        [-2.9996880e-03,  4.3844716e-03,  1.0083948e-03, ...,\n",
              "         -1.9319097e-03, -2.6435489e-03,  1.0744849e-03]],\n",
              "\n",
              "       [[-1.4913169e-04,  1.5645596e-04, -3.7385739e-04, ...,\n",
              "          2.8522895e-04, -4.1372006e-04, -3.6882062e-04],\n",
              "        [-5.6657732e-06,  6.9164707e-05, -9.2346472e-04, ...,\n",
              "          1.6033540e-04, -6.3666230e-04, -2.9455899e-04],\n",
              "        [ 5.0041667e-04,  3.6841364e-05, -7.6878828e-04, ...,\n",
              "          1.8517859e-04, -9.5967739e-04, -1.6086880e-04],\n",
              "        ...,\n",
              "        [ 5.3490638e-03,  9.4843010e-04, -7.2585838e-04, ...,\n",
              "          6.4525047e-05, -1.8920521e-03, -1.1047156e-03],\n",
              "        [ 5.0143786e-03,  1.0924659e-03, -1.0076334e-03, ...,\n",
              "          1.4439578e-05, -1.5797762e-03, -1.1497888e-03],\n",
              "        [ 4.5381859e-03,  1.3128852e-03, -1.5185112e-03, ...,\n",
              "          1.9610777e-04, -1.2854844e-03, -9.7408344e-04]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPi_vBP5JYLK",
        "outputId": "a843d13d-0baf-4a9b-c13b-07b12db948cc"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    multiple                  7200600   \n",
            "                                                                 \n",
            " lstm_28 (LSTM)              multiple                  21700608  \n",
            "                                                                 \n",
            " lstm_29 (LSTM)              multiple                  33562624  \n",
            "                                                                 \n",
            " dense_14 (Dense)            multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,053,881\n",
            "Trainable params: 87,053,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model3.compile(loss=loss, optimizer=optimizer)\n",
        "model3.fit(val_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6UpWhuXJYOS",
        "outputId": "e4bee446-04e2-4b7b-d991-bcb2b6dbb388"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "137/137 [==============================] - 62s 436ms/step - loss: 4.1889\n",
            "Epoch 2/10\n",
            "137/137 [==============================] - 61s 447ms/step - loss: 3.4904\n",
            "Epoch 3/10\n",
            "137/137 [==============================] - 62s 452ms/step - loss: 3.2521\n",
            "Epoch 4/10\n",
            "137/137 [==============================] - 62s 456ms/step - loss: 3.0824\n",
            "Epoch 5/10\n",
            "137/137 [==============================] - 63s 458ms/step - loss: 2.9260\n",
            "Epoch 6/10\n",
            "137/137 [==============================] - 63s 457ms/step - loss: 2.7697\n",
            "Epoch 7/10\n",
            "137/137 [==============================] - 63s 456ms/step - loss: 2.6076\n",
            "Epoch 8/10\n",
            "137/137 [==============================] - 63s 456ms/step - loss: 2.4342\n",
            "Epoch 9/10\n",
            "137/137 [==============================] - 63s 457ms/step - loss: 2.2557\n",
            "Epoch 10/10\n",
            "137/137 [==============================] - 63s 457ms/step - loss: 2.0739\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36c815a8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model3**의 valadation loss는 2.0739이다."
      ],
      "metadata": {
        "id": "P9TYnQiJh1cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#가사 생성"
      ],
      "metadata": {
        "id": "oe43geLkKNu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "   \n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "iI2gJn_A8NZg"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.convert_to_tensor**는 테스트를 위해서 입력받은 init_sentence도 텐서로 변환한다."
      ],
      "metadata": {
        "id": "Jz3RINnn9J3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**while Loop**에서 단어를 하나씩 예측해 문장을 만든다.\n",
        "<br/>1) 입력받은 문장의 텐서를 입력한다.\n",
        "<br/>2) 예측된 값 중 가장 높은 확률인 word index를 뽑아낸다.\n",
        "<br/>3) 2에서 예측된 word index를 문장 뒤에 붙인다.\n",
        "<br/>4) 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마친다."
      ],
      "metadata": {
        "id": "Qbnc60dc9yj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer**를 이용해 word index를 단어로 하나씩 변환합니다 "
      ],
      "metadata": {
        "id": "DGxJTUaY96We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 좋은 학습 모델 **model2**를 사용해 가사를 생성한다."
      ],
      "metadata": {
        "id": "2HKRbru-kk27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> i love\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nV3xG_-IkZtC",
        "outputId": "004ec7f3-26e9-4ff0-e03c-8f956c2cf6bf"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love the way you lie <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2l23ETvyjBia",
        "outputId": "9923e150-bea7-4116-e96b-7f63f4d1098b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> good day sunshine , <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> morning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iSIzshmzjBYa",
        "outputId": "fb7a01fd-a918-41dc-cdde-b213ce76b1aa"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> morning glow is almost here <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> I gonna\")"
      ],
      "metadata": {
        "id": "Mu2jWUvOt7hV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6c5bb7d-7054-465e-ad1e-599aa5c5c39d"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i gonna make it work . i didn t brush my hair <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> where\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mW1aWEXcj49a",
        "outputId": "c61a845b-f741-4ce8-9d58-c70e82b304a0"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> where the eyelids go verse <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결론"
      ],
      "metadata": {
        "id": "sgq97imgO7Fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##하이퍼 파라미터 튜닝"
      ],
      "metadata": {
        "id": "6K0aAKGAqK_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**에서 하이퍼 파라미터를 다음과 같이 조정한다.\n",
        "> embedding_size = 256 → 600\n",
        "<br/>hidden_size = 1024 → 2048"
      ],
      "metadata": {
        "id": "YZf1hWeilkjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 좋은 **model2**의 하이퍼 파라미터 값을 평가 모델 **model3**에 사용한다.\n",
        "> embedding_size = 600\n",
        "<br/>hidden_size = 2048"
      ],
      "metadata": {
        "id": "IMmlvdoeO7MD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1**의 train loss는 2.2846이다.\n",
        "<br/>**model2**의 train loss는 1.0074이다.\n",
        "<br/>**model3**의 valadation loss는 2.0739이다."
      ],
      "metadata": {
        "id": "1NGKmBOWlJRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 조정으로 train loss는 감소했지만\n",
        "<br/>train loss와 valadation loss의 차이는 1.0665이다."
      ],
      "metadata": {
        "id": "1tc1g5Lyla2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding_size가 커지고 hidden_size가 깊어져서\n",
        "과적합이 발생한 것인가?\n",
        "<br/>하이퍼 파라미터 값이 크다고 성능이 좋아질거라는 보장은 없다."
      ],
      "metadata": {
        "id": "P5ndLwntl3Mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "또한 튜닝에 있어서 무슨 하이퍼 파라미터를 선택해야 하는가?\n",
        "<br/>embedding_size, hidden_size 튜닝은 무슨 시사점을 남기는가?"
      ],
      "metadata": {
        "id": "_hA_2XzgnHTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 튜닝 결과에 대한 분석 방법을 알고자 튜닝 관련 논문을 찾아보았다."
      ],
      "metadata": {
        "id": "sQunSVR6o9NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[RNN모델에서 하이퍼 파라미터 변화에 따른 정확도와 손실 성능, 분석융합정보논문지 v.11 no.7, 2021, pp.31 - 38, 김준용, 박구락](https://www.koreascience.or.kr/article/JAKO202123157143805.pdf)\n"
      ],
      "metadata": {
        "id": "h5thXMjSmDWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 논문에서는 LSTM의 unit, batch_size, embedding_size를 조정한다.\n"
      ],
      "metadata": {
        "id": "xWkxITBvmJqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "unit, batch_size, embedding_size 튜닝은 무슨 시사점을 남기는가?\n",
        "* embedding_size가 가장 영향력이 큰 하이퍼 파라미터였다.\n",
        "* Unit의 개수가 적을수록 batch_size가 클 수록 성능이 높아진다.\n",
        "* Embedding size이 커지면 성능이 높아졌다가 낮아진다."
      ],
      "metadata": {
        "id": "KyUqNY2CoS3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 하이퍼 파라미터 튜닝의 결과에 대해 분석할 수 있었던 이유는\n",
        "<br/>연구자가 하이퍼 파라미터 변화에 따른 Loss와 Accuracy의 추이를 표로 정리했기 때문이다."
      ],
      "metadata": {
        "id": "srELNMwPo6Ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 변화에 따른 학습 결과를 문서로 정리할 수 있는 알고리즘을 짜는 방법을 알고 싶다."
      ],
      "metadata": {
        "id": "tKRpUhjPmDcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 데이터셋"
      ],
      "metadata": {
        "id": "J6Ybgv9lqNDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 노이즈에 대한 사전지식을 갖추고 웹크롤링과 데이터 전처리를 진행해야한다.\n",
        "* 문장 부호가 작성되지 않았거나 띄어쓰기가 되지 않은 상황에서 토큰의 단위에 따라 어떻게 분리하는가?\n",
        "\n"
      ],
      "metadata": {
        "id": "q9MFa_3nqNGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#참고문헌"
      ],
      "metadata": {
        "id": "VVZkeI61zg37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "\n",
        "[text_generation_shakespeare_rnn.ipynb](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_shakespeare_rnn/text_generation_shakespeare_rnn.ipynb#scrollTo=bui0MyTjv1Mp)\n",
        "\n",
        "[OS 모듈](https://wikidocs.net/3141)\n",
        "\n",
        "[Python re 모듈 사용법](https://brownbears.tistory.com/506)\n",
        "\n",
        "[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "\n",
        "\n",
        "[Python 리스트(List)와 리스트 메소드(append, insert, remove, pop, extend)](https://velog.io/@falling_star3/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9D%98-%EB%A6%AC%EC%8A%A4%ED%8A%B8List%EC%99%80-%EA%B4%80%EB%A0%A8-%ED%95%A8%EC%88%98%EB%93%A4append-insert-remove-pop-extend)\n",
        "\n",
        "\n",
        "[파이썬 문자열을 리스트로 만들기 – split, splitlines](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=debolm74&logNo=221953881991)\n",
        "\n",
        "[PyTorch로 시작하는 딥 러닝 입문  / 01. 자연어 처리 전처리 이해하기](https://wikidocs.net/64517)\n",
        "\n",
        "[4. 텍스트 전처리(정규화)](https://blockchainstudy.tistory.com/58)\n",
        "\n",
        "[PYTHON / NLTK 텍스트 파일 문장 단위로 분해하기 (SENTENCE TOKENIZE)](https://cryptosalamander.tistory.com/140)\n",
        "\n",
        "[Python에서 문자열의 단어 계산](https://www.delftstack.com/ko/howto/python/python-count-words-in-string/)\n",
        "\n",
        "[15.Batch size & Batch Norm](https://nittaku.tistory.com/293)\n",
        "\n",
        "\n",
        "[RNN모델에서 하이퍼 파라미터 변화에 따른 정확도와 손실 성능, 분석융합정보논문지 v.11 no.7, 2021, pp.31 - 38, 김준용, 박구락](https://www.koreascience.or.kr/article/JAKO202123157143805.pdf)\n"
      ],
      "metadata": {
        "id": "ttZWzlIErLhb"
      }
    }
  ]
}