{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-06]TextGenerator(LyricsBot).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LSM EXP 06_Aiffel\n",
        "<br/>**6. 작사가 인공지능 만들기**"
      ],
      "metadata": {
        "id": "2uCcvItmOci-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "라이브러리\n",
        "<br/>데이터 정보\n",
        "<br/>데이터 탐색\n",
        "<br/>데이터 시각화\n",
        "<br/>데이터셋의 한계\n",
        "* 문장 토큰화\n",
        "* 데이터셋 노이즈\n",
        "\n",
        "데이터 전처리\n",
        "* 특수문자, 공백 제거\n",
        "* 문장 길이, 토큰 개수, 기호 제외\n",
        "\n",
        "train, val 데이터 분리\n",
        "<br/>학습 모델\n",
        "<br/>학습 모델 (하이퍼 파라미터 튜닝)\n",
        "<br/>평가 모델\n",
        "<br/>가사 생성\n",
        "<br/>결론\n",
        "* 하이퍼 파라미터 튜닝\n",
        "* 텍스트 데이터셋\n",
        "\n",
        "참고문헌"
      ],
      "metadata": {
        "id": "66AfZULXBZHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#라이브러리"
      ],
      "metadata": {
        "id": "v6TbNgiSOeb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import re \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "metadata": {
        "id": "gZvVy4njOouQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob**는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다.\n",
        "<br/>단, 조건에 정규식을 사용할 수 없으며 엑셀 등에서도 사용할 수 있는 '*'와 '?'같은 와일드카드만을 지원한다."
      ],
      "metadata": {
        "id": "0pEf5ZnoQviL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tensorflow**는 구글이 개발한 오픈소스 소프트웨어 딥러닝 및 머신러닝 라이브러리이다.\n",
        "<br/>수학 계산식과 데이터의 흐름을 노드와 엣지를 사용한 방향성 그래프, 데이터 플로우 그래프로 나타낸다."
      ],
      "metadata": {
        "id": "w-LFuuo9Oeiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**numpy**는 array 단위로 벡터와 행렬을 계산한다. 이 라이브러리를 사용하기 위해서는 선형대수학 지식이 필요하다."
      ],
      "metadata": {
        "id": "Acm1V6-fvfoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**os(Operating System)**는 운영체제에서 제공되는 여러 기능을 파이썬에서 수행한다. <br/>예를 들어, 파일 복사, 디렉터리 생성, 파일 목록을 구할 수 있다."
      ],
      "metadata": {
        "id": "ESWq3NcjvufN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**re(regex)**는 특정 문자 또는 문자열이 존재하는지나 어느 위치에 있는지와 같은 기능을 제공하는 정규표현식 라이브러리이다."
      ],
      "metadata": {
        "id": "8-_H8De9vfDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**matplotlib**은 다양한 데이터와 학습 모델을 시각화한다."
      ],
      "metadata": {
        "id": "UF9k9DtZIg4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **sklearn.model_selection**는 훈련 데이터, 테스트 데이터를 분리한다."
      ],
      "metadata": {
        "id": "92-N05wpz63c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 정보"
      ],
      "metadata": {
        "id": "Vy4iUr53Oeon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[song_lyrics](https://aiffelstaticprd.blob.core.windows.net/media/documents/song_lyrics.zip)"
      ],
      "metadata": {
        "id": "eZ3uOVAEOcnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "49명의 가수의 영어 노래 가사를 수집한 텍스트 파일 모음 데이터셋이다.\n",
        "<br/>가사 생성기(lyric Generator)를 만드는 데 사용된다."
      ],
      "metadata": {
        "id": "K-3GbtyGO-5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 탐색"
      ],
      "metadata": {
        "id": "0BleA9rSO6mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYEfeIDjXFFS",
        "outputId": "4a244bad-3fb0-4f93-fd62-a9e914581290"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file_path = '/content/drive/MyDrive/LMS/song_lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMHkEHYis4If",
        "outputId": "e2fbe099-7a02-498b-a825-8047fcf93f8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['\"Don\\'t worry about a thing,', \"'Cause every little thing gonna be all right.\", 'Singin\\': \"Don\\'t worry about a thing,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 데이터셋은 187088 문장으로 구성되어 있다.\n"
      ],
      "metadata": {
        "id": "UKSDz4tbO6eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**주의사항**\n",
        "<br/>주소를 적을 때 txt_file_path = '.../*'의 끝에 별 *를 적어야 한다.\n",
        "<br/>별을 빠뜨리면 IsADirectoryError: [Errno 21]라는 에러가 발생한다."
      ],
      "metadata": {
        "id": "FWDUByl71Ls8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob.glob**는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다. <br/>특정 파일 경로 안에 있는 파일명을 불러왔다.\n"
      ],
      "metadata": {
        "id": "u3PBTdg2tg22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**splitlines**은 줄 단위로 문자열을 리스트로 변환한다.\n",
        "<br/>그런데 split(\"\\n')도 splitlines()와 동일한 결과값을 보여주기 때문에\n",
        "<br/>문자열을 리스트로 변경할 때는 대부분 split()을 사용한다.\n"
      ],
      "metadata": {
        "id": "c_2KKH6L8s-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extend**는 확장 함수로 다른 리스트를 연결한다.\n",
        "<br/>여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다."
      ],
      "metadata": {
        "id": "snfQJyag28pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extend**와 **append**, **insert(a,b)**는 다른 형태의 추가 함수이니 때에 따라 다르게 쓴다.\n",
        "<br/>**append**는 리스트의 끝에 x 값을 추가한다.\n",
        "<br/>**insert(a,b)**는 리스트의 a 위치에 b 값을 추가한다."
      ],
      "metadata": {
        "id": "84GhFnAM-BIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 시각화"
      ],
      "metadata": {
        "id": "CTdZ96tJVUom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**matplotlib**을 이용해 문장 길이의 빈도 분포를 시각화한다."
      ],
      "metadata": {
        "id": "STBljIZRY_tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in raw_corpus)\n",
        "print('최대 길이 : %d' % max_len)\n",
        "print('최소 길이 : %d' % min(len(l) for l in raw_corpus if len(l) >= 1))\n",
        "print('평균 길이 : %f' % (sum(map(len, raw_corpus))/len(raw_corpus)))\n",
        "plt.hist([len(s) for s in raw_corpus if len(s) >= 1], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "SDlRs-eBJJJD",
        "outputId": "bdf990b8-f9dc-4a8b-cb5f-19bc71c42e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 1465\n",
            "최소 길이 : 1\n",
            "평균 길이 : 34.977070\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1,000이 넘는 지나치게 긴 길이가 있는 문장이 존재한다.\n",
        "<br/>왜 그럴까?"
      ],
      "metadata": {
        "id": "nEKXuIo1TbBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "print를 이용해 직접 1,000이 넘는 문장을 출력해서 문제 원인을 확인한다."
      ],
      "metadata": {
        "id": "FN4K1gllVnlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in raw_corpus:\n",
        "  if len(i) >= 1000:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYfbGIyUJ4hq",
        "outputId": "03a738f0-de5c-4a40-9437-4432aabeb421"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WRITERS RUSSELL BROWN, IRWIN LEVINE I'm comin' home, I've done my time Now I've got to know what is and isn't mine If you received my letter telling you I'd soon be free Then you'll know just what to do if you still want me If you still want me Just tie a yellow ribbon 'round the old oak tree It's been way too long, do you still want me? If I don't see a ribbon 'round the old oak tree I'll just stay on the bus, forget about us, put the blame on me If I don't see a yellow ribbon 'round the old oak tree Bus driver, please look for me 'Cause I couldn't bear to see what I might see I'm really still in prison and my love, he holds the key A simple yellow ribbon's all I need to set me free I wrote and told him please... Just tie a yellow ribbon 'round the old oak tree It's been way too long, do you still want me? If I don't see a ribbon 'round the old oak tree I'll just stay on the bus, forget about us, put the blame on me If I don't see a ribbon 'round the old oak tree Tie a yellow ribbon 'round that old oak tree I'm coming home Now the whole dang bus is cheerin' and I can't believe I see a hundred yellow ribbons tied 'round the old oak tree I'm comin' home, I'm glad you waited for me Tie a yellow ribbon 'round the old oak tree Tie a ribbon 'round the old oak tree Tie a ribbon 'round the old oak tree Tie a yellow ribbon if you still want me Tie a yellow ribbon 'round the old oak tree Tie a yellow ribbon 'round the old oak tree Here you come again\n",
            "Another one (Chorus) Standing on the mountain top, counting all this money, laughing at you haters, ain't nothing gonna save yeah. Yeah, Welcome Back, Another small Buy, we global , Feel my pain They can't deal witha nigga like me. Cus I keep it so hood, yeah I keep it so Street. The industry hate but they gotta see me. Turn your tvs on Bet all you see is me. Nah I ain't playing why you trying to blame me, Might as well hate the world instead of hating on me. Pussy ass nigga (And we taking over, One paper bag at a time) I need that clearence feed me more, come and think about it you need it more Uhh I am miami I do it for miami, 24 and 7 trays yeah nigga we born and raised. See this, Joe Crack we showed them. Damn right I'm so concieted. I know it made you sick, guess what it made me rich. Shout out to all my DJ's. Projects I know you feel me. Thank god for rubber bands. Phantoms on paper tags. This oens for all the fans. We the best. (Chorus) Standing on the mountain top, counting all this money, laughing at you haters, ain't nothing gonna save yeah. x2 I Introduce you to ace hood!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 자체의 문제이다.\n",
        "<br/>웹크롤링 당시 줄바꿈되지 않은 채 여러 문장이 하나의 문장으로 이어져 txt 파일에 담긴 것이다."
      ],
      "metadata": {
        "id": "s5Es1m2TTic-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터셋의 한계"
      ],
      "metadata": {
        "id": "Wb26WWs7wQpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##문장 토큰화"
      ],
      "metadata": {
        "id": "CwBMfaTHwcSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 토큰화를 하는 함수 **nltk.tokenize**의 **sent_tokenize**가 있으나\n",
        "<br/>마침표를 기준으로 문장을 나누기 때문에 길이가 1,000이 넘는 문장을 구분할 수 없다.\n",
        "여러 문장으로 구성된 이 글 안에는 마침표가 없는 문장이 있으며 마침표가 있는 문장도 존재한다.\n",
        "<br/>토큰화의 기준인 문장 부호가 제역할을 하지 못하는 것이다."
      ],
      "metadata": {
        "id": "qcA4ueaDvlbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> WRITERS RUSSELL BROWN, IRWIN LEVINE I'm comin' home, I've done my time Now I've got to know what is and isn't mine If you receive (생략)"
      ],
      "metadata": {
        "id": "wnwNEBLewLml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터셋 노이즈"
      ],
      "metadata": {
        "id": "YA_JKVN9zDYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entire_sentence_num = 0\n",
        "for i in raw_corpus:\n",
        "  entire_sentence_num += 1\n",
        "\n",
        "print('전체 문장 개수 : %d' % entire_sentence_num)\n",
        "\n",
        "fifteen_sentence_num = 0\n",
        "for i in raw_corpus:\n",
        "  if len(i) <= 70:\n",
        "    fifteen_sentence_num += 1\n",
        "\n",
        "print('문장 길이 70 미만의 문장 개수 : %d' % fifteen_sentence_num)\n",
        "\n",
        "num_difference = entire_sentence_num - fifteen_sentence_num\n",
        "print('문장 길이 70 기준 전처리 이후 제외되는 문장 개수 : %d' % num_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fie9vJGt0xxE",
        "outputId": "7bb4f186-a6c0-4467-db76-e00e6cc36ac5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 문장 개수 : 187088\n",
            "문장 길이 70 미만의 문장 개수 : 177721\n",
            "문장 길이 70 기준 전처리 이후 제외되는 문장 개수 : 9367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리를 통해 지나치게 긴 문장을 제외한 상황을 가정한다."
      ],
      "metadata": {
        "id": "NPDPv6rBI3Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이 70을 기준으로 전처리 이후 제외된 문장의 개수는 9367개이다."
      ],
      "metadata": {
        "id": "sRWTx0AT2Jm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9300개가 넘는 문장의 데이터를 잃지만 전처리를 통해 정제된 데이터를 얻을 수 있다."
      ],
      "metadata": {
        "id": "6fyhWtBJo8il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_data_rate = round((num_difference / entire_sentence_num) * 100, 2)\n",
        "print('전처리로 제외된 데이터 비율 : %.2f ' % delete_data_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6AVPhtqC2x7",
        "outputId": "0f945a29-6e03-4e7a-deb0-41bc73556fbe"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리로 제외된 데이터 비율 : 5.01 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리로 전체 데이터의 5.01%가 제외된다."
      ],
      "metadata": {
        "id": "4CCb0UyjC0Cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "웹크롤링으로 가져온 데이터셋의 노이즈가 그만큼 많다는 것이다."
      ],
      "metadata": {
        "id": "hmyOf96kEhW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이가 70을 넘어가는 문장을 제외하는 방법이 아닌 대안이 있어야하지 않을까?\n"
      ],
      "metadata": {
        "id": "K7Z_VMRvEour"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "웹에 업로드되어있는 데이터 자체의 문제로 인해 문장의 끝에 마침표가 없어서 \n",
        "<br/>여러 문장이 합쳐져 '지나치게 긴 하나의 문장'이 된 노이즈를 \n",
        "<br/>여러 문장으로 분할하여 '하나의 문장'이라는 정제된 데이터로 변환시켜주는 \n",
        "<br/>전처리 기술이 개발되어야하지 않을까?"
      ],
      "metadata": {
        "id": "o3mg75Hpu02p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 전처리 기술이 발달이 되면 5.01%와 같은 데이터양의 축소를 하지 않고\n",
        "<br/>더 많은 웹크롤링 텍스트 데이터의 양을 확보할 수 있을 것이다."
      ],
      "metadata": {
        "id": "Of2xScvFFfiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(i) for i in raw_corpus if len(i) <= 70])\n",
        "sum_len = sum([len(i) for i in raw_corpus if 1 <= len(i) <= 70])\n",
        "mean_len = sum_len / fifteen_sentence_num\n",
        "\n",
        "print('최대 길이 : %d' % max_len)\n",
        "print('최소 길이 : %d' % min([len(l) for l in raw_corpus if len(l) >= 1]))\n",
        "print('평균 길이 : %f' % mean_len)\n",
        "plt.hist([len(s) for s in raw_corpus if 1 <= len(s) <= 70], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "fnSz7KtNzAwL",
        "outputId": "a8100676-3c61-40f1-8db8-b0f475335cd3"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 70\n",
            "최소 길이 : 1\n",
            "평균 길이 : 32.068101\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 전처리"
      ],
      "metadata": {
        "id": "UKcT31lpO62T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##특수문자, 공백 제거"
      ],
      "metadata": {
        "id": "Z1SbwBLgUJ21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() \n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    return sentence\n",
        "\n",
        "\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl9Q46mhub91",
        "outputId": "2e0d8b94-d25d-4e1f-f5cc-7f5b88f47957"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lower.strip**은 소문자로 바꾸고, 양쪽 공백을 지운다.\n"
      ],
      "metadata": {
        "id": "UGdC7GMZBpj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sub**을 이용해 특수문자 양쪽에 공백을 넣는다.\n",
        "<br/>여러개의 공백은 하나의 공백으로 바꾼다.\n",
        "<br/>a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾼다."
      ],
      "metadata": {
        "id": "W74c0bm8ESvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**strip**은 다시 양쪽 공백을 지운다."
      ],
      "metadata": {
        "id": "Ys_1f9oKEWe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 시작에는 start, 끝에는 end를 추가한다."
      ],
      "metadata": {
        "id": "BA8Ik8aBEjgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##문장 길이, 토큰 개수, 기호 제외"
      ],
      "metadata": {
        "id": "wN27Y5Hp9h-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "corpus[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS28S5c4ud4W",
        "outputId": "9b25fe25-7ea1-424e-f9bd-81a4666ebce8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> don t worry about a thing , <end>',\n",
              " '<start> cause every little thing gonna be all right . <end>',\n",
              " '<start> singin don t worry about a thing , <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "corpus 리스트에 정제된 문장을 담는다."
      ],
      "metadata": {
        "id": "FogHifOIG-kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이가 0인 문장은 넘어간다."
      ],
      "metadata": {
        "id": "rYQf8VipHjkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막에 기호 :가 있는 문장은 리스트에 담지 않고 넘어간다."
      ],
      "metadata": {
        "id": "laby64YG9e0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    \n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "id": "hdTeXoduuhDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee08f07-ddb4-4e20-9c41-ea274a4b66b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2   37   15 ...    0    0    0]\n",
            " [   2   67  133 ...    0    0    0]\n",
            " [   2 1551   37 ...    0    0    0]\n",
            " ...\n",
            " [   2   45  900 ...    0    0    0]\n",
            " [   2   45   66 ...    0    0    0]\n",
            " [   2    8   83 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f3b0a2d2c10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer**는 내부 단어장의 크기를 12000로 갖는다.\n",
        "<br/>단어장에 포함되지 못한 단어는 'unk'로 저장한다. "
      ],
      "metadata": {
        "id": "RL4x_ig_qPh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "준비한 tokenizer를 이용해 corpus를 Tensor로 변환한다."
      ],
      "metadata": {
        "id": "bS8FHiQYqYRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**padding='post'**는 입력 데이터의 시퀀스 길이를 일정하게 맞춘다.\n",
        "<br/>만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다."
      ],
      "metadata": {
        "id": "mw3DuFohqZpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**maxlen=15**는 토큰의 개수가 15개 넘어가는 문장을 제외한다.\n",
        "<br/>지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거할 필요가 있다. "
      ],
      "metadata": {
        "id": "8MCwckVNBSzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:3, :10])"
      ],
      "metadata": {
        "id": "aVVdFqWAukXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9977ee29-a158-44ff-9d42-9d4393bae199"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2   37   15  717  113    9  181    4    3    0]\n",
            " [   2   67  133  117  181   96   27   24   84   20]\n",
            " [   2 1551   37   15  717  113    9  181    4    3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성된 텐서 데이터를 3번째 행, 10번째 열까지만 출력한다."
      ],
      "metadata": {
        "id": "GgwitDCA1FLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "id": "PBMjFzwNuk0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1083642-95d6-4592-fab3-6cbb8624eb54"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " tokenizer에 구축된 단어 사전의 인덱스를 통해 단어 사전이 어떻게 구축되었는지 확인한다."
      ],
      "metadata": {
        "id": "5f-A7ha41Q-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_input = tensor[:, :-1]  \n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "id": "hMwm8YKbunbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2817fc-4948-41c5-a9a4-b7c7c9e551d2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2  37  15 717 113   9 181   4   3   0   0   0   0   0]\n",
            "[ 37  15 717 113   9 181   4   3   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor에서 마지막 토큰을 잘라내서 소스 문장 **src_input**을 생성한다.\n"
      ],
      "metadata": {
        "id": "J0iu6JaG1hJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막 토큰은 end가 아니라 pad일 가능성이 높다."
      ],
      "metadata": {
        "id": "nW08LPLo1n07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor에서 start를 잘라내서 타겟 문장 **tgt_input**을 생성한다."
      ],
      "metadata": {
        "id": "5holoN2W1oxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train, val 데이터 분리"
      ],
      "metadata": {
        "id": "A9QkL92ktsrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
        "                                                    tgt_input,    \n",
        "                                                    test_size=0.2,   \n",
        "                                                    random_state=1)  \n",
        "\n",
        "print('enc_train 개수: ', len(enc_train),', enc_val 개수: ', len(enc_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIoKJQwU2DgM",
        "outputId": "c75331ba-2b5f-42ac-e2b1-b94efe1d956d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc_train 개수:  140599 , enc_val 개수:  35150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sklearnn** 모듈의 **train_test_split**를 이용해 데이터셋 분리를 한다.\n",
        "<br/>소스 문장 **src_input**을 특징 데이터, 타겟 문장 **tgt_input**을 정답 데이터로 사용한다.\n",
        "<br/>전체의 20%를 평가 데이터로 사용한다.\n",
        "<br/>**random_state**는 데이터를 무작위로 정렬하여 분리한다."
      ],
      "metadata": {
        "id": "-aIbV7qe1928"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Source Train: ', enc_train.shape)\n",
        "print('Target Train: ', dec_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QQc_zIAKZz",
        "outputId": "99390fa3-406c-4ec4-ad4f-b2338aceddd1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Train:  (140599, 14)\n",
            "Target Train:  (140599, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "LdxSEnrouBJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ed4ce9-c8b0-4bab-93db-a0469fd4e244"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WigPZz2O5ZCr",
        "outputId": "08938fa0-3208-4706-de7e-f82fa417a552"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch size**는 한 번에 네트워크에 넘겨주는 데이터의 수이다.\n",
        "<br/>trade off로서 컴퓨터의 메모리 문제 때문에 분할해서 학습하는 것이다.\n",
        "\n",
        "<br/>140599 ≥ 140544 = 256 * 549\n",
        "<br/>train data num = batch size * step\n",
        "\n",
        "<br/>35150 = 256 * 137 ≥ 35072\n",
        "<br/>validation data num = batch size * step\n",
        "\n",
        "<br/>주의할 점은 epoch와 batch size는 다른 개념이다.\n",
        "<br/>epoch = batch size * step\n"
      ],
      "metadata": {
        "id": "ICTY6YIpaXNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**vocab size**는 tokenizer가 구축한 단어사전 내 7000개, 0 : pad를 포함하여 7001개를 포함한다."
      ],
      "metadata": {
        "id": "II-5WOeN4kqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학습 모델"
      ],
      "metadata": {
        "id": "XG9ld0Xvtzhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.keras.Model을 Subclassing하는 방식으로 만든다.\n",
        "<br/>Embedding 레이어 1개, LSTM 레이어 2개, Dense 레이어 1개로 구성된다"
      ],
      "metadata": {
        "id": "P3efBSKi5_Tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "EJWb3Pjhu0O9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 모델 **model1**\n",
        "<br/>하이퍼 파라미터를 설정한 학습 모델 **model2**\n",
        "<br/>평가 모델 **model3**으로 설정한다."
      ],
      "metadata": {
        "id": "3tMryZ5u7nlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model1 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "nnDRgmqr7mNr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding 레이어**는 이 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꾼다.\n",
        "<br/>워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현(representation)으로 사용된다."
      ],
      "metadata": {
        "id": "OEYdPyFl6WPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model1(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "018DgCW7vuZm",
        "outputId": "dfb48935-3508-444e-caef-54800f77f33c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[-6.87977490e-06, -1.93995715e-04, -1.40690041e-04, ...,\n",
              "         -1.32525340e-04, -1.88838603e-04,  8.58334024e-05],\n",
              "        [-7.02813340e-05, -3.35908437e-04, -3.58021389e-05, ...,\n",
              "         -5.84428453e-05, -2.20608461e-04,  1.32566211e-05],\n",
              "        [-1.38883697e-04, -4.50056134e-04, -2.62651796e-04, ...,\n",
              "         -1.95743938e-04, -1.14026632e-04, -1.19659278e-04],\n",
              "        ...,\n",
              "        [-2.41048387e-04,  4.87185054e-04, -3.31626361e-04, ...,\n",
              "         -2.02280178e-04,  1.18767741e-04, -2.80346925e-04],\n",
              "        [-7.41479686e-04,  7.02739693e-04, -5.76830818e-04, ...,\n",
              "         -2.46126001e-04,  3.31051851e-04, -3.06490518e-04],\n",
              "        [-1.29483629e-03,  9.88811720e-04, -7.81803625e-04, ...,\n",
              "         -2.85719143e-04,  5.50867000e-04, -3.53977463e-04]],\n",
              "\n",
              "       [[-6.87977490e-06, -1.93995715e-04, -1.40690041e-04, ...,\n",
              "         -1.32525340e-04, -1.88838603e-04,  8.58334024e-05],\n",
              "        [-7.02813340e-05, -3.35908437e-04, -3.58021389e-05, ...,\n",
              "         -5.84428453e-05, -2.20608461e-04,  1.32566211e-05],\n",
              "        [-2.97978491e-04, -5.08224766e-04,  9.68505919e-05, ...,\n",
              "          1.97856541e-04, -2.30253077e-04,  1.15532284e-05],\n",
              "        ...,\n",
              "        [ 7.30885833e-04,  1.08791015e-03,  2.83553090e-04, ...,\n",
              "          7.11198372e-04,  3.28194146e-04, -4.86329925e-04],\n",
              "        [ 8.95955833e-04,  1.31195178e-03, -1.71984779e-04, ...,\n",
              "          3.96661315e-04, -5.57839849e-05, -6.34057389e-04],\n",
              "        [ 1.07030862e-03,  1.58815354e-03, -4.87745507e-04, ...,\n",
              "          4.93586005e-04, -3.74272233e-04, -8.81614629e-04]],\n",
              "\n",
              "       [[-6.87977490e-06, -1.93995715e-04, -1.40690041e-04, ...,\n",
              "         -1.32525340e-04, -1.88838603e-04,  8.58334024e-05],\n",
              "        [-3.59566708e-04, -3.94515548e-04, -2.66730203e-04, ...,\n",
              "         -2.65092240e-04, -3.60213482e-04,  1.06949323e-04],\n",
              "        [-4.57688293e-04, -3.81858874e-04, -4.13485599e-04, ...,\n",
              "         -4.25838487e-04, -1.93147265e-04,  4.48295532e-06],\n",
              "        ...,\n",
              "        [-7.76400266e-04, -4.38550691e-04,  7.27168401e-04, ...,\n",
              "          3.84076557e-04,  8.62986373e-04, -2.71967001e-04],\n",
              "        [-1.28305482e-03,  1.00431243e-05,  5.13850420e-04, ...,\n",
              "          2.24215502e-04,  8.84622044e-04, -2.41338203e-04],\n",
              "        [-1.83590199e-03,  4.84239019e-04,  3.30480514e-04, ...,\n",
              "          6.22229927e-05,  9.06106085e-04, -2.16143162e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-6.87977490e-06, -1.93995715e-04, -1.40690041e-04, ...,\n",
              "         -1.32525340e-04, -1.88838603e-04,  8.58334024e-05],\n",
              "        [-4.76196612e-04, -1.69092193e-04, -1.34404681e-05, ...,\n",
              "         -3.44230211e-04, -4.60564799e-04,  1.47745741e-04],\n",
              "        [-6.28749433e-04, -2.47702555e-04, -1.02052318e-05, ...,\n",
              "         -5.48824493e-04, -6.40642189e-04, -1.41679091e-04],\n",
              "        ...,\n",
              "        [-3.02598113e-03,  1.51415740e-03, -6.71142188e-04, ...,\n",
              "         -8.97948630e-04,  4.08847845e-04, -9.02511092e-05],\n",
              "        [-3.45226633e-03,  1.81780430e-03, -5.68105199e-04, ...,\n",
              "         -9.66960855e-04,  5.26832358e-04, -1.37380499e-04],\n",
              "        [-3.84816923e-03,  2.07470241e-03, -4.36812144e-04, ...,\n",
              "         -1.02936896e-03,  5.96738537e-04, -1.78245638e-04]],\n",
              "\n",
              "       [[-6.87977490e-06, -1.93995715e-04, -1.40690041e-04, ...,\n",
              "         -1.32525340e-04, -1.88838603e-04,  8.58334024e-05],\n",
              "        [ 1.53735993e-04, -3.93707684e-04, -9.53200215e-05, ...,\n",
              "         -2.20280213e-04, -1.24281523e-05,  5.84930131e-05],\n",
              "        [ 2.26170043e-04, -4.79310984e-04, -2.57933221e-04, ...,\n",
              "         -2.36817039e-04,  1.94479740e-04, -9.26193024e-05],\n",
              "        ...,\n",
              "        [-2.27243989e-03,  8.38449516e-04, -5.47604461e-04, ...,\n",
              "         -1.81528856e-04,  8.98689614e-04, -3.33733478e-05],\n",
              "        [-2.79238704e-03,  1.15795177e-03, -4.91572137e-04, ...,\n",
              "         -2.93684716e-04,  9.11601470e-04, -1.03799997e-04],\n",
              "        [-3.26369912e-03,  1.44957751e-03, -4.07256215e-04, ...,\n",
              "         -4.04967024e-04,  8.91892589e-04, -1.62942437e-04]],\n",
              "\n",
              "       [[-6.87977490e-06, -1.93995715e-04, -1.40690041e-04, ...,\n",
              "         -1.32525340e-04, -1.88838603e-04,  8.58334024e-05],\n",
              "        [ 5.56202249e-05, -3.31840187e-04, -9.38446283e-06, ...,\n",
              "         -3.40559578e-04, -1.90270075e-04,  2.61720736e-04],\n",
              "        [ 1.68267128e-04, -1.90094201e-04,  4.59192088e-05, ...,\n",
              "         -2.70435208e-04, -2.67180178e-04,  3.79532255e-04],\n",
              "        ...,\n",
              "        [ 6.46377041e-04,  1.98245252e-04, -1.64832018e-04, ...,\n",
              "         -7.92826468e-04, -2.58210523e-04,  1.23950769e-04],\n",
              "        [ 2.03037576e-04,  4.32992354e-04, -3.66544293e-04, ...,\n",
              "         -9.87045350e-04,  8.12718499e-05,  1.18101976e-04],\n",
              "        [-3.66596883e-04,  7.58771668e-04, -4.77328314e-04, ...,\n",
              "         -1.14854006e-03,  4.24963509e-04,  6.55016338e-05]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋에서 데이터 한 배치만 불러온다.\n",
        "<br/>한 배치만 불러온 데이터를 모델에 넣는다."
      ],
      "metadata": {
        "id": "MZ9TZ7CV44W7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model의 input shape가 결정되면서 model.build()가 자동으로 호출된다.\n",
        "<br/>"
      ],
      "metadata": {
        "id": "6cRD5_NN6x7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "5gcqszZDu3T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507fef4b-9b53-4d97-89ba-1d0ae074d692"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  3072256   \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  12301025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model1.compile(loss=loss, optimizer=optimizer)\n",
        "model1.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "id": "OMdkMRFbu7KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1218eee4-5f5b-4494-e32e-a933eff02028"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 52s 89ms/step - loss: 3.7268\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 3.2022\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 3.0118\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.8693\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.7456\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.6322\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.5261\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.4259\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.3317\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.2413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b0a95e090>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1**의 train loss는 2.2413이다."
      ],
      "metadata": {
        "id": "Yjf-mQkviLnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학습 모델 (하이퍼 파라미터 설정)"
      ],
      "metadata": {
        "id": "K9h4eV6w8jf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**에서 하이퍼 파라미터를 다음과 같이 설정한다.\n",
        "> embedding_size = 256 → 600\n",
        "<br/>hidden_size = 1024 → 2048\n"
      ],
      "metadata": {
        "id": "QOEvQmQcZsQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 600\n",
        "hidden_size = 2048\n",
        "model2 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "jo9Fpr7yMEqr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model2(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO9qatX-MEtR",
        "outputId": "93531e36-aaec-45e6-da0b-4f14514662e7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[-3.01115215e-04,  3.91958427e-04, -1.63486984e-05, ...,\n",
              "         -9.71841655e-05, -8.77720304e-05, -1.15989147e-04],\n",
              "        [-3.48189264e-04,  8.04071198e-04, -2.60386034e-04, ...,\n",
              "          4.41514203e-05, -1.93374319e-04, -1.10662935e-04],\n",
              "        [-3.54032702e-04,  1.11997244e-03, -7.92753708e-05, ...,\n",
              "         -1.37290393e-04, -5.15777465e-05, -8.09020858e-05],\n",
              "        ...,\n",
              "        [-1.41741231e-03,  1.71547430e-03, -1.38153293e-04, ...,\n",
              "         -1.35182508e-03,  6.81104488e-04, -1.84989371e-03],\n",
              "        [-1.89124269e-03,  1.59976096e-03, -2.92693876e-04, ...,\n",
              "         -1.21863675e-03,  8.76621751e-04, -2.26036622e-03],\n",
              "        [-2.14189710e-03,  1.73954817e-03, -7.65709963e-04, ...,\n",
              "         -1.04719261e-03,  1.41343160e-03, -2.50810711e-03]],\n",
              "\n",
              "       [[-3.01115215e-04,  3.91958427e-04, -1.63486984e-05, ...,\n",
              "         -9.71841655e-05, -8.77720304e-05, -1.15989147e-04],\n",
              "        [-6.30939147e-04,  4.57685470e-04, -2.61101086e-04, ...,\n",
              "         -5.62434492e-04,  3.01640161e-04, -1.98128197e-04],\n",
              "        [-5.68394433e-04,  4.72426385e-04, -5.42881433e-04, ...,\n",
              "         -8.42956360e-04,  6.62616338e-04, -2.74508580e-04],\n",
              "        ...,\n",
              "        [-2.16535456e-03,  3.03234765e-03, -4.93406272e-03, ...,\n",
              "          1.27789727e-03,  4.39180154e-03, -9.40082478e-04],\n",
              "        [-2.21335120e-03,  3.36070335e-03, -5.30952215e-03, ...,\n",
              "          1.41958788e-03,  4.44653397e-03, -9.45270876e-04],\n",
              "        [-2.24866578e-03,  3.66122951e-03, -5.61940996e-03, ...,\n",
              "          1.52938347e-03,  4.44106665e-03, -9.48509143e-04]],\n",
              "\n",
              "       [[-3.01115215e-04,  3.91958427e-04, -1.63486984e-05, ...,\n",
              "         -9.71841655e-05, -8.77720304e-05, -1.15989147e-04],\n",
              "        [-4.59621806e-04,  1.33046793e-04,  4.34948306e-04, ...,\n",
              "         -2.66732997e-04, -5.03710995e-04, -1.80144198e-04],\n",
              "        [-3.67371074e-04, -1.95247063e-04,  8.50221259e-04, ...,\n",
              "         -5.99082443e-04, -3.81365593e-04,  2.42491747e-04],\n",
              "        ...,\n",
              "        [-1.31236203e-03,  7.07924948e-04, -1.48282875e-03, ...,\n",
              "         -6.35663455e-04,  7.14565511e-04, -1.45691424e-03],\n",
              "        [-1.43947103e-03,  1.37388508e-03, -2.26122839e-03, ...,\n",
              "         -3.74647381e-04,  1.35116931e-03, -1.47085055e-03],\n",
              "        [-1.57668965e-03,  1.98793714e-03, -2.99273757e-03, ...,\n",
              "         -1.12007270e-04,  1.91630411e-03, -1.44704478e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-2.53715931e-04,  2.32172009e-04, -3.57089993e-05, ...,\n",
              "         -2.04300395e-05,  3.45010572e-04,  1.28842657e-04],\n",
              "        [-4.91477200e-04,  5.55698469e-04, -2.23021954e-04, ...,\n",
              "         -4.63021352e-05,  3.10843752e-04,  2.58343847e-04],\n",
              "        [-5.49072400e-04,  5.31838799e-04, -5.25698648e-04, ...,\n",
              "         -2.65330833e-04,  3.89267138e-04,  2.08825280e-04],\n",
              "        ...,\n",
              "        [-5.78452600e-04, -4.24144528e-04,  9.43148392e-04, ...,\n",
              "          1.99905146e-04,  1.09269726e-03,  6.32194104e-04],\n",
              "        [-5.16650791e-04, -8.74496822e-04,  5.94918965e-04, ...,\n",
              "         -3.21580563e-04,  8.08226934e-04,  6.71398418e-04],\n",
              "        [-3.03560228e-04, -1.02989154e-03,  5.01939212e-04, ...,\n",
              "         -7.48601335e-04,  9.16500227e-04,  6.46594912e-04]],\n",
              "\n",
              "       [[-3.01115215e-04,  3.91958427e-04, -1.63486984e-05, ...,\n",
              "         -9.71841655e-05, -8.77720304e-05, -1.15989147e-04],\n",
              "        [-7.39146606e-04,  3.31487099e-04,  3.31438525e-04, ...,\n",
              "          7.80021401e-06, -2.48728000e-04, -1.64013341e-04],\n",
              "        [-1.19412295e-03,  3.32554482e-04,  8.19642679e-04, ...,\n",
              "          3.38725018e-04, -9.38667043e-04, -2.32401580e-05],\n",
              "        ...,\n",
              "        [-1.17517693e-03,  1.87919359e-03, -1.06879976e-03, ...,\n",
              "          1.83952902e-03,  1.63649721e-03, -1.65693439e-03],\n",
              "        [-1.31832203e-03,  2.34179897e-03, -1.95774296e-03, ...,\n",
              "          1.87334733e-03,  2.28594616e-03, -1.67220854e-03],\n",
              "        [-1.46399857e-03,  2.77366000e-03, -2.77194357e-03, ...,\n",
              "          1.90519285e-03,  2.80426187e-03, -1.64989883e-03]],\n",
              "\n",
              "       [[-3.01115215e-04,  3.91958427e-04, -1.63486984e-05, ...,\n",
              "         -9.71841655e-05, -8.77720304e-05, -1.15989147e-04],\n",
              "        [-5.05345874e-04,  7.29841646e-04,  2.75527535e-04, ...,\n",
              "         -1.91912448e-04, -5.38831751e-04,  9.84403450e-05],\n",
              "        [-5.62257890e-04,  5.53913414e-04,  5.47833683e-04, ...,\n",
              "         -1.44994105e-04, -4.44657489e-04,  3.16826714e-04],\n",
              "        ...,\n",
              "        [-1.01742284e-04, -4.27975756e-04, -8.13606253e-04, ...,\n",
              "         -1.35600253e-03, -1.77524751e-04,  7.08567328e-04],\n",
              "        [ 2.13737949e-04, -3.91881069e-04, -5.27366239e-04, ...,\n",
              "         -1.26470882e-03, -2.59622921e-05,  7.48003251e-04],\n",
              "        [-8.20685818e-05, -3.23163491e-04, -3.43755702e-04, ...,\n",
              "         -9.37075703e-04,  3.18269071e-04,  5.48226002e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TZJwHMbMEv0",
        "outputId": "0bbc3058-f217-4169-cf30-8f77b3e99ceb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     multiple                  7200600   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               multiple                  21700608  \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               multiple                  33562624  \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,053,881\n",
            "Trainable params: 87,053,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model2.compile(loss=loss, optimizer=optimizer)\n",
        "model2.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM8qTaMVMEyb",
        "outputId": "7970b188-b2e2-49e9-8ac2-9963bab3d8f6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 132s 236ms/step - loss: 3.5851\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 2.9976\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 2.7200\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 2.4658\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 2.2204\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 1.9836\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 129s 236ms/step - loss: 1.7585\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 129s 236ms/step - loss: 1.5524\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 129s 236ms/step - loss: 1.3694\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 129s 236ms/step - loss: 1.2162\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b08ab0110>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**의 train loss는 1.2162이다."
      ],
      "metadata": {
        "id": "_4fWdrvLiIRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#평가 모델"
      ],
      "metadata": {
        "id": "YvKJIe__JPf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 높은 **model2**의 하이퍼 파라미터 값을 평가 모델 **model3**에 사용한다.\n",
        "> embedding_size = 600\n",
        "<br/>hidden_size = 2048\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ucL7-Sg_ZHfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 600\n",
        "hidden_size = 2048\n",
        "model3 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "9bVJmLmlJX5K"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in val_dataset.take(1): break\n",
        "\n",
        "model3(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TwG-IO0JYIb",
        "outputId": "73d22b08-7423-4fa0-e258-3887a876a9e8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[-1.58004943e-04, -5.43169990e-05, -1.31364209e-06, ...,\n",
              "          1.66834259e-04,  1.60625609e-06,  2.28392979e-04],\n",
              "        [-2.21902214e-04, -8.14266459e-05,  4.06967265e-05, ...,\n",
              "         -1.17828940e-05, -3.38747050e-05,  2.91785575e-04],\n",
              "        [ 1.51709144e-04,  2.71485296e-05,  1.29696753e-04, ...,\n",
              "         -3.34078883e-04, -7.54812281e-05,  6.37324469e-04],\n",
              "        ...,\n",
              "        [ 1.50438980e-03, -8.64717702e-04,  6.21383195e-04, ...,\n",
              "         -5.22706832e-04, -1.85588445e-03,  4.46000020e-04],\n",
              "        [ 1.40378741e-03, -5.83821617e-04,  6.52055081e-04, ...,\n",
              "         -8.09120189e-04, -1.59672368e-03,  3.65596527e-04],\n",
              "        [ 1.41646573e-03, -4.07556450e-04,  5.28846809e-04, ...,\n",
              "         -6.91144145e-04, -1.23948161e-03,  3.78602272e-04]],\n",
              "\n",
              "       [[-9.28000300e-05,  8.87763017e-05, -2.91218923e-04, ...,\n",
              "          7.63115168e-05,  6.37637713e-05, -3.41677049e-04],\n",
              "        [-5.08142577e-04, -4.59866606e-05,  3.22749329e-05, ...,\n",
              "         -1.46010454e-04,  2.93927907e-04, -8.87366943e-04],\n",
              "        [-1.04925281e-03, -2.49390112e-04,  1.55176138e-04, ...,\n",
              "         -1.37497220e-04,  3.36186349e-04, -9.07447829e-04],\n",
              "        ...,\n",
              "        [ 3.40888859e-04, -5.45441988e-04,  6.34060707e-04, ...,\n",
              "          2.25544674e-03,  1.33246451e-03, -9.47727123e-04],\n",
              "        [ 2.07107645e-04, -9.39005753e-04,  3.66564745e-05, ...,\n",
              "          2.93101370e-03,  1.22903183e-03, -4.78125352e-04],\n",
              "        [ 3.97674339e-05, -1.45308033e-03, -5.60536515e-04, ...,\n",
              "          3.68873496e-03,  1.08908524e-03,  6.39279824e-05]],\n",
              "\n",
              "       [[-9.28000300e-05,  8.87763017e-05, -2.91218923e-04, ...,\n",
              "          7.63115168e-05,  6.37637713e-05, -3.41677049e-04],\n",
              "        [-4.44794132e-04, -9.30522438e-05, -3.38637881e-04, ...,\n",
              "          8.43668604e-05, -3.53190844e-05, -4.34559799e-04],\n",
              "        [-7.16827170e-04, -3.99304670e-04, -5.82836336e-04, ...,\n",
              "          3.81296384e-04, -9.35263961e-05, -7.27278180e-04],\n",
              "        ...,\n",
              "        [-1.07653800e-03, -2.10159714e-03, -1.59368501e-03, ...,\n",
              "          4.96540219e-03, -5.90546697e-04,  2.15577101e-03],\n",
              "        [-1.10916444e-03, -2.72107683e-03, -1.89405051e-03, ...,\n",
              "          5.68685634e-03, -6.07071677e-04,  2.45739752e-03],\n",
              "        [-1.11927220e-03, -3.30163725e-03, -2.14265357e-03, ...,\n",
              "          6.33622427e-03, -6.52999210e-04,  2.69130757e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-9.28000300e-05,  8.87763017e-05, -2.91218923e-04, ...,\n",
              "          7.63115168e-05,  6.37637713e-05, -3.41677049e-04],\n",
              "        [ 2.14232670e-04,  1.57769813e-04, -2.59714929e-04, ...,\n",
              "          4.04092309e-04,  9.86574451e-05, -3.08889808e-04],\n",
              "        [ 7.50695326e-05,  9.25653949e-05, -2.67016003e-04, ...,\n",
              "          5.50764205e-04, -3.21837520e-04, -2.44627940e-04],\n",
              "        ...,\n",
              "        [-1.20793271e-03, -2.30601360e-03, -1.72704889e-03, ...,\n",
              "          5.01924986e-03,  4.34602145e-04,  2.70237401e-03],\n",
              "        [-1.21302914e-03, -2.88388343e-03, -1.90901710e-03, ...,\n",
              "          5.73537266e-03,  3.23933578e-04,  2.92894267e-03],\n",
              "        [-1.20009552e-03, -3.42304353e-03, -2.07228144e-03, ...,\n",
              "          6.37591211e-03,  1.77789218e-04,  3.08986683e-03]],\n",
              "\n",
              "       [[-9.28000300e-05,  8.87763017e-05, -2.91218923e-04, ...,\n",
              "          7.63115168e-05,  6.37637713e-05, -3.41677049e-04],\n",
              "        [-5.45650313e-04,  1.54407317e-05, -5.24099974e-04, ...,\n",
              "          2.16365210e-04, -9.48639536e-06, -3.46316316e-04],\n",
              "        [-9.30754584e-04, -4.69929255e-05, -5.10581536e-04, ...,\n",
              "          4.27950552e-04, -7.19988893e-05, -9.38971934e-05],\n",
              "        ...,\n",
              "        [-1.50908716e-03,  2.38519418e-03,  2.01838702e-05, ...,\n",
              "         -8.02695067e-05, -3.06055276e-03, -2.85535469e-04],\n",
              "        [-1.44495792e-03,  2.98570446e-03, -1.45187296e-04, ...,\n",
              "         -4.52748151e-04, -2.55387439e-03, -5.68398391e-04],\n",
              "        [-1.27194833e-03,  3.51561769e-03, -1.03075021e-04, ...,\n",
              "         -8.06105090e-04, -2.09282665e-03, -3.50439688e-04]],\n",
              "\n",
              "       [[ 4.06268839e-04, -1.08196573e-05,  1.10956018e-04, ...,\n",
              "          2.45145755e-04,  9.49153673e-06,  2.47030664e-04],\n",
              "        [ 4.89030033e-04,  3.66600470e-05, -1.92278996e-04, ...,\n",
              "          3.13899596e-04,  1.28643136e-04,  5.95094680e-05],\n",
              "        [ 1.67299935e-04,  1.10225003e-04, -4.60997428e-04, ...,\n",
              "          1.17370655e-04,  3.22976615e-04, -2.03439471e-04],\n",
              "        ...,\n",
              "        [-1.24671066e-03,  2.21010177e-05, -8.75367026e-04, ...,\n",
              "          3.84705869e-04,  1.23533746e-03, -1.33737712e-03],\n",
              "        [-1.18695339e-03, -2.70358432e-04, -3.91541107e-04, ...,\n",
              "          2.75664643e-04,  7.54981069e-04, -1.36870018e-03],\n",
              "        [-8.70463671e-04, -2.87189818e-04, -2.42657334e-04, ...,\n",
              "         -8.53077509e-05,  2.64869945e-04, -1.51977898e-03]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPi_vBP5JYLK",
        "outputId": "7577c3e7-3a98-4f74-e2aa-50ddf029c5db"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     multiple                  7200600   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               multiple                  21700608  \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               multiple                  33562624  \n",
            "                                                                 \n",
            " dense_3 (Dense)             multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,053,881\n",
            "Trainable params: 87,053,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model3.compile(loss=loss, optimizer=optimizer)\n",
        "model3.fit(val_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6UpWhuXJYOS",
        "outputId": "04db15de-d060-419f-ec0d-9ef024c97124"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "137/137 [==============================] - 34s 235ms/step - loss: 4.1330\n",
            "Epoch 2/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 3.4023\n",
            "Epoch 3/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 3.1710\n",
            "Epoch 4/10\n",
            "137/137 [==============================] - 32s 236ms/step - loss: 2.9884\n",
            "Epoch 5/10\n",
            "137/137 [==============================] - 32s 236ms/step - loss: 2.8115\n",
            "Epoch 6/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 2.6227\n",
            "Epoch 7/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 2.4207\n",
            "Epoch 8/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 2.2107\n",
            "Epoch 9/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 1.9988\n",
            "Epoch 10/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 1.7857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a8a21dc10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model3**의 valadation loss는 1.7857이다."
      ],
      "metadata": {
        "id": "P9TYnQiJh1cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#가사 생성"
      ],
      "metadata": {
        "id": "oe43geLkKNu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "   \n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "iI2gJn_A8NZg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.convert_to_tensor**는 테스트를 위해서 입력받은 init_sentence도 텐서로 변환한다."
      ],
      "metadata": {
        "id": "Jz3RINnn9J3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**while Loop**에서 단어를 하나씩 예측해 문장을 만든다.\n",
        "<br/>1) 입력받은 문장의 텐서를 입력한다.\n",
        "<br/>2) 예측된 값 중 가장 높은 확률인 word index를 뽑아낸다.\n",
        "<br/>3) 2에서 예측된 word index를 문장 뒤에 붙인다.\n",
        "<br/>4) 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마친다."
      ],
      "metadata": {
        "id": "Qbnc60dc9yj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer**를 이용해 word index를 단어로 하나씩 변환합니다 "
      ],
      "metadata": {
        "id": "DGxJTUaY96We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 높은 학습 모델 **model2**를 사용해 가사를 생성한다."
      ],
      "metadata": {
        "id": "2HKRbru-kk27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> i love\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nV3xG_-IkZtC",
        "outputId": "9e2c2c30-4ec3-48cb-cc93-b256afbc0351"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2l23ETvyjBia",
        "outputId": "5b4450df-a8d1-4c9b-d3f2-4ef22f04e51c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> good day sunshine , <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> out\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iSIzshmzjBYa",
        "outputId": "a2ab663f-0ea5-4c98-a50e-ca7300290214"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> out of the most highest cloud <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> see\")"
      ],
      "metadata": {
        "id": "Mu2jWUvOt7hV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67187760-4640-46ed-eeca-bd956b6eaa82"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> see i got the whole city in the world <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> where\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mW1aWEXcj49a",
        "outputId": "0eb0baad-53c1-44b3-e242-7ca748812bea"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> where the eyelids go <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결론"
      ],
      "metadata": {
        "id": "sgq97imgO7Fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##하이퍼 파라미터 튜닝"
      ],
      "metadata": {
        "id": "6K0aAKGAqK_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**에서 하이퍼 파라미터를 다음과 같이 설정한다.\n",
        "> embedding_size = 256 → 600\n",
        "<br/>hidden_size = 1024 → 2048"
      ],
      "metadata": {
        "id": "YZf1hWeilkjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 높은 **model2**의 하이퍼 파라미터 값을 평가 모델 **model3**에 사용한다.\n",
        "> embedding_size = 600\n",
        "<br/>hidden_size = 2048"
      ],
      "metadata": {
        "id": "IMmlvdoeO7MD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1**의 train loss는 2.2413이다.\n",
        "<br/>**model2**의 train loss는 1.2162이다.\n",
        "<br/>**model3**의 valadation loss는 1.7857이다."
      ],
      "metadata": {
        "id": "1NGKmBOWlJRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 설정으로 train loss는 감소했지만\n",
        "<br/>train loss와 valadation loss의 차이는 0.5695이다."
      ],
      "metadata": {
        "id": "1tc1g5Lyla2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding_size가 커지고 hidden_size가 깊어져서\n",
        "과적합이 발생한 것인가?\n",
        "<br/>하이퍼 파라미터 값이 크다고 성능이 개선될거라는 보장은 없다."
      ],
      "metadata": {
        "id": "P5ndLwntl3Mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "또한 튜닝에 있어서 무슨 하이퍼 파라미터를 선택해야 하는가?\n",
        "<br/>embedding_size, hidden_size 튜닝은 무슨 시사점을 남기는가?"
      ],
      "metadata": {
        "id": "_hA_2XzgnHTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 튜닝 결과에 대한 분석 방법을 알고자 튜닝 관련 논문을 찾아보았다."
      ],
      "metadata": {
        "id": "sQunSVR6o9NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[RNN모델에서 하이퍼 파라미터 변화에 따른 정확도와 손실 성능, 분석융합정보논문지 v.11 no.7, 2021, pp.31 - 38, 김준용, 박구락](https://www.koreascience.or.kr/article/JAKO202123157143805.pdf)\n"
      ],
      "metadata": {
        "id": "h5thXMjSmDWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 논문에서는 LSTM의 unit, batch_size, embedding_size를 설정한다.\n"
      ],
      "metadata": {
        "id": "xWkxITBvmJqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "unit, batch_size, embedding_size 튜닝은 무슨 시사점을 남기는가?\n",
        "* embedding_size가 가장 영향력이 큰 하이퍼 파라미터였다.\n",
        "* Unit의 개수가 적을수록 batch_size가 클 수록 성능이 높아진다.\n",
        "* Embedding size가 커지면서 성능이 높아졌다가 낮아진다."
      ],
      "metadata": {
        "id": "KyUqNY2CoS3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 하이퍼 파라미터 튜닝의 결과에 대해 분석할 수 있었던 이유는\n",
        "<br/>연구자가 하이퍼 파라미터 변화에 따른 Loss와 Accuracy의 추이를 표로 정리했기 때문이다."
      ],
      "metadata": {
        "id": "srELNMwPo6Ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 변화에 따른 학습 결과를 문서로 정리할 수 있는 알고리즘을 짜는 방법을 알고 싶다."
      ],
      "metadata": {
        "id": "tKRpUhjPmDcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 데이터셋"
      ],
      "metadata": {
        "id": "J6Ybgv9lqNDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 노이즈에 대한 사전지식을 갖추고 웹크롤링과 데이터 전처리를 진행해야한다.\n",
        "* 문장 부호가 작성되지 않았거나 띄어쓰기가 되지 않은 상황에서 토큰의 단위에 따라 어떻게 분리하는가?\n",
        "\n"
      ],
      "metadata": {
        "id": "q9MFa_3nqNGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#참고문헌"
      ],
      "metadata": {
        "id": "VVZkeI61zg37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "\n",
        "[text_generation_shakespeare_rnn.ipynb](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_shakespeare_rnn/text_generation_shakespeare_rnn.ipynb#scrollTo=bui0MyTjv1Mp)\n",
        "\n",
        "[OS 모듈](https://wikidocs.net/3141)\n",
        "\n",
        "[Python re 모듈 사용법](https://brownbears.tistory.com/506)\n",
        "\n",
        "[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "\n",
        "\n",
        "[Python 리스트(List)와 리스트 메소드(append, insert, remove, pop, extend)](https://velog.io/@falling_star3/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9D%98-%EB%A6%AC%EC%8A%A4%ED%8A%B8List%EC%99%80-%EA%B4%80%EB%A0%A8-%ED%95%A8%EC%88%98%EB%93%A4append-insert-remove-pop-extend)\n",
        "\n",
        "\n",
        "[파이썬 문자열을 리스트로 만들기 – split, splitlines](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=debolm74&logNo=221953881991)\n",
        "\n",
        "[PyTorch로 시작하는 딥 러닝 입문  / 01. 자연어 처리 전처리 이해하기](https://wikidocs.net/64517)\n",
        "\n",
        "[4. 텍스트 전처리(정규화)](https://blockchainstudy.tistory.com/58)\n",
        "\n",
        "[PYTHON / NLTK 텍스트 파일 문장 단위로 분해하기 (SENTENCE TOKENIZE)](https://cryptosalamander.tistory.com/140)\n",
        "\n",
        "[Python에서 문자열의 단어 계산](https://www.delftstack.com/ko/howto/python/python-count-words-in-string/)\n",
        "\n",
        "[15.Batch size & Batch Norm](https://nittaku.tistory.com/293)\n",
        "\n",
        "\n",
        "[RNN모델에서 하이퍼 파라미터 변화에 따른 정확도와 손실 성능, 분석융합정보논문지 v.11 no.7, 2021, pp.31 - 38, 김준용, 박구락](https://www.koreascience.or.kr/article/JAKO202123157143805.pdf)\n"
      ],
      "metadata": {
        "id": "ttZWzlIErLhb"
      }
    }
  ]
}