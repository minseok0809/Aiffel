{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E_05]ImageClassfication(RockSiccsorsPaper).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**인공지능과 가위바위보 하기**"
      ],
      "metadata": {
        "id": "ek8c_uGStYEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UbjenxebIG9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "개발 환경\n",
        "<br/>데이터 정보\n",
        "<br/>데이터 전처리\n"
      ],
      "metadata": {
        "id": "hnmSklCMBDGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델\n",
        "<br/>Drop-Out\n",
        "<br/>Non-Drop-Out"
      ],
      "metadata": {
        "id": "7FMGVOmsHd0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습\n",
        "<br/>모델 평가\n",
        "<br/>과적합 문제\n",
        "<br/>과적합을 방지하는 방법\n",
        "<br/>결론\n",
        "<br/>참고문헌"
      ],
      "metadata": {
        "id": "-bHEBZvAJNZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D9twJZVIJNHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#개발 환경"
      ],
      "metadata": {
        "id": "sEwljEJ6Zifo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "id": "LWywODpzxe0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ezj7KZegYJs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import splitfolders as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow는 구글이 개발한 오픈소스 소프트웨어 딥러닝 및 머신러닝 라이브러리이다. 수학 계산식과 데이터의 흐름을 노드와 엣지를 사용한 방향성 그래프, 데이터 플로우 그래프로 나타낸다.\n"
      ],
      "metadata": {
        "id": "I2Yn6FJnqOTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras는 Tensorflow 위에서 동작하는 라이브러리이다.\n",
        "<br/>사용자 친화적으로 개발된 Keras의 쉽다는 장점과\n",
        "<br/>딥러닝 프로젝트에서 범용적으로 활용할 수 있는\n",
        "<br/>Tensorflow의 장점을 통합할 수 있는 환경을 설정한다."
      ],
      "metadata": {
        "id": "MsAk6zlSbNgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy는 array 단위로 벡터와 행렬을 계산한다.\n"
      ],
      "metadata": {
        "id": "x7ADYBLHtU6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitfolders는 훈련 데이터, 평가 데이터, 검증 데이터를 분리한다."
      ],
      "metadata": {
        "id": "PKz__iE1lvtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "matplotlib은 다양한 데이터와 학습 모델을 시각화한다."
      ],
      "metadata": {
        "id": "3STUO8J5a00R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "os(Operating System)는 운영체제에서 제공되는 여러 기능을 파이썬에서 수행한다. <br/>예를 들어, 파일 복사, 디렉터리 생성, 파일 목록을 구할 수 있다."
      ],
      "metadata": {
        "id": "hdD-cj1mkVwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob"
      ],
      "metadata": {
        "id": "uEWnZkleUJ4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PIL(Python Image Library)는 다양한 이미지 파일 형식을 지원하는 작업 모듈이다. 다만, PIL의 지원이 2011년 중단되고, Pillow가 PIL의 후속 프로젝트로 나왔다.\n"
      ],
      "metadata": {
        "id": "PUDbh7UHqXRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "glob은 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다. 단, 조건에 정규식을 사용할 수 없으며 엑셀 등에서도 사용할 수 있는 '*'와 '?'같은 와일드카드만을 지원한다."
      ],
      "metadata": {
        "id": "EXaMFk4MtX6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iVeRPG09Vhwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > '/content/drive/MyDrive/lms/library_version.txt'"
      ],
      "metadata": {
        "id": "KIFPbUM4RV3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library_name = ['pandas=', 'numpy=', 'matplotlib=', 'split-folders=', 'tensorflow=', 'keras=', 'Pillow=', 'glob']\n",
        "library_version = []\n",
        "f = open('/content/drive/MyDrive/lms/library_version.txt', 'r')\n",
        "line = f.readline()\n",
        "while True:\n",
        "    line = f.readline()\n",
        "    if not line:\n",
        "      break\n",
        "    for i in library_name:\n",
        "      if i in line:\n",
        "        library_version.append(line)\n",
        "\n",
        "f.close()\n",
        "\n",
        "import sys\n",
        "print(sys.version)\n",
        "print()\n",
        "print(str(library_version).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"\\\\n\",\"\").replace(\",\",\"\"), end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MABNeL51RV6F",
        "outputId": "e04e22de-8812-46d6-bc1f-44c89417860f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n",
            "\n",
            "glob2==0.7 keras==2.8.0 matplotlib==3.2.2 numpy==1.21.6 pandas==1.3.5 Pillow==7.1.2 sklearn-pandas==1.8.0 split-folders==0.5.1 tensorflow==2.8.2+zzzcolab20220527125636"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "oCz5oa9pI2aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "MGUmf72sI2cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab에서 할당된 GPU를 확인한다.\n",
        "<br/>고용량 메모리 VM에 액세스한다."
      ],
      "metadata": {
        "id": "ltQp9SPcI2kQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 정보"
      ],
      "metadata": {
        "id": "846gqQXftfqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**rock_scissors_paper**"
      ],
      "metadata": {
        "id": "9KQEBJqHVdxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2021년 아이펠(Aiffel) 수강생이 촬영했던 가위, 바위, 보 이미지를 통합하여 만든 데이터셋이다.\n",
        "<br/>포토윅스라는 프로그램을 이용하여 이미지를 편집했다."
      ],
      "metadata": {
        "id": "jYZX65xMVPqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 데이터셋은 224X224 pixel의 6792개의 이미지로 구성되어 있다.\n",
        "<br/>rock(2202개), scissors(2320개), paper(2270개)의 이미지는 가위바위보 게임의 동작을 나타낸다.\n"
      ],
      "metadata": {
        "id": "EuFPsD-J5Y2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 전처리"
      ],
      "metadata": {
        "id": "1k2N6bUFub78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "change_path = '/content/drive/MyDrive/lms/rock_scissors_paper'\n",
        "\n",
        "os.chdir(change_path)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "T4Q3w9lAxwKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp.ratio('rock', output='rock_output',\n",
        "                  seed=1337, ratio=(.7, .0, .3))\n",
        "\n",
        "sp.ratio('scissors', output='scissors_output',\n",
        "                  seed=1337, ratio=(.7, .0, .3))\n",
        "\n",
        "sp.ratio('paper', output='paper_output',\n",
        "                  seed=1337, ratio=(.7, .0, .3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSFg68bzxwfR",
        "outputId": "3b817da0-07cd-4cd2-d6eb-4714d1326d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2202 files [00:16, 137.04 files/s]\n",
            "Copying files: 2320 files [00:19, 118.89 files/s]\n",
            "Copying files: 2270 files [00:16, 133.75 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitfolder는 훈련 데이터, 평가 데이터, 검증 데이터를 7:0:3으로 분리한다."
      ],
      "metadata": {
        "id": "YKaERm3BX5p4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "디렉토리에 따라 폴더를 생성하여 이미지 파일을 이동한다."
      ],
      "metadata": {
        "id": "UsbyCgr6BwDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train\n",
        "* rock_train\n",
        "* scissors_train\n",
        "* paper_train\n",
        "\n",
        "test\n",
        "* rock_test\n",
        "* scissors_test\n",
        "* paper_test\n"
      ],
      "metadata": {
        "id": "LeUENfOZBuyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")"
      ],
      "metadata": {
        "id": "fJ0TOY-8pxQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파일마다 모두 28x28 사이즈로 바꾼다."
      ],
      "metadata": {
        "id": "fEvLqmAbUVi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "왜 28X28인가?\n",
        "<br/>'Why 28x28 pixel'라고 검색해보았으나 나오지 않는다.\n",
        "<br/>784(28 x 28)개의 각 뉴런들은 각 픽셀의 밝기를 나타낸다고만 검색 결과가 나올 뿐이다."
      ],
      "metadata": {
        "id": "bg0uBaFDWk7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path1 = '/content/drive/MyDrive/lms/rock_scissors_paper/train/rock_train/'\n",
        "resize_images(image_dir_path1)"
      ],
      "metadata": {
        "id": "U7vzofNIuK8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676b4354-13af-4c41-f63e-8b45a22e8df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1541  images to be resized.\n",
            "1541  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rock 이미지를 28x28 사이즈로 바꾼다."
      ],
      "metadata": {
        "id": "NZWIU-8uVuwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path2 = '/content/drive/MyDrive/lms/rock_scissors_paper/train/scissors_train/'\n",
        "resize_images(image_dir_path2)"
      ],
      "metadata": {
        "id": "7JnXo7OduKbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27978ec-df29-443e-84e3-5618afc9b52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1624  images to be resized.\n",
            "1624  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "scissors 이미지를 28x28 사이즈로 바꾼다."
      ],
      "metadata": {
        "id": "UJmCgCThVszO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path3 = '/content/drive/MyDrive/lms/rock_scissors_paper/train/paper_train/'\n",
        "resize_images(image_dir_path3)"
      ],
      "metadata": {
        "id": "iM75wMsAuMmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0bd9df-0f22-4dcd-a2b6-b2f08604fd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1590  images to be resized.\n",
            "1590  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "paper 이미지를 28x28 사이즈로 바꾼다."
      ],
      "metadata": {
        "id": "wCz097juVycO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(img_path, number_of_data):\n",
        "    img_size = 28\n",
        "    color = 3\n",
        "    \n",
        "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
        "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
        "\n",
        "    idx = 0\n",
        "    for file in glob.iglob(img_path + '/rock_train/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 0\n",
        "        idx = idx + 1   \n",
        "\n",
        "    for file in glob.iglob(img_path + '/scissors_train/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 1\n",
        "        idx = idx + 1\n",
        "    \n",
        "    for file in glob.iglob(img_path + '/paper_train/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 2\n",
        "        idx = idx + 1\n",
        "        \n",
        "    return imgs, labels"
      ],
      "metadata": {
        "id": "19fxsAdFZ7RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "라벨을 rock(0), scissors(1), paper(2)로 한다.\n",
        "<br/>이미지와 라벨을 담은 행렬을 생성한다."
      ],
      "metadata": {
        "id": "ywOsxQAoYmyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for문을 실행하기 앞서 np.zeros와 reshape를 통해 행렬을 초기화한다.\n",
        "<br/>np.zeros는 크기(number_of_data * img_size * img_size * color)만큼의 0으로만 채워진 1차원 벡터를 생성한다."
      ],
      "metadata": {
        "id": "W5E_eolbTfdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reshape은 크기(number_of_data * img_size * img_size * color)만큼의 3차원 텐서를 생성한다."
      ],
      "metadata": {
        "id": "KFh_7PR4TvdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path4 = '/content/drive/MyDrive/lms/rock_scissors_paper/train/'\n",
        "(x_train,y_train) = load_data(image_dir_path4, 4755)\n",
        "x_train_norm = x_train/255.0"
      ],
      "metadata": {
        "id": "olkf0ve640Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 데이터 4755개, 테스트 데이터 2038개로 분리한 폴더에서 훈련 데이터를 불러온다."
      ],
      "metadata": {
        "id": "LB2TKBWB2xw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "255로 나누어 입력은 0~1 사이의 값으로 정규화한다.\n"
      ],
      "metadata": {
        "id": "gU0BgZrYQoxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_train shape: {}\".format(x_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))"
      ],
      "metadata": {
        "id": "VntxVlbB3lmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71c46f6-640e-4f2b-eed3-66eb542d1537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (4755, 28, 28, 3)\n",
            "y_train shape: (4755,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 학습"
      ],
      "metadata": {
        "id": "MHeidP5qufLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop-Out 적용한 모델의 이름은 'model1'\n",
        "<br/>Drop-Out 적용하지 않은 모델의 이름은 'model2'로 설정한다."
      ],
      "metadata": {
        "id": "RV_luSdSJ74u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Drop-Out"
      ],
      "metadata": {
        "id": "VepyrUECumIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_channel_1 = 256\n",
        "n_channel_2 = 512\n",
        "n_dense = 512\n",
        "n_class = 3\n",
        "n_drop_rate = 0.3\n",
        "n_train_epoch = 10"
      ],
      "metadata": {
        "id": "Svf7u78TbhNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이어의 개수, 분류 클래스의 개수, drop rate, 최적화의 학습단위(train epoch) 등 하이퍼파라미터 튜닝을 한다."
      ],
      "metadata": {
        "id": "k6WE685Kbjfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop-out은 서로 연결된 연결망(layer)에서 0부터 1 사이의 확률로 뉴런을 제거(drop)하는 기법이다.\n",
        "<br/>Drop-out을 적용하여 상관관계가 강한 Feature를 제외하여\n",
        "<br/>해당 Feature에만 출력값이 좌지우지되는 과대적합(overfitting)을 방지한다."
      ],
      "metadata": {
        "id": "IlYN2NOsb_M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 =keras.models.Sequential()\n",
        "model1.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
        "model1.add(keras.layers.MaxPool2D(2,2))\n",
        "model1.add(keras.layers.Dropout(n_drop_rate))\n",
        "model1.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
        "model1.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model1.add(keras.layers.Dropout(n_drop_rate))\n",
        "model1.add(keras.layers.Flatten())\n",
        "model1.add(keras.layers.Dense(n_dense, activation='relu'))\n",
        "model1.add(keras.layers.Dense(n_class, activation='softmax'))\n",
        "\n",
        "print('Model1 (Drop-Out 적용)에 추가된 Layer 개수: ', len(model1.layers))"
      ],
      "metadata": {
        "id": "q3NY98SDrmhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edddd870-e472-42d3-ccb6-11b001a52b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model1 (Drop-Out 적용)에 추가된 Layer 개수:  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫번째 레이어는 사이즈 3의 256개의 필터로 구성되어 있다. 이미지 형태는 28X28 크기이다.\n",
        "<br/>relu는 활성화함수로 구성된다.\n",
        "<br/>2 x 2 max-pooling 레이어를 가진다. 추상화된 형태를 오버피팅을 방지하는데 도움을 준다.\n",
        "<br/>Flatten은 입력을 1차원으로 변환한다.\n",
        "<br/>Dropout은 오버피팅을 방지한다.\n",
        "<br/>Dense는 최종적으로 지정된 Class로 분류한다."
      ],
      "metadata": {
        "id": "vOMrSPqJ8wBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "LW2YlIHmznhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f583599-ac97-400c-9c57-b6f31db60f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 26, 26, 256)       7168      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 13, 13, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 11, 11, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 5, 5, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               6554112   \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,742,979\n",
            "Trainable params: 7,742,979\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model1.fit(x_train_norm, y_train, epochs= n_train_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEB3KQMxda__",
        "outputId": "47360507-0058-4e3e-fca8-6080522228ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "149/149 [==============================] - 2s 10ms/step - loss: 1.1114 - accuracy: 0.3516\n",
            "Epoch 2/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.9955 - accuracy: 0.4927\n",
            "Epoch 3/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.7277 - accuracy: 0.6738\n",
            "Epoch 4/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.5363 - accuracy: 0.7676\n",
            "Epoch 5/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.3568 - accuracy: 0.8559\n",
            "Epoch 6/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.2471 - accuracy: 0.9110\n",
            "Epoch 7/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.1913 - accuracy: 0.9365\n",
            "Epoch 8/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.1340 - accuracy: 0.9535\n",
            "Epoch 9/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.1113 - accuracy: 0.9617\n",
            "Epoch 10/10\n",
            "149/149 [==============================] - 1s 10ms/step - loss: 0.0882 - accuracy: 0.9706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb3a6193f90>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 최적화 알고리즘으로 Adam을 사용한다."
      ],
      "metadata": {
        "id": "2j5W7Vp4efCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Adam]\n",
        "<br/>모멘텀과 AdaGrad를 결합한다.\n",
        "<br/>매개변수 공간을 효율적으로 탐색해주며\n",
        "<br/>하이퍼파라미터의 '편향 보정'이 진행된다는 점이 Adam의 특징이다."
      ],
      "metadata": {
        "id": "oA4hgymhf8vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout을 적용했을 때의 모델 성능이다.\n",
        "<br/>loss가 0.0882일 때, 97.06%의 accuracy가 나온다."
      ],
      "metadata": {
        "id": "U2-We-Fzern_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Non-Drop-Out"
      ],
      "metadata": {
        "id": "IOQhryPce0d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_channel_1 = 256\n",
        "n_channel_2 = 512\n",
        "n_channel_3 = 512\n",
        "n_dense = 512\n",
        "n_class = 3\n",
        "n_train_epoch = 10"
      ],
      "metadata": {
        "id": "0Z4aCzkAe9g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 =keras.models.Sequential()\n",
        "model2.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
        "model2.add(keras.layers.MaxPooling2D(2,2))\n",
        "model2.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
        "model2.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model2.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
        "model2.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model2.add(keras.layers.Flatten())\n",
        "model2.add(keras.layers.Dense(n_dense, activation='relu'))\n",
        "model2.add(keras.layers.Dense(n_class, activation='softmax'))\n",
        "\n",
        "print('Model2 (Drop-Out 미적용)에 추가된 Layer 개수: ', len(model2.layers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu4qNNCye91g",
        "outputId": "d49a056d-1eca-49a9-b248-f230ab8332e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model2 (Drop-Out 미적용)에 추가된 Layer 개수:  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCQC04vKfsDX",
        "outputId": "5f58aaf0-a741-4e59-9e14-24c5675c61de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 26, 26, 256)       7168      \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 13, 13, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 11, 11, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 5, 5, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 1, 1, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,811,331\n",
            "Trainable params: 3,811,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model2.fit(x_train_norm, y_train, epochs= n_train_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8a3YhDIfuMv",
        "outputId": "521c9650-16b9-4d9d-b20d-ae21f323f56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 1.0984 - accuracy: 0.3453\n",
            "Epoch 2/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.8671 - accuracy: 0.5880\n",
            "Epoch 3/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.4842 - accuracy: 0.7962\n",
            "Epoch 4/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.2454 - accuracy: 0.9079\n",
            "Epoch 5/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.1357 - accuracy: 0.9537\n",
            "Epoch 6/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.0796 - accuracy: 0.9714\n",
            "Epoch 7/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.1160 - accuracy: 0.9647\n",
            "Epoch 8/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.0281 - accuracy: 0.9903\n",
            "Epoch 9/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.0442 - accuracy: 0.9853\n",
            "Epoch 10/10\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.0317 - accuracy: 0.9905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4304338d0>"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout을 적용하지 않았을 때 모델 성능이 더 높다.\n",
        "<br/>loss가 0.0317일 때, 99.05%의 accuracy가 나온다."
      ],
      "metadata": {
        "id": "zesoupQCfxQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 평가"
      ],
      "metadata": {
        "id": "Z_A47AbGLZ-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path5 = '/content/drive/MyDrive/lms/rock_scissor_paper/test/rock_test/'\n",
        "resize_images(image_dir_path5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGa_hFhsMBCm",
        "outputId": "481c86f7-20db-47eb-88e9-3f5f6930b504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "661  images to be resized.\n",
            "661  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path6 = '/content/drive/MyDrive/lms/rock_scissor_paper/test/scissors_test/'\n",
        "resize_images(image_dir_path6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04WaK8CPL8vc",
        "outputId": "167205d2-7223-43ab-b3e2-f8a05e38deee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "696  images to be resized.\n",
            "696  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path7 = '/content/drive/MyDrive/lms/rock_scissors_paper/test/paper_test/'\n",
        "resize_images(image_dir_path7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSPTpJNZMBZr",
        "outputId": "da486e04-ca0f-496d-a921-386d31c460c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "681  images to be resized.\n",
            "681  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_data(img_path, number_of_data):\n",
        "    img_size = 28\n",
        "    color = 3\n",
        "    \n",
        "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
        "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
        "\n",
        "    idx = 0\n",
        "    for file in glob.iglob(img_path + '/rock_test/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 0\n",
        "        idx = idx + 1   \n",
        "\n",
        "    for file in glob.iglob(img_path + '/scissors_test/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 1\n",
        "        idx = idx + 1\n",
        "    \n",
        "    for file in glob.iglob(img_path + '/paper_test/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 2\n",
        "        idx = idx + 1\n",
        "        \n",
        "    return imgs, labels"
      ],
      "metadata": {
        "id": "kU4kCGrOGHzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path = '/content/drive/MyDrive/lms/rock_scissors_paper/test/'\n",
        "(x_test, y_test)=load_test_data(image_dir_path, 2038)\n",
        "x_test_norm = x_test / 255.0   "
      ],
      "metadata": {
        "id": "rKfcOguygGJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Drop-Out"
      ],
      "metadata": {
        "id": "VPW4dXk6M5t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test1_loss, test1_accuracy = model1.evaluate(x_test_norm, y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test1_loss))\n",
        "print(\"test_accuracy: {}\".format(test1_accuracy))"
      ],
      "metadata": {
        "id": "gV8jxBV03omU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db06a1a0-ce51-480a-db01-56903fbba3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 - 0s - loss: 0.0887 - accuracy: 0.9735 - 337ms/epoch - 5ms/step\n",
            "test_loss: 0.08867946267127991 \n",
            "test_accuracy: 0.9735034108161926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Non-Drop-Out"
      ],
      "metadata": {
        "id": "J3mScZjJNsYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test2_loss, test2_accuracy = model2.evaluate(x_test_norm, y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test2_loss))\n",
        "print(\"test_accuracy: {}\".format(test2_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ced7ea-3476-4e9c-8ad1-fdb0316c987d",
        "id": "iyC5-LvaNKSi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 - 0s - loss: 0.0903 - accuracy: 0.9794 - 379ms/epoch - 6ms/step\n",
            "test_loss: 0.09028542786836624 \n",
            "test_accuracy: 0.9793915748596191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 데이터와 테스트 데이터가 비슷해서 모델 설정이 쉽기 때문에 과적합이 발생한다."
      ],
      "metadata": {
        "id": "R_uNRvnEGBjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#과적합 문제"
      ],
      "metadata": {
        "id": "RCNjUR0gUB_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "과적합 문제를 파악하기 위해 모양이 다른 사진을 테스트 데이터로 써 본다."
      ],
      "metadata": {
        "id": "Oh9SO8VxFqWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "real_test\n",
        "* rock\n",
        "* scissors\n",
        "* paper"
      ],
      "metadata": {
        "id": "qECo4gGSIBs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path9 = '/content/drive/MyDrive/lms/rock_scissors_paper/real_test/rock/'\n",
        "resize_images(image_dir_path9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s9pf336TAIJ",
        "outputId": "f71f5615-e735-4739-f39e-379c71f377bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4  images to be resized.\n",
            "4  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path8 = '/content/drive/MyDrive/lms/rock_scissors_paper/real_test/scissors/'\n",
        "resize_images(image_dir_path8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMI3CRnFTAAq",
        "outputId": "3b601131-5bd3-44d8-8742-9996dbb115ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4  images to be resized.\n",
            "4  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path10 = '/content/drive/MyDrive/lms/rock_scissors_paper/real_test/paper/'\n",
        "resize_images(image_dir_path10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-cUrTb3TALJ",
        "outputId": "75ecade6-8cec-4166-8e16-b2c5483467f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4  images to be resized.\n",
            "4  images resized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_real_test_data(img_path, number_of_data):\n",
        "    img_size = 28\n",
        "    color = 3\n",
        "    \n",
        "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
        "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
        "\n",
        "    idx = 0\n",
        "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 0\n",
        "        idx = idx + 1   \n",
        "\n",
        "    for file in glob.iglob(img_path + '/scissors/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 1\n",
        "        idx = idx + 1\n",
        "    \n",
        "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype = np.int32)\n",
        "        imgs[idx, :, :, :] = img\n",
        "        labels[idx] = 2\n",
        "        idx = idx + 1\n",
        "        \n",
        "    return imgs, labels"
      ],
      "metadata": {
        "id": "tjctyPuYGQOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir_path11 = '/content/drive/MyDrive/lms/rock_scissors_paper/real_test/'\n",
        "(x_test, y_test)=load_real_test_data(image_dir_path11, 12)\n",
        "x_test_norm = x_test / 255.0  "
      ],
      "metadata": {
        "id": "y2QtKSXeTcH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Drop-Out"
      ],
      "metadata": {
        "id": "AHP1FBjcTnQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test3_loss, test3_accuracy = model1.evaluate(x_test_norm, y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test3_loss))\n",
        "print(\"test_accuracy: {}\".format(test3_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXWQdX2ITe0x",
        "outputId": "e63ed1de-6a4f-4ae5-d3cf-a2a99be1c58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 3.7691 - accuracy: 0.2500 - 21ms/epoch - 21ms/step\n",
            "test_loss: 3.7690927982330322 \n",
            "test_accuracy: 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Non-Drop-Out"
      ],
      "metadata": {
        "id": "VbPWNDBlTnp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test4_loss, test4_accuracy = model2.evaluate(x_test_norm, y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test4_loss))\n",
        "print(\"test_accuracy: {}\".format(test4_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbRcZIj4Tnzb",
        "outputId": "b58e1fd5-bc80-41c1-c02c-8f50db5502b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 3.8002 - accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
            "test_loss: 3.8001725673675537 \n",
            "test_accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 데이터의 accuracy가 75% 이하로 떨어졌다.\n",
        "<br/>이유는 훈련 데이터에 대한 과적합이 발생했기 때문이다.\n",
        "<br/>훈련 데이터와 다른 형태의 데이터가 들어온다면 융통성이 없어서 그 데이터에 적응을 못하는 것이다."
      ],
      "metadata": {
        "id": "r5O8NhpvUqfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##과적합을 방지하는 방법"
      ],
      "metadata": {
        "id": "u0f3yq8FUkjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **추가 데이터 수집**\n",
        "<br/>모형을 일반화하기 위해서는 더 많은 예제를 수집해야 한다."
      ],
      "metadata": {
        "id": "dH4SWAvIWgnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **데이터 확대 및 노이즈**\n",
        "<br/>데이터를 여러 가지 형태로 변형시켜 다양성에 적응할 수 있는 모델의 범용성을 확대한다.\n",
        "<br/>적당한 노이즈를 추가하여 정제되지 않을 가능성 있는 데이터의 현실성을 반영한다."
      ],
      "metadata": {
        "id": "qMzHfnZDGhhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **모델 단순화**\n",
        "<br/>복잡한 모델을 단순화하여 모델의 학습시간을 줄인다.\n",
        "<br/>이로 인해 더 많은 학습횟수를 확보할 수 있다."
      ],
      "metadata": {
        "id": "OPlA5R4xGoQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결론"
      ],
      "metadata": {
        "id": "CkoV-5amWqdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'model1'과 'model2'는 과적합을 방지할 수 있는 보완점을 마련해야 한다.\n",
        "<br/>그렇지 않으면 과거 1990년대 후반 ~ 2000년대 초반 MNIST 데이터셋의 매우 쉬운 학습과 같은 한계에 머무를 것이다.\n",
        "<br/>이러한 MNIST의 한계를 극복하기 위해 Fashion MNIST 등 다양하고 범용성 높은 데이터셋이 사용되기 시작했다는 역사적 배경을 되돌아본다."
      ],
      "metadata": {
        "id": "f15ASXQDXyDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "과적합을 방지하는 문제를 해결하고 나서야\n",
        "<br/>이 프로젝트의 목표 Drop-out 하이퍼파라미터 적용이 효과가 있는지 알아보는 것을 달성할 수 있을 것이다.\n",
        "<br/>현재 'model1'과 'model2' 상황으로는 비교할 수 없다.\n",
        "<br/>또한 Drop-out 하이퍼파라미터는 모델 성능을 끌어올리는 최후의 수단으로 쓰일 것이라고 생각하기에 \n",
        "<br/>Drop-out보다 과적합 문제 해결이 우선이다.\n"
      ],
      "metadata": {
        "id": "18KtOJhrYMc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#참고문헌"
      ],
      "metadata": {
        "id": "91Bv9lOPYyYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**단행본**\n",
        "<br/>정용범, 손상우 외 1명, 사장님 몰래 하는 파이썬 업무자동화(부제 : 들키면 일 많아짐), wikidocs, 2022\n",
        "<br/>[Pillow 설치 및 이미지 불러오기](https://wikidocs.net/153080)\n",
        "<br/>\n",
        "<br/>권상기 외 1명, 토닥토닥 파이썬 - 이미지를 위한 딥러닝, wikidocs, 2022\n",
        "<br/>[가위 바위 보 분류 모델 학습](https://wikidocs.net/73612)\n",
        "\n",
        "<br/>**웹사이트**\n",
        "<br/>[딥러닝 프레임워크 종류별 장. 단점 - 텐서플로, 케라스, 파이토치](https://hongong.hanbit.co.kr/%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EB%B9%84%EA%B5%90-%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C-%EC%BC%80%EB%9D%BC%EC%8A%A4-%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98/)\n",
        "<br/>[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "<br/>[딥러닝Drop-out(드롭아웃)은 무엇이고 왜 사용할까?](https://heytech.tistory.com/127)\n",
        "<br/>[Keras를 사용한 머신 러닝 mnist 코드 탐구 (3)](https://m.blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=ksg97031&logNo=221302568652)\n",
        "<br/>[기계학습 : 과적합을 방지하는 방법 6가지](https://iotnbigdata.tistory.com/15)"
      ],
      "metadata": {
        "id": "ngF61YsyY1jC"
      }
    }
  ]
}