{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E_06]TextGenerator(LyricsBot).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LMS Exploration\n",
        "<br/>**6. 작사가 인공지능 만들기**"
      ],
      "metadata": {
        "id": "2uCcvItmOci-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "개발 환경\n",
        "<br/>데이터 정보\n",
        "<br/>데이터 탐색\n",
        "<br/>데이터 시각화\n",
        "<br/>데이터셋의 한계\n",
        "* 문장 토큰화\n",
        "* 데이터셋 노이즈\n",
        "\n",
        "데이터 전처리\n",
        "<br/>train, val 데이터 분리\n",
        "<br/>모델 학습\n",
        "<br/>하이퍼 파라미터 튜닝\n",
        "<br/>모델 평가\n",
        "<br/>가사 생성\n",
        "<br/>결론\n",
        "<br/>참고문헌"
      ],
      "metadata": {
        "id": "66AfZULXBZHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#개발 환경"
      ],
      "metadata": {
        "id": "v6TbNgiSOeb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import re \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "metadata": {
        "id": "gZvVy4njOouQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob**는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다.\n",
        "<br/>단, 조건에 정규식을 사용할 수 없으며 엑셀 등에서도 사용할 수 있는 '*'와 '?'같은 와일드카드만을 지원한다."
      ],
      "metadata": {
        "id": "0pEf5ZnoQviL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tensorflow**는 구글이 개발한 오픈소스 소프트웨어 딥러닝 및 머신러닝 라이브러리이다.\n",
        "<br/>수학 계산식과 데이터의 흐름을 노드와 엣지를 사용한 방향성 그래프, 데이터 플로우 그래프로 나타낸다."
      ],
      "metadata": {
        "id": "w-LFuuo9Oeiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**numpy**는 array 단위로 벡터와 행렬을 계산한다. 이 라이브러리를 사용하기 위해서는 선형대수학 지식이 필요하다."
      ],
      "metadata": {
        "id": "Acm1V6-fvfoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**os(Operating System)**는 운영체제에서 제공되는 여러 기능을 파이썬에서 수행한다. <br/>예를 들어, 파일 복사, 디렉터리 생성, 파일 목록을 구할 수 있다."
      ],
      "metadata": {
        "id": "ESWq3NcjvufN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**re(regex)**는 특정 문자 또는 문자열이 존재하는지나 어느 위치에 있는지와 같은 기능을 제공하는 정규표현식 라이브러리이다."
      ],
      "metadata": {
        "id": "8-_H8De9vfDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**matplotlib**은 다양한 데이터와 학습 모델을 시각화한다."
      ],
      "metadata": {
        "id": "UF9k9DtZIg4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **sklearn.model_selection**는 훈련 데이터, 테스트 데이터를 분리한다."
      ],
      "metadata": {
        "id": "92-N05wpz63c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ix7riMmBSYX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > '/content/drive/MyDrive/lms/library_version.txt'"
      ],
      "metadata": {
        "id": "Jn68J8zRSYaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library_name = ['pandas=', 'numpy=', 'matplotlib=', 'sklearn=', 'regex=']\n",
        "library_version = []\n",
        "f = open('/content/drive/MyDrive/lms/library_version.txt', 'r')\n",
        "line = f.readline()\n",
        "while True:\n",
        "    line = f.readline()\n",
        "    if not line:\n",
        "      break\n",
        "    for i in library_name:\n",
        "      if i in line:\n",
        "        library_version.append(line)\n",
        "\n",
        "f.close()\n",
        "\n",
        "import sys\n",
        "print(sys.version)\n",
        "print()\n",
        "print(str(library_version).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"\\\\n\",\"\").replace(\",\",\"\"), end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ-3VpndSYhF",
        "outputId": "b297a2e5-8942-4c23-81d4-33e3dab6d6e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n",
            "\n",
            "matplotlib==3.2.2 numpy==1.21.6 pandas==1.3.5 regex==2019.12.20 sklearn==0.0 sklearn-pandas==1.8.0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "pjT4Mff_JHEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "zuf_jclMJHG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab에서 할당된 GPU를 확인한다.\n",
        "<br/>고용량 메모리 VM에 액세스한다."
      ],
      "metadata": {
        "id": "lXFo6I-pJHR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 정보"
      ],
      "metadata": {
        "id": "Vy4iUr53Oeon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[song_lyrics](https://www.kaggle.com/datasets/paultimothymooney/poetry)"
      ],
      "metadata": {
        "id": "eZ3uOVAEOcnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "49명의 가수의 영어 노래 가사를 수집한 텍스트 파일 모음 데이터셋이다.\n",
        "<br/>가사 생성기(lyrics Generator)를 만드는 데 사용된다."
      ],
      "metadata": {
        "id": "K-3GbtyGO-5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 탐색"
      ],
      "metadata": {
        "id": "0BleA9rSO6mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BYEfeIDjXFFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file_path = '/content/drive/MyDrive/LMS/song_lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMHkEHYis4If",
        "outputId": "e2fbe099-7a02-498b-a825-8047fcf93f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['\"Don\\'t worry about a thing,', \"'Cause every little thing gonna be all right.\", 'Singin\\': \"Don\\'t worry about a thing,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 데이터셋은 187088 문장으로 구성되어 있다.\n"
      ],
      "metadata": {
        "id": "UKSDz4tbO6eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**주의사항**\n",
        "<br/>주소를 적을 때 txt_file_path = '.../*'의 끝에 별 *를 적어야 한다.\n",
        "<br/>별을 빠뜨리면 IsADirectoryError: [Errno 21]라는 에러가 발생한다."
      ],
      "metadata": {
        "id": "FWDUByl71Ls8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob.glob**는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다. <br/>특정 파일 경로 안에 있는 파일명을 불러왔다.\n"
      ],
      "metadata": {
        "id": "u3PBTdg2tg22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**splitlines**은 줄 단위로 문자열을 리스트로 변환한다.\n",
        "<br/>그런데 split(\"\\n')도 splitlines()와 동일한 결과값을 보여주기 때문에\n",
        "<br/>문자열을 리스트로 변경할 때는 대부분 split()을 사용한다.\n"
      ],
      "metadata": {
        "id": "c_2KKH6L8s-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extend**는 확장 함수로 다른 리스트를 연결한다.\n",
        "<br/>여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다."
      ],
      "metadata": {
        "id": "snfQJyag28pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extend**와 **append**, **insert(a,b)**는 다른 형태의 추가 함수이니 때에 따라 다르게 쓴다.\n",
        "<br/>**append**는 리스트의 끝에 x 값을 추가한다.\n",
        "<br/>**insert(a,b)**는 리스트의 a 위치에 b 값을 추가한다."
      ],
      "metadata": {
        "id": "84GhFnAM-BIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 시각화"
      ],
      "metadata": {
        "id": "CTdZ96tJVUom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**matplotlib**을 이용해 문장 길이의 빈도 분포를 시각화한다."
      ],
      "metadata": {
        "id": "STBljIZRY_tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in raw_corpus)\n",
        "print('최대 길이 : %d' % max_len)\n",
        "print('최소 길이 : %d' % min(len(l) for l in raw_corpus if len(l) >= 1))\n",
        "print('평균 길이 : %f' % (sum(map(len, raw_corpus))/len(raw_corpus)))\n",
        "plt.hist([len(s) for s in raw_corpus if len(s) >= 1], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "SDlRs-eBJJJD",
        "outputId": "bdf990b8-f9dc-4a8b-cb5f-19bc71c42e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 1465\n",
            "최소 길이 : 1\n",
            "평균 길이 : 34.977070\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1,000이 넘는 지나치게 긴 길이가 있는 문장이 존재한다.\n",
        "<br/>왜 그럴까?"
      ],
      "metadata": {
        "id": "nEKXuIo1TbBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "print를 이용해 직접 1,000이 넘는 문장을 출력해서 문제 원인을 확인한다."
      ],
      "metadata": {
        "id": "FN4K1gllVnlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in raw_corpus:\n",
        "  if len(i) >= 1000:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYfbGIyUJ4hq",
        "outputId": "03a738f0-de5c-4a40-9437-4432aabeb421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WRITERS RUSSELL BROWN, IRWIN LEVINE I'm comin' home, I've done my time Now I've got to know what is and isn't mine If you received my letter telling you I'd soon be free Then you'll know just what to do if you still want me If you still want me Just tie a yellow ribbon 'round the old oak tree It's been way too long, do you still want me? If I don't see a ribbon 'round the old oak tree I'll just stay on the bus, forget about us, put the blame on me If I don't see a yellow ribbon 'round the old oak tree Bus driver, please look for me 'Cause I couldn't bear to see what I might see I'm really still in prison and my love, he holds the key A simple yellow ribbon's all I need to set me free I wrote and told him please... Just tie a yellow ribbon 'round the old oak tree It's been way too long, do you still want me? If I don't see a ribbon 'round the old oak tree I'll just stay on the bus, forget about us, put the blame on me If I don't see a ribbon 'round the old oak tree Tie a yellow ribbon 'round that old oak tree I'm coming home Now the whole dang bus is cheerin' and I can't believe I see a hundred yellow ribbons tied 'round the old oak tree I'm comin' home, I'm glad you waited for me Tie a yellow ribbon 'round the old oak tree Tie a ribbon 'round the old oak tree Tie a ribbon 'round the old oak tree Tie a yellow ribbon if you still want me Tie a yellow ribbon 'round the old oak tree Tie a yellow ribbon 'round the old oak tree Here you come again\n",
            "Another one (Chorus) Standing on the mountain top, counting all this money, laughing at you haters, ain't nothing gonna save yeah. Yeah, Welcome Back, Another small Buy, we global , Feel my pain They can't deal witha nigga like me. Cus I keep it so hood, yeah I keep it so Street. The industry hate but they gotta see me. Turn your tvs on Bet all you see is me. Nah I ain't playing why you trying to blame me, Might as well hate the world instead of hating on me. Pussy ass nigga (And we taking over, One paper bag at a time) I need that clearence feed me more, come and think about it you need it more Uhh I am miami I do it for miami, 24 and 7 trays yeah nigga we born and raised. See this, Joe Crack we showed them. Damn right I'm so concieted. I know it made you sick, guess what it made me rich. Shout out to all my DJ's. Projects I know you feel me. Thank god for rubber bands. Phantoms on paper tags. This oens for all the fans. We the best. (Chorus) Standing on the mountain top, counting all this money, laughing at you haters, ain't nothing gonna save yeah. x2 I Introduce you to ace hood!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 자체의 문제이다.\n",
        "<br/>웹크롤링 당시 줄바꿈되지 않은 채 여러 문장이 하나의 문장으로 이어져 txt 파일에 담긴 것이다."
      ],
      "metadata": {
        "id": "s5Es1m2TTic-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터셋의 한계"
      ],
      "metadata": {
        "id": "Wb26WWs7wQpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##문장 토큰화"
      ],
      "metadata": {
        "id": "CwBMfaTHwcSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 토큰화를 하는 함수 **nltk.tokenize**의 **sent_tokenize**가 있으나\n",
        "<br/>마침표를 기준으로 문장을 나누기 때문에 길이가 1,000이 넘는 문장을 구분할 수 없다.\n",
        "여러 문장으로 구성된 이 글 안에는 마침표가 없는 문장이 있으며 마침표가 있는 문장도 존재한다.\n",
        "<br/>토큰화의 기준인 문장 부호가 제역할을 하지 못하는 것이다."
      ],
      "metadata": {
        "id": "qcA4ueaDvlbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> WRITERS RUSSELL BROWN, IRWIN LEVINE I'm comin' home, I've done my time Now I've got to know what is and isn't mine If you receive (생략)"
      ],
      "metadata": {
        "id": "wnwNEBLewLml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터셋 노이즈"
      ],
      "metadata": {
        "id": "YA_JKVN9zDYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entire_sentence_num = 0\n",
        "for i in raw_corpus:\n",
        "  entire_sentence_num += 1\n",
        "\n",
        "print('전체 문장 개수 : %d' % entire_sentence_num)\n",
        "\n",
        "fifteen_sentence_num = 0\n",
        "for i in raw_corpus:\n",
        "  if len(i) <= 70:\n",
        "    fifteen_sentence_num += 1\n",
        "\n",
        "print('문장 길이 70 미만의 문장 개수 : %d' % fifteen_sentence_num)\n",
        "\n",
        "num_difference = entire_sentence_num - fifteen_sentence_num\n",
        "print('문장 길이 70 기준 전처리 이후 제외되는 문장 개수 : %d' % num_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fie9vJGt0xxE",
        "outputId": "7bb4f186-a6c0-4467-db76-e00e6cc36ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 문장 개수 : 187088\n",
            "문장 길이 70 미만의 문장 개수 : 177721\n",
            "문장 길이 70 기준 전처리 이후 제외되는 문장 개수 : 9367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리를 통해 지나치게 긴 문장을 제외한 상황을 가정한다."
      ],
      "metadata": {
        "id": "NPDPv6rBI3Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이 70을 기준으로 전처리 이후 제외된 문장의 개수는 9367개이다."
      ],
      "metadata": {
        "id": "sRWTx0AT2Jm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9300개가 넘는 문장의 데이터를 잃지만 전처리를 통해 정제된 데이터를 얻을 수 있다."
      ],
      "metadata": {
        "id": "6fyhWtBJo8il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_data_rate = round((num_difference / entire_sentence_num) * 100, 2)\n",
        "print('전처리로 제외된 데이터 비율 : %.2f ' % delete_data_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6AVPhtqC2x7",
        "outputId": "0f945a29-6e03-4e7a-deb0-41bc73556fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리로 제외된 데이터 비율 : 5.01 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리로 전체 데이터의 5.01%가 제외된다."
      ],
      "metadata": {
        "id": "4CCb0UyjC0Cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "웹크롤링으로 가져온 데이터셋의 노이즈가 그만큼 많다는 것이다."
      ],
      "metadata": {
        "id": "hmyOf96kEhW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이가 70을 넘어가는 문장을 제외하는 방법이 아닌 대안이 있어야하지 않을까?\n"
      ],
      "metadata": {
        "id": "K7Z_VMRvEour"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "웹에 업로드되어있는 데이터 자체의 문제로 인해 문장의 끝에 마침표가 없어서 \n",
        "<br/>여러 문장이 합쳐져 '지나치게 긴 하나의 문장'이 된 노이즈를 \n",
        "<br/>여러 문장으로 분할하여 '하나의 문장'이라는 정제된 데이터로 변환시켜주는 \n",
        "<br/>전처리 기술이 개발되어야하지 않을까?"
      ],
      "metadata": {
        "id": "o3mg75Hpu02p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 전처리 기술이 발달이 되면 5.01%와 같은 데이터양의 축소를 하지 않고\n",
        "<br/>더 많은 웹크롤링 텍스트 데이터의 양을 확보할 수 있을 것이다."
      ],
      "metadata": {
        "id": "Of2xScvFFfiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(i) for i in raw_corpus if len(i) <= 70])\n",
        "sum_len = sum([len(i) for i in raw_corpus if 1 <= len(i) <= 70])\n",
        "mean_len = sum_len / fifteen_sentence_num\n",
        "\n",
        "print('최대 길이 : %d' % max_len)\n",
        "print('최소 길이 : %d' % min([len(l) for l in raw_corpus if len(l) >= 1]))\n",
        "print('평균 길이 : %f' % mean_len)\n",
        "plt.hist([len(s) for s in raw_corpus if 1 <= len(s) <= 70], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "fnSz7KtNzAwL",
        "outputId": "a8100676-3c61-40f1-8db8-b0f475335cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 70\n",
            "최소 길이 : 1\n",
            "평균 길이 : 32.068101\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 전처리"
      ],
      "metadata": {
        "id": "UKcT31lpO62T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() \n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    return sentence\n",
        "\n",
        "\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl9Q46mhub91",
        "outputId": "2e0d8b94-d25d-4e1f-f5cc-7f5b88f47957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lower.strip**은 소문자로 바꾸고, 양쪽 공백을 지운다.\n"
      ],
      "metadata": {
        "id": "UGdC7GMZBpj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sub**을 이용해 특수문자 양쪽에 공백을 넣는다.\n",
        "<br/>여러개의 공백은 하나의 공백으로 바꾼다.\n",
        "<br/>a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾼다."
      ],
      "metadata": {
        "id": "W74c0bm8ESvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**strip**은 다시 양쪽 공백을 지운다."
      ],
      "metadata": {
        "id": "Ys_1f9oKEWe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 시작에는 start, 끝에는 end를 추가한다."
      ],
      "metadata": {
        "id": "BA8Ik8aBEjgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "corpus[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS28S5c4ud4W",
        "outputId": "9b25fe25-7ea1-424e-f9bd-81a4666ebce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> don t worry about a thing , <end>',\n",
              " '<start> cause every little thing gonna be all right . <end>',\n",
              " '<start> singin don t worry about a thing , <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "corpus 리스트에 정제된 문장을 담는다."
      ],
      "metadata": {
        "id": "FogHifOIG-kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 길이가 0인 문장은 넘어간다."
      ],
      "metadata": {
        "id": "rYQf8VipHjkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막에 기호 :가 있는 문장은 리스트에 담지 않고 넘어간다."
      ],
      "metadata": {
        "id": "laby64YG9e0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    \n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "id": "hdTeXoduuhDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee08f07-ddb4-4e20-9c41-ea274a4b66b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2   37   15 ...    0    0    0]\n",
            " [   2   67  133 ...    0    0    0]\n",
            " [   2 1551   37 ...    0    0    0]\n",
            " ...\n",
            " [   2   45  900 ...    0    0    0]\n",
            " [   2   45   66 ...    0    0    0]\n",
            " [   2    8   83 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f3b0a2d2c10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer**는 내부 단어장의 크기를 12000로 갖는다.\n",
        "<br/>단어장에 포함되지 못한 단어는 'unk'로 저장한다. "
      ],
      "metadata": {
        "id": "RL4x_ig_qPh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "준비한 tokenizer를 이용해 corpus를 Tensor로 변환한다."
      ],
      "metadata": {
        "id": "bS8FHiQYqYRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**padding='post'**는 입력 데이터의 시퀀스 길이를 일정하게 맞춘다.\n",
        "<br/>만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다."
      ],
      "metadata": {
        "id": "mw3DuFohqZpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**maxlen=15**는 토큰의 개수가 15개 넘어가는 문장을 제외한다.\n",
        "<br/>지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거할 필요가 있다. "
      ],
      "metadata": {
        "id": "8MCwckVNBSzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:3, :10])"
      ],
      "metadata": {
        "id": "aVVdFqWAukXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9977ee29-a158-44ff-9d42-9d4393bae199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2   37   15  717  113    9  181    4    3    0]\n",
            " [   2   67  133  117  181   96   27   24   84   20]\n",
            " [   2 1551   37   15  717  113    9  181    4    3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성된 텐서 데이터를 3번째 행, 10번째 열까지만 출력한다."
      ],
      "metadata": {
        "id": "GgwitDCA1FLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "id": "PBMjFzwNuk0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1083642-95d6-4592-fab3-6cbb8624eb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " tokenizer에 구축된 단어 사전의 인덱스를 통해 단어 사전이 어떻게 구축되었는지 확인한다."
      ],
      "metadata": {
        "id": "5f-A7ha41Q-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_input = tensor[:, :-1]  \n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "id": "hMwm8YKbunbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2817fc-4948-41c5-a9a4-b7c7c9e551d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2  37  15 717 113   9 181   4   3   0   0   0   0   0]\n",
            "[ 37  15 717 113   9 181   4   3   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor에서 마지막 토큰을 잘라내서 소스 문장 **src_input**을 생성한다.\n"
      ],
      "metadata": {
        "id": "J0iu6JaG1hJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막 토큰은 end가 아니라 pad일 가능성이 높다."
      ],
      "metadata": {
        "id": "nW08LPLo1n07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor에서 start를 잘라내서 타겟 문장 **tgt_input**을 생성한다."
      ],
      "metadata": {
        "id": "5holoN2W1oxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train, val 데이터 분리"
      ],
      "metadata": {
        "id": "A9QkL92ktsrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
        "                                                    tgt_input,    \n",
        "                                                    test_size=0.2,   \n",
        "                                                    random_state=1)  \n",
        "\n",
        "print('enc_train 개수: ', len(enc_train),', enc_val 개수: ', len(enc_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIoKJQwU2DgM",
        "outputId": "c75331ba-2b5f-42ac-e2b1-b94efe1d956d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc_train 개수:  140599 , enc_val 개수:  35150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sklearnn** 모듈의 **train_test_split**를 이용해 데이터셋 분리를 한다.\n",
        "<br/>소스 문장 **src_input**을 특징 데이터, 타겟 문장 **tgt_input**을 정답 데이터로 사용한다.\n",
        "<br/>전체의 20%를 평가 데이터로 사용한다.\n",
        "<br/>**random_state**는 데이터를 무작위로 정렬하여 분리한다."
      ],
      "metadata": {
        "id": "-aIbV7qe1928"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Source Train: ', enc_train.shape)\n",
        "print('Target Train: ', dec_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QQc_zIAKZz",
        "outputId": "99390fa3-406c-4ec4-ad4f-b2338aceddd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Train:  (140599, 14)\n",
            "Target Train:  (140599, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "LdxSEnrouBJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ed4ce9-c8b0-4bab-93db-a0469fd4e244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WigPZz2O5ZCr",
        "outputId": "08938fa0-3208-4706-de7e-f82fa417a552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch size**는 한 번에 네트워크에 넘겨주는 데이터의 수이다.\n",
        "<br/>trade off로서 컴퓨터의 메모리 문제 때문에 분할해서 학습하는 것이다.\n",
        "\n",
        "<br/>140599 ≥ 140544 = 256 * 549\n",
        "<br/>train data num = batch size * step\n",
        "\n",
        "<br/>35150 = 256 * 137 ≥ 35072\n",
        "<br/>validation data num = batch size * step\n",
        "\n",
        "<br/>주의할 점은 epoch와 batch size는 다른 개념이다.\n",
        "<br/>epoch = batch size * step\n"
      ],
      "metadata": {
        "id": "ICTY6YIpaXNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**vocab size**는 tokenizer가 구축한 단어사전 내 7000개, 0 : pad를 포함하여 7001개를 포함한다."
      ],
      "metadata": {
        "id": "II-5WOeN4kqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 학습"
      ],
      "metadata": {
        "id": "XG9ld0Xvtzhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.keras.Model을 Subclassing하는 방식으로 만든다.\n",
        "<br/>Embedding 레이어 1개, LSTM 레이어 2개, Dense 레이어 1개로 구성된다"
      ],
      "metadata": {
        "id": "P3efBSKi5_Tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "EJWb3Pjhu0O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 모델 **model1**\n",
        "<br/>하이퍼 파라미터를 설정한 학습 모델 **model2**\n",
        "<br/>평가 모델 **model3**으로 설정한다."
      ],
      "metadata": {
        "id": "3tMryZ5u7nlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model1 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "nnDRgmqr7mNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding 레이어**는 이 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꾼다.\n",
        "<br/>워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현(representation)으로 사용된다."
      ],
      "metadata": {
        "id": "OEYdPyFl6WPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model1(src_sample)"
      ],
      "metadata": {
        "id": "018DgCW7vuZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋에서 데이터 한 배치만 불러온다.\n",
        "<br/>한 배치만 불러온 데이터를 모델에 넣는다."
      ],
      "metadata": {
        "id": "MZ9TZ7CV44W7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model의 input shape가 결정되면서 model.build()가 자동으로 호출된다.\n",
        "<br/>"
      ],
      "metadata": {
        "id": "6cRD5_NN6x7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "5gcqszZDu3T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507fef4b-9b53-4d97-89ba-1d0ae074d692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  3072256   \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  12301025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model1.compile(loss=loss, optimizer=optimizer)\n",
        "model1.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "id": "OMdkMRFbu7KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1218eee4-5f5b-4494-e32e-a933eff02028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 52s 89ms/step - loss: 3.7268\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 3.2022\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 3.0118\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.8693\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.7456\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.6322\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.5261\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.4259\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.3317\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 2.2413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b0a95e090>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1**의 train loss는 2.2413이다."
      ],
      "metadata": {
        "id": "Yjf-mQkviLnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#하이퍼 파라미터 튜닝"
      ],
      "metadata": {
        "id": "K9h4eV6w8jf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**에서 하이퍼 파라미터를 다음과 같이 설정한다.\n",
        "> embedding_size = 256 → 600\n",
        "<br/>hidden_size = 1024 → 2048\n"
      ],
      "metadata": {
        "id": "QOEvQmQcZsQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 600\n",
        "hidden_size = 2048\n",
        "model2 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "jo9Fpr7yMEqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model2(src_sample)"
      ],
      "metadata": {
        "id": "VO9qatX-MEtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TZJwHMbMEv0",
        "outputId": "0bbc3058-f217-4169-cf30-8f77b3e99ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     multiple                  7200600   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               multiple                  21700608  \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               multiple                  33562624  \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,053,881\n",
            "Trainable params: 87,053,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model2.compile(loss=loss, optimizer=optimizer)\n",
        "model2.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM8qTaMVMEyb",
        "outputId": "7970b188-b2e2-49e9-8ac2-9963bab3d8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 132s 236ms/step - loss: 3.5851\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 2.9976\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 2.7200\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 2.4658\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 2.2204\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 130s 236ms/step - loss: 1.9836\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 129s 236ms/step - loss: 1.7585\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 129s 236ms/step - loss: 1.5524\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 129s 236ms/step - loss: 1.3694\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 129s 236ms/step - loss: 1.2162\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b08ab0110>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**의 train loss는 1.2162이다."
      ],
      "metadata": {
        "id": "_4fWdrvLiIRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 평가"
      ],
      "metadata": {
        "id": "YvKJIe__JPf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 높은 **model2**의 하이퍼 파라미터 값을 평가 모델 **model3**에 사용한다.\n",
        "> embedding_size = 600\n",
        "<br/>hidden_size = 2048\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ucL7-Sg_ZHfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 600\n",
        "hidden_size = 2048\n",
        "model3 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "9bVJmLmlJX5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in val_dataset.take(1): break\n",
        "\n",
        "model3(src_sample)"
      ],
      "metadata": {
        "id": "2TwG-IO0JYIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPi_vBP5JYLK",
        "outputId": "7577c3e7-3a98-4f74-e2aa-50ddf029c5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     multiple                  7200600   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               multiple                  21700608  \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               multiple                  33562624  \n",
            "                                                                 \n",
            " dense_3 (Dense)             multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,053,881\n",
            "Trainable params: 87,053,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model3.compile(loss=loss, optimizer=optimizer)\n",
        "model3.fit(val_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6UpWhuXJYOS",
        "outputId": "04db15de-d060-419f-ec0d-9ef024c97124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "137/137 [==============================] - 34s 235ms/step - loss: 4.1330\n",
            "Epoch 2/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 3.4023\n",
            "Epoch 3/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 3.1710\n",
            "Epoch 4/10\n",
            "137/137 [==============================] - 32s 236ms/step - loss: 2.9884\n",
            "Epoch 5/10\n",
            "137/137 [==============================] - 32s 236ms/step - loss: 2.8115\n",
            "Epoch 6/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 2.6227\n",
            "Epoch 7/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 2.4207\n",
            "Epoch 8/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 2.2107\n",
            "Epoch 9/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 1.9988\n",
            "Epoch 10/10\n",
            "137/137 [==============================] - 32s 235ms/step - loss: 1.7857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a8a21dc10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model3**의 valadation loss는 1.7857이다."
      ],
      "metadata": {
        "id": "P9TYnQiJh1cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#가사 생성"
      ],
      "metadata": {
        "id": "oe43geLkKNu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "   \n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "iI2gJn_A8NZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.convert_to_tensor**는 테스트를 위해서 입력받은 init_sentence도 텐서로 변환한다."
      ],
      "metadata": {
        "id": "Jz3RINnn9J3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**while Loop**에서 단어를 하나씩 예측해 문장을 만든다.\n",
        "<br/>1) 입력받은 문장의 텐서를 입력한다.\n",
        "<br/>2) 예측된 값 중 가장 높은 확률인 word index를 뽑아낸다.\n",
        "<br/>3) 2에서 예측된 word index를 문장 뒤에 붙인다.\n",
        "<br/>4) 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마친다."
      ],
      "metadata": {
        "id": "Qbnc60dc9yj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer**를 이용해 word index를 단어로 하나씩 변환합니다 "
      ],
      "metadata": {
        "id": "DGxJTUaY96We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 높은 학습 모델 **model2**를 사용해 가사를 생성한다."
      ],
      "metadata": {
        "id": "2HKRbru-kk27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> i love\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nV3xG_-IkZtC",
        "outputId": "9e2c2c30-4ec3-48cb-cc93-b256afbc0351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2l23ETvyjBia",
        "outputId": "5b4450df-a8d1-4c9b-d3f2-4ef22f04e51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> good day sunshine , <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> out\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iSIzshmzjBYa",
        "outputId": "a2ab663f-0ea5-4c98-a50e-ca7300290214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> out of the most highest cloud <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> see\")"
      ],
      "metadata": {
        "id": "Mu2jWUvOt7hV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67187760-4640-46ed-eeca-bd956b6eaa82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> see i got the whole city in the world <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model2, tokenizer, init_sentence=\"<start> where\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mW1aWEXcj49a",
        "outputId": "0eb0baad-53c1-44b3-e242-7ca748812bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> where the eyelids go <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결론"
      ],
      "metadata": {
        "id": "sgq97imgO7Fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**하이퍼 파라미터 튜닝**"
      ],
      "metadata": {
        "id": "6K0aAKGAqK_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model2**에서 하이퍼 파라미터를 다음과 같이 설정한다.\n",
        "> embedding_size = 256 → 600\n",
        "<br/>hidden_size = 1024 → 2048"
      ],
      "metadata": {
        "id": "YZf1hWeilkjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 높은 **model2**의 하이퍼 파라미터 값을 평가 모델 **model3**에 사용한다.\n",
        "> embedding_size = 600\n",
        "<br/>hidden_size = 2048"
      ],
      "metadata": {
        "id": "IMmlvdoeO7MD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1**의 train loss는 2.2413이다.\n",
        "<br/>**model2**의 train loss는 1.2162이다.\n",
        "<br/>**model3**의 valadation loss는 1.7857이다."
      ],
      "metadata": {
        "id": "1NGKmBOWlJRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 설정으로 train loss는 감소했지만\n",
        "<br/>train loss와 valadation loss의 차이는 0.5695이다."
      ],
      "metadata": {
        "id": "1tc1g5Lyla2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding_size가 커지고 hidden_size가 깊어져서\n",
        "과적합이 발생한 것인가?\n",
        "<br/>하이퍼 파라미터 값이 크다고 성능이 개선될거라는 보장은 없다."
      ],
      "metadata": {
        "id": "P5ndLwntl3Mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "또한 튜닝에 있어서 무슨 하이퍼 파라미터를 선택해야 하는가?\n",
        "<br/>embedding_size, hidden_size 튜닝은 무슨 시사점을 남기는가?"
      ],
      "metadata": {
        "id": "_hA_2XzgnHTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 튜닝 결과에 대한 분석 방법을 알고자 튜닝 관련 논문을 찾아보았다."
      ],
      "metadata": {
        "id": "sQunSVR6o9NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[RNN모델에서 하이퍼 파라미터 변화에 따른 정확도와 손실 성능, 분석융합정보논문지 v.11 no.7, 2021, pp.31 - 38, 김준용, 박구락](https://www.koreascience.or.kr/article/JAKO202123157143805.pdf)\n"
      ],
      "metadata": {
        "id": "h5thXMjSmDWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 논문에서는 LSTM의 unit, batch_size, embedding_size를 설정한다.\n"
      ],
      "metadata": {
        "id": "xWkxITBvmJqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "unit, batch_size, embedding_size 튜닝은 무슨 시사점을 남기는가?\n",
        "* embedding_size가 가장 영향력이 큰 하이퍼 파라미터였다.\n",
        "* Unit의 개수가 적을수록 batch_size가 클수록 성능이 높아진다.\n",
        "* Embedding size가 커지면서 성능이 높아졌다가 낮아진다."
      ],
      "metadata": {
        "id": "KyUqNY2CoS3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 하이퍼 파라미터 튜닝의 결과에 대해 분석할 수 있었던 이유는\n",
        "<br/>연구자가 하이퍼 파라미터 변화에 따른 Loss와 Accuracy의 추이를 표로 정리했기 때문이다."
      ],
      "metadata": {
        "id": "srELNMwPo6Ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 변화에 따른 학습 결과를 문서로 정리할 수 있는 알고리즘을 짜는 방법을 알고 싶다."
      ],
      "metadata": {
        "id": "tKRpUhjPmDcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**텍스트 데이터셋**"
      ],
      "metadata": {
        "id": "J6Ybgv9lqNDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 노이즈에 대한 사전지식을 갖추고 웹크롤링과 데이터 전처리를 진행해야한다.\n",
        "* 문장 부호가 작성되지 않았거나 띄어쓰기가 되지 않은 상황에서 토큰의 단위에 따라 어떻게 분리하는가?\n",
        "\n"
      ],
      "metadata": {
        "id": "q9MFa_3nqNGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#참고문헌"
      ],
      "metadata": {
        "id": "VVZkeI61zg37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "\n",
        "[text_generation_shakespeare_rnn.ipynb](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_shakespeare_rnn/text_generation_shakespeare_rnn.ipynb#scrollTo=bui0MyTjv1Mp)\n",
        "\n",
        "[OS 모듈](https://wikidocs.net/3141)\n",
        "\n",
        "[Python re 모듈 사용법](https://brownbears.tistory.com/506)\n",
        "\n",
        "[Python glob.glob() 사용법](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=siniphia&logNo=221397012627)\n",
        "\n",
        "\n",
        "[Python 리스트(List)와 리스트 메소드(append, insert, remove, pop, extend)](https://velog.io/@falling_star3/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9D%98-%EB%A6%AC%EC%8A%A4%ED%8A%B8List%EC%99%80-%EA%B4%80%EB%A0%A8-%ED%95%A8%EC%88%98%EB%93%A4append-insert-remove-pop-extend)\n",
        "\n",
        "\n",
        "[파이썬 문자열을 리스트로 만들기 – split, splitlines](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=debolm74&logNo=221953881991)\n",
        "\n",
        "[PyTorch로 시작하는 딥 러닝 입문  / 01. 자연어 처리 전처리 이해하기](https://wikidocs.net/64517)\n",
        "\n",
        "[4. 텍스트 전처리(정규화)](https://blockchainstudy.tistory.com/58)\n",
        "\n",
        "[PYTHON / NLTK 텍스트 파일 문장 단위로 분해하기 (SENTENCE TOKENIZE)](https://cryptosalamander.tistory.com/140)\n",
        "\n",
        "[Python에서 문자열의 단어 계산](https://www.delftstack.com/ko/howto/python/python-count-words-in-string/)\n",
        "\n",
        "[15.Batch size & Batch Norm](https://nittaku.tistory.com/293)\n",
        "\n",
        "\n",
        "[RNN모델에서 하이퍼 파라미터 변화에 따른 정확도와 손실 성능, 분석융합정보논문지 v.11 no.7, 2021, pp.31 - 38, 김준용, 박구락](https://www.koreascience.or.kr/article/JAKO202123157143805.pdf)\n"
      ],
      "metadata": {
        "id": "ttZWzlIErLhb"
      }
    }
  ]
}